{"cells":[{"cell_type":"markdown","metadata":{"papermill":{"duration":0.004896,"end_time":"2024-02-19T18:30:53.912637","exception":false,"start_time":"2024-02-19T18:30:53.907741","status":"completed"},"tags":[]},"source":["# CWT preprocessing\n","\n","Loading pretrained model, apply feature engineering to test eegs, and predict on local test set."]},{"cell_type":"code","execution_count":4,"id":"06c94ab2","metadata":{"execution":{"iopub.execute_input":"2024-03-10T07:06:00.760960Z","iopub.status.busy":"2024-03-10T07:06:00.759818Z","iopub.status.idle":"2024-03-10T07:06:15.550345Z","shell.execute_reply":"2024-03-10T07:06:15.549386Z","shell.execute_reply.started":"2024-03-10T07:06:00.760919Z"},"papermill":{"duration":13.003552,"end_time":"2024-02-19T18:31:06.921234","exception":false,"start_time":"2024-02-19T18:30:53.917682","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-03-10 12:53:32.184100: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import keras\n","import sys\n","import os\n","import pywt\n","import time\n","\n","\n","# ----------------------------------------\n","# Flags for working on different hardware.\n","flag_kaggle = True\n","# flag_FW = True\n","# flag_LN = True\n","\n","try:\n","    if flag_kaggle:\n","        sys.path.insert(0, '/kaggle/input/hms-lib')\n","        base_dir = '/kaggle/input/hms-harmful-brain-activity-classification'\n","except:\n","    pass \n","\n","try:\n","    if flag_FW:\n","        sys.path.insert(0, '../lib')\n","        base_dir = '../../kaggle_data/hms'\n","        devset_dir = '../data'\n","except:\n","    pass \n","\n","try:\n","    if flag_LN:\n","        sys.path.insert(0, '../lib')\n","        base_dir = '../../data/hms'\n","        devset_dir = '../data'\n","except:\n","    pass \n","# ----------------------------------------\n","\n","\n","from lib_banana import banana\n","from lib_pooling import poolingOverlap\n","\n","\n","test_path = '/kaggle/input/hms-toy-test-eegs'\n","\n","test_files = os.listdir(test_path)\n","test_size = len(test_files)\n","test_size\n"]},{"cell_type":"markdown","id":"34b032ff","metadata":{},"source":["## Preprocessing test set"]},{"cell_type":"code","execution_count":null,"id":"7f66d4f7","metadata":{},"outputs":[],"source":["scales = np.arange(1,50)\n","waveletname = 'morl'\n","n_channels = 5\n","dim1 = scales.shape[0]\n","pool_window = 5\n","dim2 = int(2000/pool_window)\n","sampling_period = 1\n","# Center 10 s adjusted by pooling window.\n","start2 = int(4000/pool_window)\n","end2 = int(6000/pool_window)\n","\n","sgrams = np.empty((test_size, dim1, dim2, n_channels))\n","# item: [eeg_id, eeg_sub_id, idx in sgrams (1st index), target,\n","#       seizure_vote, lpd_vote, gpd_vote, lrda_vote,\n","#       grda_vote, other_vote]\n","items = np.array([], dtype=float).reshape(0,10)"]},{"cell_type":"code","execution_count":null,"id":"98952372","metadata":{},"outputs":[],"source":["t1 = time.perf_counter()\n","\n","for i, file in enumerate(test_files):\n","    eeg_full = pd.read_parquet(f'{test_path}/{file}')\n","    # eeg_full = eeg_full.interpolate(limit_direction='both') # <<<<< Interpolation\n","    eeg = banana(eeg_full, filter=False)\n","\n","        # Averaging each chain in the banana montage.\n","\n","    # Left temporal chain.\n","    coeff = np.zeros((dim1, 10000))\n","    # coeff = np.zeros((dim1, 6000))  # keeping 30 s to reduce runtime.\n","    for col in [0,1,2,3]:\n","        coeff_, freq = pywt.cwt(eeg.iloc[:,col], scales, waveletname, sampling_period=sampling_period)\n","        coeff = coeff + coeff_\n","\n","    coeff = coeff/4\n","    coeff = poolingOverlap(coeff,(1,pool_window),stride=None,method='mean',pad=False)\n","    coeff = (coeff - np.mean(coeff)) / np.std(coeff)\n","    sgrams[i,:,:,0] = coeff[:,start2:end2].copy()\n","\n","    # Right temporal chain.\n","    coeff = np.zeros((dim1, 10000))\n","    for col in [4,5,6,7]:\n","        coeff_, freq = pywt.cwt(eeg.iloc[:,col], scales, waveletname, sampling_period=sampling_period)\n","        coeff = coeff + coeff_\n","\n","    coeff = coeff/4\n","    coeff = poolingOverlap(coeff,(1,pool_window),stride=None,method='mean',pad=False)\n","    coeff = (coeff - np.mean(coeff)) / np.std(coeff)\n","    sgrams[i,:,:,1] = coeff[:,start2:end2].copy()\n","\n","    # Left parasagittal chain.\n","    coeff = np.zeros((dim1, 10000))\n","    for col in [8,9,10,11]:\n","        coeff_, freq = pywt.cwt(eeg.iloc[:,col], scales, waveletname, sampling_period=sampling_period)\n","        coeff = coeff + coeff_\n","\n","    coeff = coeff/4\n","    coeff = poolingOverlap(coeff,(1,pool_window),stride=None,method='mean',pad=False)\n","    coeff = (coeff - np.mean(coeff)) / np.std(coeff)\n","    sgrams[i,:,:,2] = coeff[:,start2:end2].copy()\n","\n","    # Right parasagittal chain.\n","    coeff = np.zeros((dim1, 10000))\n","    for col in [12,13,14,15]:\n","        coeff_, freq = pywt.cwt(eeg.iloc[:,col], scales, waveletname, sampling_period=sampling_period)\n","        coeff = coeff + coeff_\n","\n","    coeff = coeff/4\n","    coeff = poolingOverlap(coeff,(1,pool_window),stride=None,method='mean',pad=False)\n","    coeff = (coeff - np.mean(coeff)) / np.std(coeff)\n","    sgrams[i,:,:,3] = coeff[:,start2:end2].copy()\n","\n","    # Central chain.\n","    coeff = np.zeros((dim1, 10000))\n","    for col in [16,17]:\n","        coeff_, freq = pywt.cwt(eeg.iloc[:,col], scales, waveletname, sampling_period=sampling_period)\n","        coeff = coeff + coeff_\n","\n","    coeff = coeff/2\n","    coeff = poolingOverlap(coeff,(1,pool_window),stride=None,method='mean',pad=False)\n","    coeff = (coeff - np.mean(coeff)) / np.std(coeff)\n","    sgrams[i,:,:,4] = coeff[:,start2:end2].copy()\n","\n","    eeg_id = int(test_files[2].split('.')[0])\n","    # Set unkowns to zero, to reuse code.\n","    xitem = np.array([eeg_id, 0, i, 0, 0, 0, 0,\n","                      0, 0, 0], dtype=float).reshape(1,10)\n","    items = np.concatenate([items, xitem])\n","\n","t2 = time.perf_counter()\n","print(f'Time for preprocessing {test_size} files: {np.round(t2-t1,3)} s.')"]},{"cell_type":"code","execution_count":null,"id":"85ee2461","metadata":{},"outputs":[],"source":["t1 = time.perf_counter()\n","\n","TARGETS = ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n","\n","#\n","# Test Data generator\n","#\n","# for predictions in Kaggle.\n","# \n","\n","class TestDataGenerator(keras.utils.Sequence):\n","    'Generates data for Keras'\n","    def __init__(self, items, data, batch_size=32, n_classes=6, shuffle=False):\n","        ''' Initialization\n","        items: [eeg_id, eeg_sub_id, idx of offset, target, ...]\n","        '''\n","        self.n_channels = 5\n","        self.data = data\n","        self.items = items\n","        self.dim = (self.data.shape[1], self.data.shape[2])\n","        self.batch_size = batch_size\n","        self.len = self.data.shape[0]\n","        self.n_classes = n_classes\n","        self.shuffle = shuffle\n","        self.on_epoch_end()\n","\n","    def __len__(self):\n","        'Denotes the number of batches per epoch'\n","        return int(np.ceil(self.len / self.batch_size))\n","\n","    def __getitem__(self, index):\n","        'Generate one batch of data'\n","        # Generate indexes of the batch\n","        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n","\n","        # Generate data\n","        X = self.__data_generation(indexes)\n","\n","        return X\n","\n","    def get_dim(self):\n","        'Dimensions for the input layer.'\n","        return (self.dim[0], self.dim[1], self.n_channels)\n","\n","    def on_epoch_end(self):\n","        'Updates indexes after each epoch'\n","        self.indexes = np.arange(self.len)\n","        # pass \n","        \n","    def __data_generation(self, indexes):\n","        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n","        # Initialization\n","        true_size = len(indexes)\n","        X = np.empty((true_size, *self.dim, self.n_channels))\n","\n","        # Generate data\n","        for i, idx in enumerate(indexes):\n","            item = self.items[idx]\n","            # print(item)  # Uncomment for testing.\n","            X[i,:,:,:] = self.data[np.int32(item[2]), :, :, :]\n","\n","        return X\n","\n","params = {\n","    'batch_size': 32,\n","    'n_classes': 6,\n","    }\n","\n","test_generator = TestDataGenerator(items, sgrams, **params)\n"]},{"cell_type":"code","execution_count":null,"id":"1d217bdb","metadata":{},"outputs":[],"source":["model_file = '/kaggle/input/hms-model-cwt-v1/model_cwt_031001_057.keras'\n","checkpoint_filepath = '/kaggle/input/hms-model-cwt-v1/checkpoint2.model.keras'\n","loaded_model = keras.models.load_model(model_file)\n","loaded_model.load_weights(checkpoint_filepath)\n","y_pred = loaded_model.predict(test_generator)"]},{"cell_type":"code","execution_count":null,"id":"1ec52882","metadata":{},"outputs":[],"source":["t2 = time.perf_counter()\n","print(f'Time for predicting {test_size} files: {np.round(t2-t1,3)} s.')"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":7469972,"sourceId":59093,"sourceType":"competition"},{"datasetId":4432380,"sourceId":7611741,"sourceType":"datasetVersion"},{"datasetId":4551183,"sourceId":7777833,"sourceType":"datasetVersion"}],"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":689.517384,"end_time":"2024-02-19T18:42:20.635927","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-02-19T18:30:51.118543","version":"2.5.0"}},"nbformat":4,"nbformat_minor":5}
