{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ce1a051",
   "metadata": {
    "papermill": {
     "duration": 0.006496,
     "end_time": "2024-03-10T18:18:35.037364",
     "exception": false,
     "start_time": "2024-03-10T18:18:35.030868",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CWT scalograms\n",
    "\n",
    "Use GPU T4 x 2  \n",
    "When using GP100, there are XLA errors.  \n",
    "\n",
    "5 channels (LT, RT, LP, RP, C).\n",
    "\n",
    "Implementing tf.keras.metrics.KLDivergence().\n",
    "\n",
    "- Definitions for scoring.\n",
    "- Training run.\n",
    "- Scoring locally.\n",
    "- Submit for LB scoring.\n",
    "\n",
    "Score uniform probabilities: 1.3718\n",
    "\n",
    "Final score: 0.57\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "913ff53c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T18:18:35.051156Z",
     "iopub.status.busy": "2024-03-10T18:18:35.050803Z",
     "iopub.status.idle": "2024-03-10T18:18:56.038746Z",
     "shell.execute_reply": "2024-03-10T18:18:56.037883Z"
    },
    "papermill": {
     "duration": 20.997387,
     "end_time": "2024-03-10T18:18:56.041272",
     "exception": false,
     "start_time": "2024-03-10T18:18:35.043885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-10 18:18:40.157168: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-10 18:18:40.157275: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-10 18:18:40.427383: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# base_dir = '../../kaggle_data/hms'\n",
    "# base_dir = '../../data/hms'\n",
    "base_dir = '/kaggle/input/hms-harmful-brain-activity-classification'\n",
    "\n",
    "# devset_dir = '../data'\n",
    "devset_dir = '/kaggle/input/hms-cwt-scalograms-single-numpy-v1'\n",
    "\n",
    "path_train = f'{devset_dir}/05_single_cwt_v1_train.npy'\n",
    "path_train_items = f'{devset_dir}/05_single_cwt_v1_train_items.npy'\n",
    "path_val = f'{devset_dir}/05_single_cwt_v1_val.npy'\n",
    "path_val_items = f'{devset_dir}/05_single_cwt_v1_val_items.npy'\n",
    "path_test = f'{devset_dir}/05_single_cwt_v1_test.npy'\n",
    "path_test_items = f'{devset_dir}/05_single_cwt_v1_test_items.npy'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51c686e",
   "metadata": {
    "papermill": {
     "duration": 0.005743,
     "end_time": "2024-03-10T18:18:56.053510",
     "exception": false,
     "start_time": "2024-03-10T18:18:56.047767",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Definitions\n",
    "\n",
    "For scoring without submitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50d3255f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T18:18:56.066780Z",
     "iopub.status.busy": "2024-03-10T18:18:56.066206Z",
     "iopub.status.idle": "2024-03-10T18:18:56.091997Z",
     "shell.execute_reply": "2024-03-10T18:18:56.091193Z"
    },
    "papermill": {
     "duration": 0.035051,
     "end_time": "2024-03-10T18:18:56.094159",
     "exception": false,
     "start_time": "2024-03-10T18:18:56.059108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas.api.types\n",
    "from typing import Union\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "class ParticipantVisibleError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class HostVisibleError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "def treat_as_participant_error(error_message: str, solution: Union[pd.DataFrame, np.ndarray]) -> bool:\n",
    "    ''' Many metrics can raise more errors than can be handled manually. This function attempts\n",
    "    to identify errors that can be treated as ParticipantVisibleError without leaking any competition data.\n",
    "\n",
    "    If the solution is purely numeric, and there are no numbers in the error message,\n",
    "    then the error message is sufficiently unlikely to leak usable data and can be shown to participants.\n",
    "\n",
    "    We expect this filter to reject many safe messages. It's intended only to reduce the number of errors we need to manage manually.\n",
    "    '''\n",
    "    # This check treats bools as numeric\n",
    "    if isinstance(solution, pd.DataFrame):\n",
    "        solution_is_all_numeric = all([pandas.api.types.is_numeric_dtype(x) for x in solution.dtypes.values])\n",
    "        solution_has_bools = any([pandas.api.types.is_bool_dtype(x) for x in solution.dtypes.values])\n",
    "    elif isinstance(solution, np.ndarray):\n",
    "        solution_is_all_numeric = pandas.api.types.is_numeric_dtype(solution)\n",
    "        solution_has_bools = pandas.api.types.is_bool_dtype(solution)\n",
    "\n",
    "    if not solution_is_all_numeric:\n",
    "        return False\n",
    "\n",
    "    for char in error_message:\n",
    "        if char.isnumeric():\n",
    "            return False\n",
    "    if solution_has_bools:\n",
    "        if 'true' in error_message.lower() or 'false' in error_message.lower():\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def safe_call_score(metric_function, solution, submission, **metric_func_kwargs):\n",
    "    '''\n",
    "    Call score. If that raises an error and that already been specifically handled, just raise it.\n",
    "    Otherwise make a conservative attempt to identify potential participant visible errors.\n",
    "    '''\n",
    "    try:\n",
    "        score_result = metric_function(solution, submission, **metric_func_kwargs)\n",
    "    except Exception as err:\n",
    "        error_message = str(err)\n",
    "        if err.__class__.__name__ == 'ParticipantVisibleError':\n",
    "            raise ParticipantVisibleError(error_message)\n",
    "        elif err.__class__.__name__ == 'HostVisibleError':\n",
    "            raise HostVisibleError(error_message)\n",
    "        else:\n",
    "            if treat_as_participant_error(error_message, solution):\n",
    "                raise ParticipantVisibleError(error_message)\n",
    "            else:\n",
    "                raise err\n",
    "    return score_result\n",
    "\n",
    "\n",
    "def verify_valid_probabilities(df: pd.DataFrame, df_name: str):\n",
    "    \"\"\" Verify that the dataframe contains valid probabilities.\n",
    "\n",
    "    The dataframe must be limited to the target columns; do not pass in any ID columns.\n",
    "    \"\"\"\n",
    "    if not pandas.api.types.is_numeric_dtype(df.values):\n",
    "        raise ParticipantVisibleError(f'All target values in {df_name} must be numeric')\n",
    "\n",
    "    if df.min().min() < 0:\n",
    "        raise ParticipantVisibleError(f'All target values in {df_name} must be at least zero')\n",
    "\n",
    "    if df.max().max() > 1:\n",
    "        raise ParticipantVisibleError(f'All target values in {df_name} must be no greater than one')\n",
    "\n",
    "    if not np.allclose(df.sum(axis=1), 1):\n",
    "        raise ParticipantVisibleError(f'Target values in {df_name} do not add to one within all rows')\n",
    "\n",
    "\n",
    "def kl_divergence(solution: pd.DataFrame, submission: pd.DataFrame, epsilon: float, micro_average: bool, sample_weights: Optional[pd.Series]):\n",
    "    # Overwrite solution for convenience\n",
    "    for col in solution.columns:\n",
    "        # Prevent issue with populating int columns with floats\n",
    "        if not pandas.api.types.is_float_dtype(solution[col]):\n",
    "            solution[col] = solution[col].astype(float)\n",
    "\n",
    "        # Clip both the min and max following Kaggle conventions for related metrics like log loss\n",
    "        # Clipping the max avoids cases where the loss would be infinite or undefined, clipping the min\n",
    "        # prevents users from playing games with the 20th decimal place of predictions.\n",
    "        submission[col] = np.clip(submission[col], epsilon, 1 - epsilon)\n",
    "\n",
    "        y_nonzero_indices = solution[col] != 0\n",
    "        solution[col] = solution[col].astype(float)\n",
    "        solution.loc[y_nonzero_indices, col] = solution.loc[y_nonzero_indices, col] * np.log(solution.loc[y_nonzero_indices, col] / submission.loc[y_nonzero_indices, col])\n",
    "        # Set the loss equal to zero where y_true equals zero following the scipy convention:\n",
    "        # https://docs.scipy.org/doc/scipy/reference/generated/scipy.special.rel_entr.html#scipy.special.rel_entr\n",
    "        solution.loc[~y_nonzero_indices, col] = 0\n",
    "\n",
    "    if micro_average:\n",
    "        return np.average(solution.sum(axis=1), weights=sample_weights)\n",
    "    else:\n",
    "        return np.average(solution.mean())\n",
    "\n",
    "def score(\n",
    "        solution: pd.DataFrame,\n",
    "        submission: pd.DataFrame,\n",
    "        row_id_column_name: str,\n",
    "        epsilon: float=10**-15,\n",
    "        micro_average: bool=True,\n",
    "        sample_weights_column_name: Optional[str]=None\n",
    "    ) -> float:\n",
    "    ''' The Kullback-Leibler divergence.\n",
    "    The KL divergence is technically undefined/infinite where the target equals zero.\n",
    "\n",
    "    This implementation always assigns those cases a score of zero; effectively removing them from consideration.\n",
    "    The predictions in each row must add to one so any probability assigned to a case where y == 0 reduces\n",
    "    another prediction where y > 0, so crucially there is an important indirect effect.\n",
    "\n",
    "    https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence\n",
    "\n",
    "    solution: pd.DataFrame\n",
    "    submission: pd.DataFrame\n",
    "    epsilon: KL divergence is undefined for p=0 or p=1. If epsilon is not null, solution and submission probabilities are clipped to max(eps, min(1 - eps, p).\n",
    "    row_id_column_name: str\n",
    "    micro_average: bool. Row-wise average if True, column-wise average if False.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> import pandas as pd\n",
    "    >>> row_id_column_name = \"id\"\n",
    "    >>> score(pd.DataFrame({'id': range(4), 'ham': [0, 1, 1, 0], 'spam': [1, 0, 0, 1]}), pd.DataFrame({'id': range(4), 'ham': [.1, .9, .8, .35], 'spam': [.9, .1, .2, .65]}), row_id_column_name=row_id_column_name)\n",
    "    0.216161...\n",
    "    >>> solution = pd.DataFrame({'id': range(3), 'ham': [0, 0.5, 0.5], 'spam': [0.1, 0.5, 0.5], 'other': [0.9, 0, 0]})\n",
    "    >>> submission = pd.DataFrame({'id': range(3), 'ham': [0, 0.5, 0.5], 'spam': [0.1, 0.5, 0.5], 'other': [0.9, 0, 0]})\n",
    "    >>> score(solution, submission, 'id')\n",
    "    0.0\n",
    "    >>> solution = pd.DataFrame({'id': range(3), 'ham': [0, 0.5, 0.5], 'spam': [0.1, 0.5, 0.5], 'other': [0.9, 0, 0]})\n",
    "    >>> submission = pd.DataFrame({'id': range(3), 'ham': [0.2, 0.3, 0.5], 'spam': [0.1, 0.5, 0.5], 'other': [0.7, 0.2, 0]})\n",
    "    >>> score(solution, submission, 'id')\n",
    "    0.160531...\n",
    "    '''\n",
    "    del solution[row_id_column_name]\n",
    "    del submission[row_id_column_name]\n",
    "\n",
    "    sample_weights = None\n",
    "    if sample_weights_column_name:\n",
    "        if sample_weights_column_name not in solution.columns:\n",
    "            raise ParticipantVisibleError(f'{sample_weights_column_name} not found in solution columns')\n",
    "        sample_weights = solution.pop(sample_weights_column_name)\n",
    "\n",
    "    if sample_weights_column_name and not micro_average:\n",
    "        raise ParticipantVisibleError('Sample weights are only valid if `micro_average` is `True`')\n",
    "\n",
    "    for col in solution.columns:\n",
    "        if col not in submission.columns:\n",
    "            raise ParticipantVisibleError(f'Missing submission column {col}')\n",
    "\n",
    "    verify_valid_probabilities(solution, 'solution')\n",
    "    verify_valid_probabilities(submission, 'submission')\n",
    "\n",
    "    return safe_call_score(kl_divergence, solution, submission, epsilon=epsilon, micro_average=micro_average, sample_weights=sample_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0cf1c6",
   "metadata": {
    "papermill": {
     "duration": 0.005678,
     "end_time": "2024-03-10T18:18:56.105732",
     "exception": false,
     "start_time": "2024-03-10T18:18:56.100054",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91fdf23d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T18:18:56.118838Z",
     "iopub.status.busy": "2024-03-10T18:18:56.118505Z",
     "iopub.status.idle": "2024-03-10T18:18:56.131377Z",
     "shell.execute_reply": "2024-03-10T18:18:56.130470Z"
    },
    "papermill": {
     "duration": 0.021808,
     "end_time": "2024-03-10T18:18:56.133354",
     "exception": false,
     "start_time": "2024-03-10T18:18:56.111546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Data generator using numpy and no pandas.\n",
    "#\n",
    "# scalograms\n",
    "# 30 seconds slice (I think)\n",
    "# 5 channels (LP, RP, LT, RP, C)\n",
    "#\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, path_to_items, path_to_data, batch_size=32, n_classes=6, shuffle=True):\n",
    "        ''' Initialization\n",
    "        item: [eeg_id, eeg_sub_id, idx in sgrams (1st index), target,\n",
    "        seizure_vote, lpd_vote, gpd_vote, lrda_vote,\n",
    "        grda_vote, other_vote]\n",
    "        '''\n",
    "        self.n_channels = 5\n",
    "        # self.n_freqs = 40\n",
    "\n",
    "        self.data = np.load(path_to_data)\n",
    "        self.items = np.load(path_to_items)\n",
    "        self.dim = (self.data.shape[1], self.data.shape[2])\n",
    "        self.batch_size = batch_size\n",
    "        self.len = self.data.shape[0]\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.ceil(self.len / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(indexes)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def get_dim(self):\n",
    "        'Dimensions for the input layer.'\n",
    "        return (self.dim[0], self.dim[1], self.n_channels)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(self.len)\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, indexes):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        true_size = len(indexes)\n",
    "        X = np.empty((true_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((true_size, self.n_classes), dtype=float)\n",
    "\n",
    "        # Generate data\n",
    "        for i, idx in enumerate(indexes):\n",
    "            item = self.items[idx]\n",
    "            # print(item)  # Uncomment for testing.\n",
    "            X[i,:,:,:] = self.data[np.int32(item[2]), :, :, :]\n",
    "            # Store solution\n",
    "            y[i,:] = item[-6:]\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "049d1a54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T18:18:56.146419Z",
     "iopub.status.busy": "2024-03-10T18:18:56.146114Z",
     "iopub.status.idle": "2024-03-10T18:18:56.154477Z",
     "shell.execute_reply": "2024-03-10T18:18:56.153798Z"
    },
    "papermill": {
     "duration": 0.016959,
     "end_time": "2024-03-10T18:18:56.156327",
     "exception": false,
     "start_time": "2024-03-10T18:18:56.139368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def make_model(input_shape, num_classes):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "\n",
    "    #max1 = keras.layers.MaxPooling1D(pool_size=2)(input_layer)\n",
    "    \n",
    "    conv1 = keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\")(input_layer)\n",
    "    #conv1 = keras.layers.BatchNormalization()(conv1)\n",
    "    # conv1 = keras.layers.MaxPooling2D(pool_size=8)(conv1)\n",
    "    conv1 = keras.layers.ReLU()(conv1)\n",
    "    \n",
    "    conv2 = keras.layers.Conv2D(filters=64, kernel_size=5, padding=\"same\")(conv1)\n",
    "    #conv2 = keras.layers.BatchNormalization()(conv2)\n",
    "    # conv2 = keras.layers.MaxPooling2D(pool_size=8)(conv2)\n",
    "    conv2 = keras.layers.ReLU()(conv2)\n",
    "\n",
    "    conv3 = keras.layers.Conv2D(filters=256, kernel_size=3, padding=\"same\")(conv2)\n",
    "    #conv3 = keras.layers.BatchNormalization()(conv3)\n",
    "    conv3 = keras.layers.MaxPooling2D(pool_size=2)(conv3)\n",
    "    conv3 = keras.layers.ReLU()(conv3)\n",
    "\n",
    "#     conv4 = keras.layers.Conv2D(filters=512, kernel_size=3, padding=\"same\")(conv3)\n",
    "#     conv4 = keras.layers.BatchNormalization()(conv4)\n",
    "#     conv4 = keras.layers.MaxPooling2D(pool_size=4)(conv4)\n",
    "#     conv4 = keras.layers.ReLU()(conv4)\n",
    "\n",
    "    fltn  = keras.layers.Flatten()(conv3) \n",
    "    \n",
    "    relu1 = keras.layers.Dense(128)(fltn)\n",
    "    relu1 = keras.layers.ReLU()(relu1)\n",
    "\n",
    "#     relu2 = keras.layers.Dense(64)(relu1)\n",
    "#     relu2 = keras.layers.ReLU(64)(relu2)\n",
    "\n",
    "#     lin = keras.layers.Dense(2)(relu2)\n",
    "\n",
    "    output_layer = keras.layers.Dense(num_classes, activation=\"softmax\")(relu1)\n",
    "\n",
    "    return keras.models.Model(inputs=input_layer, outputs=output_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94d7713a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T18:18:56.168383Z",
     "iopub.status.busy": "2024-03-10T18:18:56.168110Z",
     "iopub.status.idle": "2024-03-10T18:20:40.646261Z",
     "shell.execute_reply": "2024-03-10T18:20:40.645338Z"
    },
    "papermill": {
     "duration": 104.492282,
     "end_time": "2024-03-10T18:20:40.654131",
     "exception": false,
     "start_time": "2024-03-10T18:18:56.161849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations in training set: 12192\n",
      "Observations in validation set: 2176\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "params = {\n",
    "    'batch_size': 32,\n",
    "    'n_classes': 6,\n",
    "    'shuffle': True\n",
    "    }\n",
    "\n",
    "training_generator = DataGenerator(path_train_items, path_train , **params)\n",
    "validation_generator = DataGenerator(path_val_items, path_val, **params)\n",
    "\n",
    "print(\"Observations in training set:\", training_generator.__len__()*params['batch_size'])\n",
    "print(\"Observations in validation set:\", validation_generator.__len__()*params['batch_size'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a0e23ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T18:20:40.667070Z",
     "iopub.status.busy": "2024-03-10T18:20:40.666804Z",
     "iopub.status.idle": "2024-03-10T18:20:40.671134Z",
     "shell.execute_reply": "2024-03-10T18:20:40.670248Z"
    },
    "papermill": {
     "duration": 0.013241,
     "end_time": "2024-03-10T18:20:40.673351",
     "exception": false,
     "start_time": "2024-03-10T18:20:40.660110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint_filepath = 'checkpoint2.model.keras'\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='val_kl_divergence',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e85144a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T18:20:40.685912Z",
     "iopub.status.busy": "2024-03-10T18:20:40.685432Z",
     "iopub.status.idle": "2024-03-10T18:40:41.572648Z",
     "shell.execute_reply": "2024-03-10T18:40:41.571736Z"
    },
    "papermill": {
     "duration": 1200.89593,
     "end_time": "2024-03-10T18:40:41.574772",
     "exception": false,
     "start_time": "2024-03-10T18:20:40.678842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/381\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:11:27\u001b[0m 30s/step - kl_divergence: 0.0373 - loss: 0.0373"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1710094887.885214      74 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "W0000 00:00:1710094887.906206      74 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - kl_divergence: 0.0754 - loss: 0.0754"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1710094980.422426      74 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 276ms/step - kl_divergence: 0.0754 - loss: 0.0754 - val_kl_divergence: 0.6311 - val_loss: 0.6233\n",
      "Epoch 2/15\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 196ms/step - kl_divergence: 0.0502 - loss: 0.0503 - val_kl_divergence: 0.6588 - val_loss: 0.6506\n",
      "Epoch 3/15\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 196ms/step - kl_divergence: 0.0418 - loss: 0.0418 - val_kl_divergence: 0.6829 - val_loss: 0.6751\n",
      "Epoch 4/15\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 196ms/step - kl_divergence: 0.0443 - loss: 0.0443 - val_kl_divergence: 0.6666 - val_loss: 0.6802\n",
      "Epoch 5/15\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 196ms/step - kl_divergence: 0.0446 - loss: 0.0446 - val_kl_divergence: 0.7022 - val_loss: 0.6935\n",
      "Epoch 6/15\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 196ms/step - kl_divergence: 0.0462 - loss: 0.0462 - val_kl_divergence: 0.6773 - val_loss: 0.6709\n",
      "Epoch 7/15\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 196ms/step - kl_divergence: 0.0430 - loss: 0.0430 - val_kl_divergence: 0.6678 - val_loss: 0.6702\n",
      "Epoch 8/15\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 196ms/step - kl_divergence: 0.0443 - loss: 0.0443 - val_kl_divergence: 0.6611 - val_loss: 0.6735\n",
      "Epoch 9/15\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 196ms/step - kl_divergence: 0.0421 - loss: 0.0421 - val_kl_divergence: 0.6744 - val_loss: 0.6658\n",
      "Epoch 10/15\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 196ms/step - kl_divergence: 0.0412 - loss: 0.0412 - val_kl_divergence: 0.6756 - val_loss: 0.6674\n",
      "Epoch 11/15\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 196ms/step - kl_divergence: 0.0376 - loss: 0.0376 - val_kl_divergence: 0.6891 - val_loss: 0.6946\n",
      "Epoch 12/15\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 196ms/step - kl_divergence: 0.0352 - loss: 0.0352 - val_kl_divergence: 0.6807 - val_loss: 0.6761\n",
      "Epoch 13/15\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 196ms/step - kl_divergence: 0.0369 - loss: 0.0368 - val_kl_divergence: 0.6903 - val_loss: 0.7090\n",
      "Epoch 14/15\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 196ms/step - kl_divergence: 0.0359 - loss: 0.0359 - val_kl_divergence: 0.6719 - val_loss: 0.6772\n",
      "Epoch 15/15\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 196ms/step - kl_divergence: 0.0334 - loss: 0.0334 - val_kl_divergence: 0.6940 - val_loss: 0.7021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x78bf12962500>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = keras.optimizers.SGD(\n",
    "    learning_rate=0.007,\n",
    "    momentum=0.01,\n",
    ")\n",
    "\n",
    "# opt = keras.optimizers.Adam(\n",
    "#     learning_rate=0.004,\n",
    "# )\n",
    "\n",
    "dim = training_generator.get_dim()\n",
    "\n",
    "model = make_model(input_shape=dim, num_classes=6)\n",
    "\n",
    "model.load_weights('/kaggle/input/hms-model-cwt-v1/checkpoint.model.keras')\n",
    "\n",
    "model.compile(optimizer=opt,\n",
    "            loss=tf.keras.losses.KLDivergence(),\n",
    "            metrics=[tf.keras.metrics.KLDivergence()])\n",
    "\n",
    "model.fit(training_generator, epochs=15,\n",
    "          validation_data=validation_generator,\n",
    "          callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd3b32c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T18:40:42.669540Z",
     "iopub.status.busy": "2024-03-10T18:40:42.669185Z",
     "iopub.status.idle": "2024-03-10T18:40:49.407414Z",
     "shell.execute_reply": "2024-03-10T18:40:49.406476Z"
    },
    "papermill": {
     "duration": 7.278809,
     "end_time": "2024-03-10T18:40:49.410080",
     "exception": false,
     "start_time": "2024-03-10T18:40:42.131271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save(\"model_cwt_031001_057.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc12244e",
   "metadata": {
    "papermill": {
     "duration": 0.478171,
     "end_time": "2024-03-10T18:40:50.370123",
     "exception": false,
     "start_time": "2024-03-10T18:40:49.891952",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2668dfda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T18:40:51.394244Z",
     "iopub.status.busy": "2024-03-10T18:40:51.393492Z",
     "iopub.status.idle": "2024-03-10T18:40:51.400345Z",
     "shell.execute_reply": "2024-03-10T18:40:51.399372Z"
    },
    "papermill": {
     "duration": 0.544821,
     "end_time": "2024-03-10T18:40:51.402383",
     "exception": false,
     "start_time": "2024-03-10T18:40:50.857562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TARGETS = ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n",
    "\n",
    "# #\n",
    "# # Test Data generator: for predicting\n",
    "# # using own test set.\n",
    "# # (Not for predicting LB)\n",
    "# #\n",
    "\n",
    "# class TestDataGenerator(keras.utils.Sequence):\n",
    "#     'Generates data for Keras'\n",
    "#     def __init__(self, path_to_items, path_to_data, batch_size=32, n_classes=6, shuffle=False):\n",
    "#         ''' Initialization\n",
    "#         item: [eeg_id, eeg_sub_id, idx in sgrams (1st index), target,\n",
    "#         seizure_vote, lpd_vote, gpd_vote, lrda_vote,\n",
    "#         grda_vote, other_vote]\n",
    "#         '''\n",
    "#         self.n_channels = 5\n",
    "#         self.data = np.load(path_to_data)\n",
    "#         self.items = np.load(path_to_items)\n",
    "#         self.dim = (self.data.shape[1], self.data.shape[2])\n",
    "#         self.batch_size = batch_size\n",
    "#         self.len = self.data.shape[0]\n",
    "#         self.n_classes = n_classes\n",
    "#         self.shuffle = shuffle\n",
    "#         self.on_epoch_end()\n",
    "\n",
    "#     def __len__(self):\n",
    "#         'Denotes the number of batches per epoch'\n",
    "#         return int(np.ceil(self.len / self.batch_size))\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         'Generate one batch of data'\n",
    "#         # Generate indexes of the batch\n",
    "#         indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "#         # Generate data\n",
    "#         X = self.__data_generation(indexes)\n",
    "\n",
    "#         return X\n",
    "\n",
    "#     def get_dim(self):\n",
    "#         'Dimensions for the input layer.'\n",
    "#         return (self.dim[0], self.dim[1], self.n_channels)\n",
    "\n",
    "#     def on_epoch_end(self):\n",
    "#         'Updates indexes after each epoch'\n",
    "#         self.indexes = np.arange(self.len)\n",
    "#         # pass \n",
    "        \n",
    "#     def __data_generation(self, indexes):\n",
    "#         'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "#         # Initialization\n",
    "#         true_size = len(indexes)\n",
    "#         X = np.empty((true_size, *self.dim, self.n_channels))\n",
    "\n",
    "#         # Generate data\n",
    "#         for i, idx in enumerate(indexes):\n",
    "#             item = self.items[idx]\n",
    "#             # print(item)  # Uncomment for testing.\n",
    "#             X[i,:,:,:] = self.data[np.int32(item[2]), :, :, :]\n",
    "\n",
    "#         return X\n",
    "    \n",
    "                \n",
    "# params = {\n",
    "#     'batch_size': 32,\n",
    "#     'n_classes': 6,\n",
    "#     }\n",
    "\n",
    "# test_generator = TestDataGenerator(path_test_items, path_test, **params)\n",
    "\n",
    "# y_pred = model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1836d269",
   "metadata": {
    "papermill": {
     "duration": 0.480662,
     "end_time": "2024-03-10T18:40:52.363886",
     "exception": false,
     "start_time": "2024-03-10T18:40:51.883224",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Scoring without submission\n",
    "\n",
    "Using a local test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a79602d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T18:40:53.316543Z",
     "iopub.status.busy": "2024-03-10T18:40:53.315744Z",
     "iopub.status.idle": "2024-03-10T18:40:53.320351Z",
     "shell.execute_reply": "2024-03-10T18:40:53.319446Z"
    },
    "papermill": {
     "duration": 0.477216,
     "end_time": "2024-03-10T18:40:53.322237",
     "exception": false,
     "start_time": "2024-03-10T18:40:52.845021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_items = np.load(path_test_items)\n",
    "# # test_items = np.load(f'{devset_dir}/03_single_spectrograms_reduced_v1_test_items.npy')\n",
    "# df_test_items = pd.DataFrame(test_items)\n",
    "# df_test_items[0] = df_test_items[0].astype(int)\n",
    "\n",
    "# sub = pd.DataFrame({'eeg_id':df_test_items[0]})\n",
    "# sub[TARGETS] = np.round(y_pred,6)\n",
    "# sub.to_csv('submission.csv',index=False)\n",
    "\n",
    "# df_test_scoring = df_test_items[[0,4,5,6,7,8,9]]\n",
    "# df_test_scoring.columns = sub.columns\n",
    "# # df_test_scoring\n",
    "\n",
    "# score(df_test_scoring, sub, 'eeg_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e41d1d",
   "metadata": {
    "papermill": {
     "duration": 0.551778,
     "end_time": "2024-03-10T18:40:54.415932",
     "exception": false,
     "start_time": "2024-03-10T18:40:53.864154",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Uniform probabilities classificator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdcd8ffb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T18:40:55.437526Z",
     "iopub.status.busy": "2024-03-10T18:40:55.437122Z",
     "iopub.status.idle": "2024-03-10T18:40:55.441857Z",
     "shell.execute_reply": "2024-03-10T18:40:55.440875Z"
    },
    "papermill": {
     "duration": 0.497398,
     "end_time": "2024-03-10T18:40:55.444381",
     "exception": false,
     "start_time": "2024-03-10T18:40:54.946983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_npy = np.load(path_test)\n",
    "# test_items = np.load(path_test_items)\n",
    "\n",
    "# y_pred = np.ones((test_items.shape[0],6),dtype=float)\n",
    "# y_pred[:,0:4] = y_pred[:,0:4] * 0.167\n",
    "# y_pred[:,4:] = y_pred[:,4:] * 0.166\n",
    "\n",
    "# df_test_items = pd.DataFrame(test_items)\n",
    "# df_test_items[0] = df_test_items[0].astype(int)\n",
    "\n",
    "# sub = pd.DataFrame({'eeg_id':df_test_items[0]})\n",
    "# sub[TARGETS] = np.round(y_pred,6)\n",
    "# # sub.to_csv('submission.csv',index=False)\n",
    "\n",
    "# df_test_scoring = df_test_items[[0,4,5,6,7,8,9]]\n",
    "# df_test_scoring.columns = sub.columns\n",
    "\n",
    "# score(df_test_scoring, sub, 'eeg_id')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1377c5",
   "metadata": {
    "papermill": {
     "duration": 0.522395,
     "end_time": "2024-03-10T18:40:56.447174",
     "exception": false,
     "start_time": "2024-03-10T18:40:55.924779",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submit to LB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6fef7d",
   "metadata": {
    "papermill": {
     "duration": 0.476047,
     "end_time": "2024-03-10T18:40:57.413213",
     "exception": false,
     "start_time": "2024-03-10T18:40:56.937166",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 7469972,
     "sourceId": 59093,
     "sourceType": "competition"
    },
    {
     "datasetId": 4432380,
     "sourceId": 7611741,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4551183,
     "sourceId": 7777833,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4573788,
     "sourceId": 7809333,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1350.918643,
   "end_time": "2024-03-10T18:41:01.896576",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-10T18:18:30.977933",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
