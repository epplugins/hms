{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":59093,"databundleVersionId":7469972,"sourceType":"competition"},{"sourceId":7611741,"sourceType":"datasetVersion","datasetId":4432380},{"sourceId":7777833,"sourceType":"datasetVersion","datasetId":4551183}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"papermill":{"default_parameters":{},"duration":689.517384,"end_time":"2024-02-19T18:42:20.635927","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-02-19T18:30:51.118543","version":"2.5.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# CWT scalograms\n\n5 channels (LT, RT, LP, RP, C).\n\nImplementing tf.keras.metrics.KLDivergence().\n\n- Definitions for scoring.\n- Training run.\n- Scoring locally.\n- Submit for LB scoring.\n\nScore uniform probabilities: 1.3718\n\nFinal score: 0.57\n","metadata":{"papermill":{"duration":0.004896,"end_time":"2024-02-19T18:30:53.912637","exception":false,"start_time":"2024-02-19T18:30:53.907741","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport keras\nfrom keras import regularizers\nimport matplotlib.pyplot as plt\n\n# base_dir = '../../kaggle_data/hms'\n# base_dir = '../../data/hms'\nbase_dir = '/kaggle/input/hms-harmful-brain-activity-classification'\n\n# devset_dir = '../data'\ndevset_dir = '/kaggle/input/hms-cwt-scalograms-single-numpy-v1'\n\npath_train = f'{devset_dir}/05_single_cwt_v1_train.npy'\npath_train_items = f'{devset_dir}/05_single_cwt_v1_train_items.npy'\npath_val = f'{devset_dir}/05_single_cwt_v1_val.npy'\npath_val_items = f'{devset_dir}/05_single_cwt_v1_val_items.npy'\npath_test = f'{devset_dir}/05_single_cwt_v1_test.npy'\npath_test_items = f'{devset_dir}/05_single_cwt_v1_test_items.npy'","metadata":{"papermill":{"duration":13.003552,"end_time":"2024-02-19T18:31:06.921234","exception":false,"start_time":"2024-02-19T18:30:53.917682","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-03-10T07:06:00.759818Z","iopub.execute_input":"2024-03-10T07:06:00.760960Z","iopub.status.idle":"2024-03-10T07:06:15.550345Z","shell.execute_reply.started":"2024-03-10T07:06:00.760919Z","shell.execute_reply":"2024-03-10T07:06:15.549386Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-03-10 07:06:04.236886: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-10 07:06:04.237012: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-10 07:06:04.424789: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Definitions\n\nFor scoring without submitting.","metadata":{"papermill":{"duration":0.005501,"end_time":"2024-02-19T18:31:06.932688","exception":false,"start_time":"2024-02-19T18:31:06.927187","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import pandas.api.types\nfrom typing import Union\nfrom typing import Optional\n\n\nclass ParticipantVisibleError(Exception):\n    pass\n\n\nclass HostVisibleError(Exception):\n    pass\n\n\ndef treat_as_participant_error(error_message: str, solution: Union[pd.DataFrame, np.ndarray]) -> bool:\n    ''' Many metrics can raise more errors than can be handled manually. This function attempts\n    to identify errors that can be treated as ParticipantVisibleError without leaking any competition data.\n\n    If the solution is purely numeric, and there are no numbers in the error message,\n    then the error message is sufficiently unlikely to leak usable data and can be shown to participants.\n\n    We expect this filter to reject many safe messages. It's intended only to reduce the number of errors we need to manage manually.\n    '''\n    # This check treats bools as numeric\n    if isinstance(solution, pd.DataFrame):\n        solution_is_all_numeric = all([pandas.api.types.is_numeric_dtype(x) for x in solution.dtypes.values])\n        solution_has_bools = any([pandas.api.types.is_bool_dtype(x) for x in solution.dtypes.values])\n    elif isinstance(solution, np.ndarray):\n        solution_is_all_numeric = pandas.api.types.is_numeric_dtype(solution)\n        solution_has_bools = pandas.api.types.is_bool_dtype(solution)\n\n    if not solution_is_all_numeric:\n        return False\n\n    for char in error_message:\n        if char.isnumeric():\n            return False\n    if solution_has_bools:\n        if 'true' in error_message.lower() or 'false' in error_message.lower():\n            return False\n    return True\n\n\ndef safe_call_score(metric_function, solution, submission, **metric_func_kwargs):\n    '''\n    Call score. If that raises an error and that already been specifically handled, just raise it.\n    Otherwise make a conservative attempt to identify potential participant visible errors.\n    '''\n    try:\n        score_result = metric_function(solution, submission, **metric_func_kwargs)\n    except Exception as err:\n        error_message = str(err)\n        if err.__class__.__name__ == 'ParticipantVisibleError':\n            raise ParticipantVisibleError(error_message)\n        elif err.__class__.__name__ == 'HostVisibleError':\n            raise HostVisibleError(error_message)\n        else:\n            if treat_as_participant_error(error_message, solution):\n                raise ParticipantVisibleError(error_message)\n            else:\n                raise err\n    return score_result\n\n\ndef verify_valid_probabilities(df: pd.DataFrame, df_name: str):\n    \"\"\" Verify that the dataframe contains valid probabilities.\n\n    The dataframe must be limited to the target columns; do not pass in any ID columns.\n    \"\"\"\n    if not pandas.api.types.is_numeric_dtype(df.values):\n        raise ParticipantVisibleError(f'All target values in {df_name} must be numeric')\n\n    if df.min().min() < 0:\n        raise ParticipantVisibleError(f'All target values in {df_name} must be at least zero')\n\n    if df.max().max() > 1:\n        raise ParticipantVisibleError(f'All target values in {df_name} must be no greater than one')\n\n    if not np.allclose(df.sum(axis=1), 1):\n        raise ParticipantVisibleError(f'Target values in {df_name} do not add to one within all rows')\n\n\ndef kl_divergence(solution: pd.DataFrame, submission: pd.DataFrame, epsilon: float, micro_average: bool, sample_weights: Optional[pd.Series]):\n    # Overwrite solution for convenience\n    for col in solution.columns:\n        # Prevent issue with populating int columns with floats\n        if not pandas.api.types.is_float_dtype(solution[col]):\n            solution[col] = solution[col].astype(float)\n\n        # Clip both the min and max following Kaggle conventions for related metrics like log loss\n        # Clipping the max avoids cases where the loss would be infinite or undefined, clipping the min\n        # prevents users from playing games with the 20th decimal place of predictions.\n        submission[col] = np.clip(submission[col], epsilon, 1 - epsilon)\n\n        y_nonzero_indices = solution[col] != 0\n        solution[col] = solution[col].astype(float)\n        solution.loc[y_nonzero_indices, col] = solution.loc[y_nonzero_indices, col] * np.log(solution.loc[y_nonzero_indices, col] / submission.loc[y_nonzero_indices, col])\n        # Set the loss equal to zero where y_true equals zero following the scipy convention:\n        # https://docs.scipy.org/doc/scipy/reference/generated/scipy.special.rel_entr.html#scipy.special.rel_entr\n        solution.loc[~y_nonzero_indices, col] = 0\n\n    if micro_average:\n        return np.average(solution.sum(axis=1), weights=sample_weights)\n    else:\n        return np.average(solution.mean())\n\ndef score(\n        solution: pd.DataFrame,\n        submission: pd.DataFrame,\n        row_id_column_name: str,\n        epsilon: float=10**-15,\n        micro_average: bool=True,\n        sample_weights_column_name: Optional[str]=None\n    ) -> float:\n    ''' The Kullback-Leibler divergence.\n    The KL divergence is technically undefined/infinite where the target equals zero.\n\n    This implementation always assigns those cases a score of zero; effectively removing them from consideration.\n    The predictions in each row must add to one so any probability assigned to a case where y == 0 reduces\n    another prediction where y > 0, so crucially there is an important indirect effect.\n\n    https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence\n\n    solution: pd.DataFrame\n    submission: pd.DataFrame\n    epsilon: KL divergence is undefined for p=0 or p=1. If epsilon is not null, solution and submission probabilities are clipped to max(eps, min(1 - eps, p).\n    row_id_column_name: str\n    micro_average: bool. Row-wise average if True, column-wise average if False.\n\n    Examples\n    --------\n    >>> import pandas as pd\n    >>> row_id_column_name = \"id\"\n    >>> score(pd.DataFrame({'id': range(4), 'ham': [0, 1, 1, 0], 'spam': [1, 0, 0, 1]}), pd.DataFrame({'id': range(4), 'ham': [.1, .9, .8, .35], 'spam': [.9, .1, .2, .65]}), row_id_column_name=row_id_column_name)\n    0.216161...\n    >>> solution = pd.DataFrame({'id': range(3), 'ham': [0, 0.5, 0.5], 'spam': [0.1, 0.5, 0.5], 'other': [0.9, 0, 0]})\n    >>> submission = pd.DataFrame({'id': range(3), 'ham': [0, 0.5, 0.5], 'spam': [0.1, 0.5, 0.5], 'other': [0.9, 0, 0]})\n    >>> score(solution, submission, 'id')\n    0.0\n    >>> solution = pd.DataFrame({'id': range(3), 'ham': [0, 0.5, 0.5], 'spam': [0.1, 0.5, 0.5], 'other': [0.9, 0, 0]})\n    >>> submission = pd.DataFrame({'id': range(3), 'ham': [0.2, 0.3, 0.5], 'spam': [0.1, 0.5, 0.5], 'other': [0.7, 0.2, 0]})\n    >>> score(solution, submission, 'id')\n    0.160531...\n    '''\n    del solution[row_id_column_name]\n    del submission[row_id_column_name]\n\n    sample_weights = None\n    if sample_weights_column_name:\n        if sample_weights_column_name not in solution.columns:\n            raise ParticipantVisibleError(f'{sample_weights_column_name} not found in solution columns')\n        sample_weights = solution.pop(sample_weights_column_name)\n\n    if sample_weights_column_name and not micro_average:\n        raise ParticipantVisibleError('Sample weights are only valid if `micro_average` is `True`')\n\n    for col in solution.columns:\n        if col not in submission.columns:\n            raise ParticipantVisibleError(f'Missing submission column {col}')\n\n    verify_valid_probabilities(solution, 'solution')\n    verify_valid_probabilities(submission, 'submission')\n\n    return safe_call_score(kl_divergence, solution, submission, epsilon=epsilon, micro_average=micro_average, sample_weights=sample_weights)\n","metadata":{"papermill":{"duration":0.037218,"end_time":"2024-02-19T18:31:06.975770","exception":false,"start_time":"2024-02-19T18:31:06.938552","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-03-10T07:06:21.551597Z","iopub.execute_input":"2024-03-10T07:06:21.552228Z","iopub.status.idle":"2024-03-10T07:06:21.579321Z","shell.execute_reply.started":"2024-03-10T07:06:21.552197Z","shell.execute_reply":"2024-03-10T07:06:21.578289Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Train","metadata":{"papermill":{"duration":0.004653,"end_time":"2024-02-19T18:31:07.002231","exception":false,"start_time":"2024-02-19T18:31:06.997578","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#\n# Data generator using numpy and no pandas.\n#\n# scalograms\n# 30 seconds slice (I think)\n# 5 channels (LP, RP, LT, RP, C)\n#\n\nclass DataGenerator(keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, path_to_items, path_to_data, batch_size=32, n_classes=6, shuffle=True):\n        ''' Initialization\n        item: [eeg_id, eeg_sub_id, idx in sgrams (1st index), target,\n        seizure_vote, lpd_vote, gpd_vote, lrda_vote,\n        grda_vote, other_vote]\n        '''\n        self.n_channels = 5\n        # self.n_freqs = 40\n\n        self.data = np.load(path_to_data)\n        self.items = np.load(path_to_items)\n        self.dim = (self.data.shape[1], self.data.shape[2])\n        self.batch_size = batch_size\n        self.len = self.data.shape[0]\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.ceil(self.len / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Generate data\n        X, y = self.__data_generation(indexes)\n\n        return X, y\n\n    def get_dim(self):\n        'Dimensions for the input layer.'\n        return (self.dim[0], self.dim[1], self.n_channels)\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(self.len)\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, indexes):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        true_size = len(indexes)\n        X = np.empty((true_size, *self.dim, self.n_channels))\n        y = np.empty((true_size, self.n_classes), dtype=float)\n\n        # Generate data\n        for i, idx in enumerate(indexes):\n            item = self.items[idx]\n            # print(item)  # Uncomment for testing.\n            X[i,:,:,:] = self.data[np.int32(item[2]), :, :, :]\n            # Store solution\n            y[i,:] = item[-6:]\n\n        return X, y","metadata":{"papermill":{"duration":0.020601,"end_time":"2024-02-19T18:31:07.027552","exception":false,"start_time":"2024-02-19T18:31:07.006951","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-03-10T07:06:25.215125Z","iopub.execute_input":"2024-03-10T07:06:25.215496Z","iopub.status.idle":"2024-03-10T07:06:25.230010Z","shell.execute_reply.started":"2024-03-10T07:06:25.215465Z","shell.execute_reply":"2024-03-10T07:06:25.229167Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"\ndef make_model(input_shape, num_classes):\n    input_layer = keras.layers.Input(input_shape)\n\n    #max1 = keras.layers.MaxPooling1D(pool_size=2)(input_layer)\n    \n    conv1 = keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\")(input_layer)\n    #conv1 = keras.layers.BatchNormalization()(conv1)\n    # conv1 = keras.layers.MaxPooling2D(pool_size=8)(conv1)\n    conv1 = keras.layers.ReLU()(conv1)\n    \n    conv2 = keras.layers.Conv2D(filters=64, kernel_size=5, padding=\"same\")(conv1)\n    #conv2 = keras.layers.BatchNormalization()(conv2)\n    # conv2 = keras.layers.MaxPooling2D(pool_size=8)(conv2)\n    conv2 = keras.layers.ReLU()(conv2)\n\n    conv3 = keras.layers.Conv2D(filters=256, kernel_size=3, padding=\"same\")(conv2)\n    #conv3 = keras.layers.BatchNormalization()(conv3)\n    conv3 = keras.layers.MaxPooling2D(pool_size=2)(conv3)\n    conv3 = keras.layers.ReLU()(conv3)\n\n#     conv4 = keras.layers.Conv2D(filters=512, kernel_size=3, padding=\"same\")(conv3)\n#     conv4 = keras.layers.BatchNormalization()(conv4)\n#     conv4 = keras.layers.MaxPooling2D(pool_size=4)(conv4)\n#     conv4 = keras.layers.ReLU()(conv4)\n\n    fltn  = keras.layers.Flatten()(conv3) \n    \n    relu1 = keras.layers.Dense(128)(fltn)\n    relu1 = keras.layers.ReLU()(relu1)\n\n#     relu2 = keras.layers.Dense(64)(relu1)\n#     relu2 = keras.layers.ReLU(64)(relu2)\n\n#     lin = keras.layers.Dense(2)(relu2)\n\n    output_layer = keras.layers.Dense(num_classes, activation=\"softmax\")(relu1)\n\n    return keras.models.Model(inputs=input_layer, outputs=output_layer)\n","metadata":{"papermill":{"duration":0.018651,"end_time":"2024-02-19T18:31:07.051182","exception":false,"start_time":"2024-02-19T18:31:07.032531","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-03-10T07:06:27.182970Z","iopub.execute_input":"2024-03-10T07:06:27.183596Z","iopub.status.idle":"2024-03-10T07:06:27.192900Z","shell.execute_reply.started":"2024-03-10T07:06:27.183567Z","shell.execute_reply":"2024-03-10T07:06:27.191728Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Parameters\nparams = {\n    'batch_size': 32,\n    'n_classes': 6,\n    'shuffle': True\n    }\n\ntraining_generator = DataGenerator(path_train_items, path_train , **params)\nvalidation_generator = DataGenerator(path_val_items, path_val, **params)\n\nprint(\"Observations in training set:\", training_generator.__len__()*params['batch_size'])\nprint(\"Observations in validation set:\", validation_generator.__len__()*params['batch_size'])\n","metadata":{"papermill":{"duration":32.97052,"end_time":"2024-02-19T18:31:40.026924","exception":false,"start_time":"2024-02-19T18:31:07.056404","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-03-10T07:06:28.672404Z","iopub.execute_input":"2024-03-10T07:06:28.672827Z","iopub.status.idle":"2024-03-10T07:08:19.936479Z","shell.execute_reply.started":"2024-03-10T07:06:28.672793Z","shell.execute_reply":"2024-03-10T07:08:19.935520Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Observations in training set: 12192\nObservations in validation set: 2176\n","output_type":"stream"}]},{"cell_type":"code","source":"checkpoint_filepath = 'checkpoint.model.keras'\nmodel_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    monitor='val_kl_divergence',\n    mode='min',\n    save_best_only=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-10T07:08:38.163234Z","iopub.execute_input":"2024-03-10T07:08:38.163614Z","iopub.status.idle":"2024-03-10T07:08:38.168670Z","shell.execute_reply.started":"2024-03-10T07:08:38.163583Z","shell.execute_reply":"2024-03-10T07:08:38.167685Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# opt = keras.optimizers.SGD(\n#     learning_rate=0.005,\n#     momentum=0.00,\n# )\n\nopt = keras.optimizers.Adam(\n    learning_rate=0.005,\n)\n\ndim = training_generator.get_dim()\n\nmodel = make_model(input_shape=dim, num_classes=6)\n\n# model.load_weights(checkpoint_filepath)\n\nmodel.compile(optimizer=opt,\n            loss=tf.keras.losses.KLDivergence(),\n            metrics=[tf.keras.metrics.KLDivergence()])\n\nmodel.fit(training_generator, epochs=5,\n          validation_data=validation_generator,\n          callbacks=[model_checkpoint_callback])","metadata":{"papermill":{"duration":623.197335,"end_time":"2024-02-19T18:42:03.228965","exception":false,"start_time":"2024-02-19T18:31:40.031630","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-03-10T07:08:43.112464Z","iopub.execute_input":"2024-03-10T07:08:43.112933Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  1/381\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:10:27\u001b[0m 30s/step - kl_divergence: 1.2491 - loss: 1.2491","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1710054553.910516     109 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\nW0000 00:00:1710054553.927697     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - kl_divergence: 12.0517 - loss: 12.0520","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1710054656.031345     108 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 307ms/step - kl_divergence: 12.0520 - loss: 12.0523 - val_kl_divergence: 13.1665 - val_loss: 13.1825\nEpoch 2/5\n\u001b[1m  1/381\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:06:20\u001b[0m 58s/step - kl_divergence: 11.8154 - loss: 11.8154","output_type":"stream"}]},{"cell_type":"code","source":"model.save(\"model_cwt_057.keras\")","metadata":{"execution":{"iopub.status.busy":"2024-03-10T06:21:25.383695Z","iopub.execute_input":"2024-03-10T06:21:25.384084Z","iopub.status.idle":"2024-03-10T06:21:28.223154Z","shell.execute_reply.started":"2024-03-10T06:21:25.384055Z","shell.execute_reply":"2024-03-10T06:21:28.222172Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Score","metadata":{"papermill":{"duration":0.106847,"end_time":"2024-02-19T18:42:03.442617","exception":false,"start_time":"2024-02-19T18:42:03.335770","status":"completed"},"tags":[]}},{"cell_type":"code","source":"TARGETS = ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n\n#\n# Test Data generator: for predicting\n# using own test set.\n# (Not for predicting LB)\n#\n\nclass TestDataGenerator(keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, path_to_items, path_to_data, batch_size=32, n_classes=6, shuffle=False):\n        ''' Initialization\n        item: [eeg_id, eeg_sub_id, idx in sgrams (1st index), target,\n        seizure_vote, lpd_vote, gpd_vote, lrda_vote,\n        grda_vote, other_vote]\n        '''\n        self.n_channels = 5\n        self.data = np.load(path_to_data)\n        self.items = np.load(path_to_items)\n        self.dim = (self.data.shape[1], self.data.shape[2])\n        self.batch_size = batch_size\n        self.len = self.data.shape[0]\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.ceil(self.len / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Generate data\n        X = self.__data_generation(indexes)\n\n        return X\n\n    def get_dim(self):\n        'Dimensions for the input layer.'\n        return (self.dim[0], self.dim[1], self.n_channels)\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(self.len)\n        # pass \n        \n    def __data_generation(self, indexes):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        true_size = len(indexes)\n        X = np.empty((true_size, *self.dim, self.n_channels))\n\n        # Generate data\n        for i, idx in enumerate(indexes):\n            item = self.items[idx]\n            # print(item)  # Uncomment for testing.\n            X[i,:,:,:] = self.data[np.int32(item[2]), :, :, :]\n\n        return X\n    \n                \nparams = {\n    'batch_size': 32,\n    'n_classes': 6,\n    }\n\ntest_generator = TestDataGenerator(path_test_items, path_test, **params)\n\ny_pred = model.predict(test_generator)","metadata":{"papermill":{"duration":13.970827,"end_time":"2024-02-19T18:42:17.520255","exception":false,"start_time":"2024-02-19T18:42:03.549428","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-03-10T06:19:08.979255Z","iopub.execute_input":"2024-03-10T06:19:08.981578Z","iopub.status.idle":"2024-03-10T06:19:19.121274Z","shell.execute_reply.started":"2024-03-10T06:19:08.981542Z","shell.execute_reply":"2024-03-10T06:19:19.120483Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Scoring without submission\n\nUsing a local test set.","metadata":{"papermill":{"duration":0.112005,"end_time":"2024-02-19T18:42:17.746564","exception":false,"start_time":"2024-02-19T18:42:17.634559","status":"completed"},"tags":[]}},{"cell_type":"code","source":"test_items = np.load(path_test_items)\n# test_items = np.load(f'{devset_dir}/03_single_spectrograms_reduced_v1_test_items.npy')\ndf_test_items = pd.DataFrame(test_items)\ndf_test_items[0] = df_test_items[0].astype(int)\n\nsub = pd.DataFrame({'eeg_id':df_test_items[0]})\nsub[TARGETS] = np.round(y_pred,6)\nsub.to_csv('submission.csv',index=False)\n\ndf_test_scoring = df_test_items[[0,4,5,6,7,8,9]]\ndf_test_scoring.columns = sub.columns\n# df_test_scoring\n\nscore(df_test_scoring, sub, 'eeg_id')","metadata":{"papermill":{"duration":0.187177,"end_time":"2024-02-19T18:42:18.046703","exception":false,"start_time":"2024-02-19T18:42:17.859526","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-03-10T06:19:22.938005Z","iopub.execute_input":"2024-03-10T06:19:22.938730Z","iopub.status.idle":"2024-03-10T06:19:22.994877Z","shell.execute_reply.started":"2024-03-10T06:19:22.938690Z","shell.execute_reply":"2024-03-10T06:19:22.993956Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_1321/1435129968.py:95: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  solution[col] = solution[col].astype(float)\n/tmp/ipykernel_1321/1435129968.py:95: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  solution[col] = solution[col].astype(float)\n/tmp/ipykernel_1321/1435129968.py:95: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  solution[col] = solution[col].astype(float)\n/tmp/ipykernel_1321/1435129968.py:95: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  solution[col] = solution[col].astype(float)\n/tmp/ipykernel_1321/1435129968.py:95: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  solution[col] = solution[col].astype(float)\n/tmp/ipykernel_1321/1435129968.py:95: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  solution[col] = solution[col].astype(float)\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"0.5706095955828902"},"metadata":{}}]},{"cell_type":"markdown","source":"# Uniform probabilities classificator","metadata":{}},{"cell_type":"code","source":"# test_npy = np.load(path_test)\n# test_items = np.load(path_test_items)\n\n# y_pred = np.ones((test_items.shape[0],6),dtype=float)\n# y_pred[:,0:4] = y_pred[:,0:4] * 0.167\n# y_pred[:,4:] = y_pred[:,4:] * 0.166\n\n# df_test_items = pd.DataFrame(test_items)\n# df_test_items[0] = df_test_items[0].astype(int)\n\n# sub = pd.DataFrame({'eeg_id':df_test_items[0]})\n# sub[TARGETS] = np.round(y_pred,6)\n# # sub.to_csv('submission.csv',index=False)\n\n# df_test_scoring = df_test_items[[0,4,5,6,7,8,9]]\n# df_test_scoring.columns = sub.columns\n\n# score(df_test_scoring, sub, 'eeg_id')\n","metadata":{"execution":{"iopub.status.busy":"2024-03-09T18:33:20.292491Z","iopub.execute_input":"2024-03-09T18:33:20.292858Z","iopub.status.idle":"2024-03-09T18:33:21.380048Z","shell.execute_reply.started":"2024-03-09T18:33:20.292827Z","shell.execute_reply":"2024-03-09T18:33:21.379248Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_33/1435129968.py:95: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  solution[col] = solution[col].astype(float)\n/tmp/ipykernel_33/1435129968.py:95: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  solution[col] = solution[col].astype(float)\n/tmp/ipykernel_33/1435129968.py:95: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  solution[col] = solution[col].astype(float)\n/tmp/ipykernel_33/1435129968.py:95: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  solution[col] = solution[col].astype(float)\n/tmp/ipykernel_33/1435129968.py:95: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  solution[col] = solution[col].astype(float)\n/tmp/ipykernel_33/1435129968.py:95: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  solution[col] = solution[col].astype(float)\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"1.3718073504111403"},"metadata":{}}]},{"cell_type":"markdown","source":"# Submit to LB","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}}]}