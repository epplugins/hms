{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run VK1\n",
    "\n",
    "**Download Kaggle version**\n",
    "\n",
    "Spectrograms of F3 and F4 in two channels.\n",
    "\n",
    "- Definitions for scoring.\n",
    "- Training run.\n",
    "- Scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "base_dir = '../../kaggle_data/hms'\n",
    "# base_dir = '../../data/hms'\n",
    "# base_dir = '/kaggle/input/hms-harmful-brain-activity-classification'\n",
    "\n",
    "devset_dir = '../data'\n",
    "\n",
    "# path_train = f'{devset_dir}/03_single_spectrograms_v1_train.npy'\n",
    "# path_train_items = f'{devset_dir}/03_single_spectrograms_v1_train_items.npy'\n",
    "# path_val = f'{devset_dir}/03_single_spectrograms_v1_val.npy'\n",
    "# path_val_items = f'{devset_dir}/03_single_spectrograms_v1_val_items.npy'\n",
    "# path_test = f'{devset_dir}/03_single_spectrograms_v1_test.npy'\n",
    "# path_test_items = f'{devset_dir}/03_single_spectrograms_v1_test_items.npy'\n",
    "\n",
    "path_train = f'{devset_dir}/03_single_spectrograms_reduced_v1_train.npy'\n",
    "path_train_items = f'{devset_dir}/03_single_spectrograms_reduced_v1_train_items.npy'\n",
    "path_val = f'{devset_dir}/03_single_spectrograms_reduced_v1_val.npy'\n",
    "path_val_items = f'{devset_dir}/03_single_spectrograms_reduced_v1_val_items.npy'\n",
    "path_test = f'{devset_dir}/03_single_spectrograms_reduced_v1_test.npy'\n",
    "path_test_items = f'{devset_dir}/03_single_spectrograms_reduced_v1_test_items.npy'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas.api.types\n",
    "from typing import Union\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "class ParticipantVisibleError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class HostVisibleError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "def treat_as_participant_error(error_message: str, solution: Union[pd.DataFrame, np.ndarray]) -> bool:\n",
    "    ''' Many metrics can raise more errors than can be handled manually. This function attempts\n",
    "    to identify errors that can be treated as ParticipantVisibleError without leaking any competition data.\n",
    "\n",
    "    If the solution is purely numeric, and there are no numbers in the error message,\n",
    "    then the error message is sufficiently unlikely to leak usable data and can be shown to participants.\n",
    "\n",
    "    We expect this filter to reject many safe messages. It's intended only to reduce the number of errors we need to manage manually.\n",
    "    '''\n",
    "    # This check treats bools as numeric\n",
    "    if isinstance(solution, pd.DataFrame):\n",
    "        solution_is_all_numeric = all([pandas.api.types.is_numeric_dtype(x) for x in solution.dtypes.values])\n",
    "        solution_has_bools = any([pandas.api.types.is_bool_dtype(x) for x in solution.dtypes.values])\n",
    "    elif isinstance(solution, np.ndarray):\n",
    "        solution_is_all_numeric = pandas.api.types.is_numeric_dtype(solution)\n",
    "        solution_has_bools = pandas.api.types.is_bool_dtype(solution)\n",
    "\n",
    "    if not solution_is_all_numeric:\n",
    "        return False\n",
    "\n",
    "    for char in error_message:\n",
    "        if char.isnumeric():\n",
    "            return False\n",
    "    if solution_has_bools:\n",
    "        if 'true' in error_message.lower() or 'false' in error_message.lower():\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def safe_call_score(metric_function, solution, submission, **metric_func_kwargs):\n",
    "    '''\n",
    "    Call score. If that raises an error and that already been specifically handled, just raise it.\n",
    "    Otherwise make a conservative attempt to identify potential participant visible errors.\n",
    "    '''\n",
    "    try:\n",
    "        score_result = metric_function(solution, submission, **metric_func_kwargs)\n",
    "    except Exception as err:\n",
    "        error_message = str(err)\n",
    "        if err.__class__.__name__ == 'ParticipantVisibleError':\n",
    "            raise ParticipantVisibleError(error_message)\n",
    "        elif err.__class__.__name__ == 'HostVisibleError':\n",
    "            raise HostVisibleError(error_message)\n",
    "        else:\n",
    "            if treat_as_participant_error(error_message, solution):\n",
    "                raise ParticipantVisibleError(error_message)\n",
    "            else:\n",
    "                raise err\n",
    "    return score_result\n",
    "\n",
    "\n",
    "def verify_valid_probabilities(df: pd.DataFrame, df_name: str):\n",
    "    \"\"\" Verify that the dataframe contains valid probabilities.\n",
    "\n",
    "    The dataframe must be limited to the target columns; do not pass in any ID columns.\n",
    "    \"\"\"\n",
    "    if not pandas.api.types.is_numeric_dtype(df.values):\n",
    "        raise ParticipantVisibleError(f'All target values in {df_name} must be numeric')\n",
    "\n",
    "    if df.min().min() < 0:\n",
    "        raise ParticipantVisibleError(f'All target values in {df_name} must be at least zero')\n",
    "\n",
    "    if df.max().max() > 1:\n",
    "        raise ParticipantVisibleError(f'All target values in {df_name} must be no greater than one')\n",
    "\n",
    "    if not np.allclose(df.sum(axis=1), 1):\n",
    "        raise ParticipantVisibleError(f'Target values in {df_name} do not add to one within all rows')\n",
    "\n",
    "\n",
    "def kl_divergence(solution: pd.DataFrame, submission: pd.DataFrame, epsilon: float, micro_average: bool, sample_weights: Optional[pd.Series]):\n",
    "    # Overwrite solution for convenience\n",
    "    for col in solution.columns:\n",
    "        # Prevent issue with populating int columns with floats\n",
    "        if not pandas.api.types.is_float_dtype(solution[col]):\n",
    "            solution[col] = solution[col].astype(float)\n",
    "\n",
    "        # Clip both the min and max following Kaggle conventions for related metrics like log loss\n",
    "        # Clipping the max avoids cases where the loss would be infinite or undefined, clipping the min\n",
    "        # prevents users from playing games with the 20th decimal place of predictions.\n",
    "        submission[col] = np.clip(submission[col], epsilon, 1 - epsilon)\n",
    "\n",
    "        y_nonzero_indices = solution[col] != 0\n",
    "        solution[col] = solution[col].astype(float)\n",
    "        solution.loc[y_nonzero_indices, col] = solution.loc[y_nonzero_indices, col] * np.log(solution.loc[y_nonzero_indices, col] / submission.loc[y_nonzero_indices, col])\n",
    "        # Set the loss equal to zero where y_true equals zero following the scipy convention:\n",
    "        # https://docs.scipy.org/doc/scipy/reference/generated/scipy.special.rel_entr.html#scipy.special.rel_entr\n",
    "        solution.loc[~y_nonzero_indices, col] = 0\n",
    "\n",
    "    if micro_average:\n",
    "        return np.average(solution.sum(axis=1), weights=sample_weights)\n",
    "    else:\n",
    "        return np.average(solution.mean())\n",
    "\n",
    "def score(\n",
    "        solution: pd.DataFrame,\n",
    "        submission: pd.DataFrame,\n",
    "        row_id_column_name: str,\n",
    "        epsilon: float=10**-15,\n",
    "        micro_average: bool=True,\n",
    "        sample_weights_column_name: Optional[str]=None\n",
    "    ) -> float:\n",
    "    ''' The Kullback-Leibler divergence.\n",
    "    The KL divergence is technically undefined/infinite where the target equals zero.\n",
    "\n",
    "    This implementation always assigns those cases a score of zero; effectively removing them from consideration.\n",
    "    The predictions in each row must add to one so any probability assigned to a case where y == 0 reduces\n",
    "    another prediction where y > 0, so crucially there is an important indirect effect.\n",
    "\n",
    "    https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence\n",
    "\n",
    "    solution: pd.DataFrame\n",
    "    submission: pd.DataFrame\n",
    "    epsilon: KL divergence is undefined for p=0 or p=1. If epsilon is not null, solution and submission probabilities are clipped to max(eps, min(1 - eps, p).\n",
    "    row_id_column_name: str\n",
    "    micro_average: bool. Row-wise average if True, column-wise average if False.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> import pandas as pd\n",
    "    >>> row_id_column_name = \"id\"\n",
    "    >>> score(pd.DataFrame({'id': range(4), 'ham': [0, 1, 1, 0], 'spam': [1, 0, 0, 1]}), pd.DataFrame({'id': range(4), 'ham': [.1, .9, .8, .35], 'spam': [.9, .1, .2, .65]}), row_id_column_name=row_id_column_name)\n",
    "    0.216161...\n",
    "    >>> solution = pd.DataFrame({'id': range(3), 'ham': [0, 0.5, 0.5], 'spam': [0.1, 0.5, 0.5], 'other': [0.9, 0, 0]})\n",
    "    >>> submission = pd.DataFrame({'id': range(3), 'ham': [0, 0.5, 0.5], 'spam': [0.1, 0.5, 0.5], 'other': [0.9, 0, 0]})\n",
    "    >>> score(solution, submission, 'id')\n",
    "    0.0\n",
    "    >>> solution = pd.DataFrame({'id': range(3), 'ham': [0, 0.5, 0.5], 'spam': [0.1, 0.5, 0.5], 'other': [0.9, 0, 0]})\n",
    "    >>> submission = pd.DataFrame({'id': range(3), 'ham': [0.2, 0.3, 0.5], 'spam': [0.1, 0.5, 0.5], 'other': [0.7, 0.2, 0]})\n",
    "    >>> score(solution, submission, 'id')\n",
    "    0.160531...\n",
    "    '''\n",
    "    del solution[row_id_column_name]\n",
    "    del submission[row_id_column_name]\n",
    "\n",
    "    sample_weights = None\n",
    "    if sample_weights_column_name:\n",
    "        if sample_weights_column_name not in solution.columns:\n",
    "            raise ParticipantVisibleError(f'{sample_weights_column_name} not found in solution columns')\n",
    "        sample_weights = solution.pop(sample_weights_column_name)\n",
    "\n",
    "    if sample_weights_column_name and not micro_average:\n",
    "        raise ParticipantVisibleError('Sample weights are only valid if `micro_average` is `True`')\n",
    "\n",
    "    for col in solution.columns:\n",
    "        if col not in submission.columns:\n",
    "            raise ParticipantVisibleError(f'Missing submission column {col}')\n",
    "\n",
    "    verify_valid_probabilities(solution, 'solution')\n",
    "    verify_valid_probabilities(submission, 'submission')\n",
    "\n",
    "    return safe_call_score(kl_divergence, solution, submission, epsilon=epsilon, micro_average=micro_average, sample_weights=sample_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set = np.load(f'{devset_dir}/03_single_spectrograms_v1_train.npy')\n",
    "# train_items = np.load(f'{devset_dir}/03_single_spectrograms_v1_train_items.npy')\n",
    "# val_set = np.load(f'{devset_dir}/03_single_spectrograms_v1_val.npy')\n",
    "# val_items = np.load(f'{devset_dir}/03_single_spectrograms_v1_val_items.npy')\n",
    "# test_set = np.load(f'{devset_dir}/03_single_spectrograms_v1_test.npy')\n",
    "# test_items = np.load(f'{devset_dir}/03_single_spectrograms_v1_test_items.npy')\n",
    "# print(f'{train_set.shape[0]} observations in training set.')\n",
    "# print(f'{val_set.shape[0]} observations in validation set.')\n",
    "# print(f'{test_set.shape[0]} observations in testing set.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Data generator using numpy and no pandas.\n",
    "#\n",
    "# Spectrograms\n",
    "# 10 seconds slice\n",
    "# 2 channels\n",
    "#\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, path_to_items, path_to_data, batch_size=32, n_classes=6, shuffle=True):\n",
    "        ''' Initialization\n",
    "        items: [eeg_id, eeg_sub_id, idx of offset, target]\n",
    "        '''\n",
    "        self.n_channels = 2\n",
    "        # self.n_freqs = 40\n",
    "\n",
    "        self.data = np.load(path_to_data)\n",
    "        self.items = np.load(path_to_items)\n",
    "        self.dim = (self.data.shape[1], self.data.shape[2])\n",
    "        self.batch_size = batch_size\n",
    "        self.len = self.data.shape[0]\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.ceil(self.len / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(indexes)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def get_dim(self):\n",
    "        'Dimensions for the input layer.'\n",
    "        return (self.dim[0], self.dim[1], self.n_channels)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(self.len)\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, indexes):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        true_size = len(indexes)\n",
    "        X = np.empty((true_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((true_size), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, idx in enumerate(indexes):\n",
    "            item = self.items[idx]\n",
    "            # print(item)  # Uncomment for testing.\n",
    "            X[i,:,:,:] = self.data[np.int16(item[2]), :, :, :]\n",
    "            # Store class\n",
    "            y[i] = np.int16(item[3])\n",
    "\n",
    "        return X, keras.utils.to_categorical(y, num_classes=self.n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_model(input_shape, num_classes):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "\n",
    "    #max1 = keras.layers.MaxPooling1D(pool_size=2)(input_layer)\n",
    "    \n",
    "    conv1 = keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\")(input_layer)\n",
    "    #conv1 = keras.layers.BatchNormalization()(conv1)\n",
    "    # conv1 = keras.layers.MaxPooling2D(pool_size=8)(conv1)\n",
    "    conv1 = keras.layers.ReLU()(conv1)\n",
    "    \n",
    "    conv2 = keras.layers.Conv2D(filters=64, kernel_size=7, padding=\"same\")(conv1)\n",
    "    #conv2 = keras.layers.BatchNormalization()(conv2)\n",
    "    # conv2 = keras.layers.MaxPooling2D(pool_size=8)(conv2)\n",
    "    conv2 = keras.layers.ReLU()(conv2)\n",
    "\n",
    "    conv3 = keras.layers.Conv2D(filters=256, kernel_size=7, padding=\"same\")(conv2)\n",
    "    #conv3 = keras.layers.BatchNormalization()(conv3)\n",
    "    conv3 = keras.layers.MaxPooling2D(pool_size=2)(conv3)\n",
    "    conv3 = keras.layers.ReLU()(conv3)\n",
    "\n",
    "    conv4 = keras.layers.Conv1D(filters=512, kernel_size=3, padding=\"same\")(conv3)\n",
    "    conv4 = keras.layers.BatchNormalization()(conv4)\n",
    "    conv4 = keras.layers.MaxPooling2D(pool_size=4)(conv4)\n",
    "    conv4 = keras.layers.ReLU()(conv4)\n",
    "\n",
    "    fltn  = keras.layers.Flatten()(conv4) \n",
    "    \n",
    "    relu1 = keras.layers.Dense(256)(fltn)\n",
    "    relu1 = keras.layers.ReLU()(relu1)\n",
    "\n",
    "    relu2 = keras.layers.Dense(64)(relu1)\n",
    "    relu2 = keras.layers.ReLU(64)(relu2)\n",
    "\n",
    "#     lin = keras.layers.Dense(2)(relu2)\n",
    "\n",
    "    output_layer = keras.layers.Dense(num_classes, activation=\"softmax\")(relu2)\n",
    "\n",
    "    return keras.models.Model(inputs=input_layer, outputs=output_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations in training set: 416\n",
      "Observations in validation set: 128\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "params = {\n",
    "    'batch_size': 32,\n",
    "    'n_classes': 6,\n",
    "    'shuffle': True\n",
    "    }\n",
    "\n",
    "training_generator = DataGenerator(path_train_items, path_train , **params)\n",
    "validation_generator = DataGenerator(path_val_items, path_val, **params)\n",
    "\n",
    "print(\"Observations in training set:\", training_generator.__len__()*params['batch_size'])\n",
    "print(\"Observations in validation set:\", validation_generator.__len__()*params['batch_size'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 376s 29s/step - loss: 4.7281 - accuracy: 0.1650 - val_loss: 2.6698 - val_accuracy: 0.1800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f71341e7160>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim = training_generator.get_dim()\n",
    "\n",
    "model = make_model(input_shape=dim, num_classes=6)\n",
    "model.compile(optimizer='sgd',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=tf.keras.metrics.KLDivergence(\n",
    "                    name='kullback_leibler_divergence', dtype=None\n",
    "                    )\n",
    "            )\n",
    "\n",
    "model.fit(training_generator, epochs=1, validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 21s 5s/step\n"
     ]
    }
   ],
   "source": [
    "TARGETS = ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n",
    "\n",
    "#\n",
    "# Test Data generator: for predicting\n",
    "# using own test set.\n",
    "# (Not for predicting LB)\n",
    "#\n",
    "\n",
    "class TestDataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, path_to_items, path_to_data, batch_size=32, n_classes=6, shuffle=False):\n",
    "        ''' Initialization\n",
    "        items: [eeg_id, eeg_sub_id, idx of offset, target, ...]\n",
    "        '''\n",
    "        self.n_channels = 2\n",
    "        self.data = np.load(path_to_data)\n",
    "        self.items = np.load(path_to_items)\n",
    "        self.dim = (self.data.shape[1], self.data.shape[2])\n",
    "        self.batch_size = batch_size\n",
    "        self.len = self.data.shape[0]\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.ceil(self.len / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Generate data\n",
    "        X = self.__data_generation(indexes)\n",
    "\n",
    "        return X\n",
    "\n",
    "    def get_dim(self):\n",
    "        'Dimensions for the input layer.'\n",
    "        return (self.dim[0], self.dim[1], self.n_channels)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(self.len)\n",
    "        # pass \n",
    "        \n",
    "    def __data_generation(self, indexes):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        true_size = len(indexes)\n",
    "        X = np.empty((true_size, *self.dim, self.n_channels))\n",
    "\n",
    "        # Generate data\n",
    "        for i, idx in enumerate(indexes):\n",
    "            item = self.items[idx]\n",
    "            # print(item)  # Uncomment for testing.\n",
    "            X[i,:,:,:] = self.data[np.int16(item[2]), :, :, :]\n",
    "\n",
    "        return X\n",
    "    \n",
    "                \n",
    "params = {\n",
    "    'batch_size': 32,\n",
    "    'n_classes': 6,\n",
    "    }\n",
    "\n",
    "test_generator = TestDataGenerator(path_test_items, path_test, **params)\n",
    "\n",
    "y_pred = model.predict(test_generator)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.6577519e-01, 1.6426449e-01, 1.6785835e-01, 1.7222977e-01,\n",
       "        1.6519608e-01, 1.6467607e-01],\n",
       "       [3.0143499e-01, 9.7424351e-02, 1.7135055e-01, 1.6934478e-01,\n",
       "        1.1828900e-01, 1.4215627e-01],\n",
       "       [1.6569136e-01, 1.6416799e-01, 1.6785404e-01, 1.7209414e-01,\n",
       "        1.6552234e-01, 1.6467015e-01],\n",
       "       [1.6553679e-01, 1.6415414e-01, 1.6778225e-01, 1.7213893e-01,\n",
       "        1.6567042e-01, 1.6471750e-01],\n",
       "       [1.6557640e-01, 1.6422121e-01, 1.6775626e-01, 1.7231408e-01,\n",
       "        1.6539159e-01, 1.6474041e-01],\n",
       "       [1.6575530e-01, 1.6420758e-01, 1.6783547e-01, 1.7209406e-01,\n",
       "        1.6541541e-01, 1.6469210e-01],\n",
       "       [1.6557972e-01, 1.6419984e-01, 1.6778640e-01, 1.7214333e-01,\n",
       "        1.6555798e-01, 1.6473272e-01],\n",
       "       [1.6554473e-01, 1.6417181e-01, 1.6780341e-01, 1.7211093e-01,\n",
       "        1.6565093e-01, 1.6471815e-01],\n",
       "       [1.7138892e-01, 1.5923227e-01, 1.6824876e-01, 1.7618155e-01,\n",
       "        1.6267794e-01, 1.6227053e-01],\n",
       "       [1.6558611e-01, 1.6426310e-01, 1.6776933e-01, 1.7215177e-01,\n",
       "        1.6551244e-01, 1.6471733e-01],\n",
       "       [1.6574967e-01, 1.6423726e-01, 1.6784377e-01, 1.7222922e-01,\n",
       "        1.6512540e-01, 1.6481468e-01],\n",
       "       [1.6577110e-01, 1.6424154e-01, 1.6781828e-01, 1.7203921e-01,\n",
       "        1.6552176e-01, 1.6460812e-01],\n",
       "       [1.7729135e-01, 1.5667437e-01, 1.6969638e-01, 1.7713733e-01,\n",
       "        1.5585825e-01, 1.6334233e-01],\n",
       "       [1.6554390e-01, 1.6413864e-01, 1.6780709e-01, 1.7214854e-01,\n",
       "        1.6566069e-01, 1.6470110e-01],\n",
       "       [1.6552477e-01, 1.6419025e-01, 1.6779526e-01, 1.7213500e-01,\n",
       "        1.6562515e-01, 1.6472957e-01],\n",
       "       [1.6556673e-01, 1.6413039e-01, 1.6782096e-01, 1.7212716e-01,\n",
       "        1.6567314e-01, 1.6468161e-01],\n",
       "       [1.6574527e-01, 1.6417272e-01, 1.6781746e-01, 1.7218854e-01,\n",
       "        1.6537671e-01, 1.6469935e-01],\n",
       "       [9.9963915e-01, 7.7156031e-08, 1.8373766e-04, 1.5227440e-05,\n",
       "        1.5588972e-08, 1.6180961e-04],\n",
       "       [1.9644849e-01, 1.4334583e-01, 1.7557652e-01, 1.8238454e-01,\n",
       "        1.3607742e-01, 1.6616726e-01],\n",
       "       [1.6558485e-01, 1.6417395e-01, 1.6777529e-01, 1.7209858e-01,\n",
       "        1.6565906e-01, 1.6470826e-01],\n",
       "       [2.1760447e-01, 1.4088075e-01, 1.7358603e-01, 1.7294288e-01,\n",
       "        1.3706145e-01, 1.5792447e-01],\n",
       "       [1.6555315e-01, 1.6413665e-01, 1.6780864e-01, 1.7214800e-01,\n",
       "        1.6565323e-01, 1.6470040e-01],\n",
       "       [8.7460327e-01, 3.7204965e-03, 6.2651694e-02, 3.3383936e-02,\n",
       "        3.7523364e-03, 2.1888256e-02],\n",
       "       [1.8968868e-01, 1.5486622e-01, 1.7271534e-01, 1.7447038e-01,\n",
       "        1.4263543e-01, 1.6562396e-01],\n",
       "       [1.6555737e-01, 1.6418456e-01, 1.6781540e-01, 1.7206645e-01,\n",
       "        1.6564783e-01, 1.6472845e-01],\n",
       "       [1.6567422e-01, 1.6433960e-01, 1.6776153e-01, 1.7190897e-01,\n",
       "        1.6553843e-01, 1.6477722e-01],\n",
       "       [1.6704407e-01, 1.6338184e-01, 1.6804317e-01, 1.7313796e-01,\n",
       "        1.6421552e-01, 1.6417737e-01],\n",
       "       [1.0000000e+00, 3.8579701e-27, 1.9591760e-14, 2.8051150e-15,\n",
       "        2.9862537e-25, 1.5563141e-18],\n",
       "       [1.6557384e-01, 1.6420218e-01, 1.6778934e-01, 1.7208415e-01,\n",
       "        1.6563186e-01, 1.6471870e-01],\n",
       "       [1.6602921e-01, 1.6395630e-01, 1.6803223e-01, 1.7256045e-01,\n",
       "        1.6505019e-01, 1.6437165e-01],\n",
       "       [1.6558091e-01, 1.6415960e-01, 1.6779788e-01, 1.7209184e-01,\n",
       "        1.6567133e-01, 1.6469844e-01],\n",
       "       [9.9999976e-01, 3.3238782e-25, 1.5003177e-07, 3.4106401e-26,\n",
       "        0.0000000e+00, 1.2705327e-07],\n",
       "       [1.6612306e-01, 1.6368099e-01, 1.6837394e-01, 1.7250711e-01,\n",
       "        1.6476026e-01, 1.6455463e-01],\n",
       "       [1.6560341e-01, 1.6418143e-01, 1.6779220e-01, 1.7207478e-01,\n",
       "        1.6563883e-01, 1.6470937e-01],\n",
       "       [9.8796976e-01, 6.1641636e-05, 8.0604944e-03, 2.4151569e-03,\n",
       "        5.1207215e-05, 1.4417690e-03],\n",
       "       [1.6559544e-01, 1.6422538e-01, 1.6777253e-01, 1.7206402e-01,\n",
       "        1.6562602e-01, 1.6471662e-01],\n",
       "       [1.6834779e-01, 1.6284895e-01, 1.6714044e-01, 1.7404149e-01,\n",
       "        1.6362406e-01, 1.6399720e-01],\n",
       "       [1.9018376e-01, 1.5474284e-01, 1.6774864e-01, 1.7050827e-01,\n",
       "        1.5078482e-01, 1.6603164e-01],\n",
       "       [9.9999952e-01, 1.8450505e-22, 5.3446337e-07, 7.4490058e-12,\n",
       "        2.3688014e-38, 4.2835544e-09],\n",
       "       [1.6558640e-01, 1.6418150e-01, 1.6781171e-01, 1.7213464e-01,\n",
       "        1.6561478e-01, 1.6467096e-01],\n",
       "       [1.6557842e-01, 1.6418383e-01, 1.6778138e-01, 1.7208205e-01,\n",
       "        1.6566557e-01, 1.6470869e-01],\n",
       "       [1.6888948e-01, 1.6319846e-01, 1.6783062e-01, 1.7267440e-01,\n",
       "        1.6292366e-01, 1.6448338e-01],\n",
       "       [1.6564792e-01, 1.6432905e-01, 1.6774292e-01, 1.7194726e-01,\n",
       "        1.6556941e-01, 1.6476338e-01],\n",
       "       [1.9219293e-01, 1.5312172e-01, 1.8205927e-01, 1.6314304e-01,\n",
       "        1.4517425e-01, 1.6430871e-01],\n",
       "       [1.6688947e-01, 1.6350780e-01, 1.6781706e-01, 1.7317177e-01,\n",
       "        1.6419989e-01, 1.6441403e-01],\n",
       "       [1.6582629e-01, 1.6437811e-01, 1.6766635e-01, 1.7254359e-01,\n",
       "        1.6485582e-01, 1.6472983e-01],\n",
       "       [1.6559666e-01, 1.6422608e-01, 1.6777542e-01, 1.7202790e-01,\n",
       "        1.6565910e-01, 1.6471484e-01],\n",
       "       [1.0000000e+00, 0.0000000e+00, 7.8542538e-13, 1.1299456e-30,\n",
       "        0.0000000e+00, 8.7519986e-28],\n",
       "       [1.6585447e-01, 1.6425551e-01, 1.6779514e-01, 1.7206527e-01,\n",
       "        1.6533698e-01, 1.6469263e-01],\n",
       "       [7.8461295e-01, 7.7219889e-03, 9.6615702e-02, 5.7870697e-02,\n",
       "        1.5490240e-02, 3.7688438e-02],\n",
       "       [1.6598216e-01, 1.6438258e-01, 1.6784601e-01, 1.7190692e-01,\n",
       "        1.6530864e-01, 1.6457371e-01],\n",
       "       [1.6552792e-01, 1.6412556e-01, 1.6780138e-01, 1.7216967e-01,\n",
       "        1.6566986e-01, 1.6470549e-01],\n",
       "       [1.6577671e-01, 1.6423321e-01, 1.6751061e-01, 1.7291856e-01,\n",
       "        1.6476861e-01, 1.6479224e-01],\n",
       "       [1.6926952e-01, 1.6210943e-01, 1.6810979e-01, 1.7547756e-01,\n",
       "        1.6037135e-01, 1.6466232e-01],\n",
       "       [1.6565463e-01, 1.6424234e-01, 1.6779216e-01, 1.7197858e-01,\n",
       "        1.6565324e-01, 1.6467905e-01],\n",
       "       [1.8176824e-01, 1.5522392e-01, 1.6781048e-01, 1.7621413e-01,\n",
       "        1.5361822e-01, 1.6536500e-01],\n",
       "       [1.6566537e-01, 1.6424082e-01, 1.6781154e-01, 1.7203590e-01,\n",
       "        1.6552341e-01, 1.6472293e-01],\n",
       "       [1.6559321e-01, 1.6416799e-01, 1.6781145e-01, 1.7211792e-01,\n",
       "        1.6561651e-01, 1.6469288e-01],\n",
       "       [1.6711493e-01, 1.6343322e-01, 1.6780643e-01, 1.7371003e-01,\n",
       "        1.6369562e-01, 1.6423976e-01],\n",
       "       [1.6562970e-01, 1.6426615e-01, 1.6776817e-01, 1.7201255e-01,\n",
       "        1.6562197e-01, 1.6470143e-01],\n",
       "       [6.0560870e-01, 2.0804370e-02, 1.9383849e-01, 1.1005000e-01,\n",
       "        1.8182464e-02, 5.1515952e-02],\n",
       "       [1.6575263e-01, 1.6438271e-01, 1.6772564e-01, 1.7222796e-01,\n",
       "        1.6519271e-01, 1.6471840e-01],\n",
       "       [1.6606897e-01, 1.6398194e-01, 1.6790138e-01, 1.7232612e-01,\n",
       "        1.6519417e-01, 1.6452737e-01],\n",
       "       [1.6610180e-01, 1.6188635e-01, 1.6933957e-01, 1.7423846e-01,\n",
       "        1.6403373e-01, 1.6440015e-01],\n",
       "       [1.6561741e-01, 1.6421255e-01, 1.6775857e-01, 1.7205215e-01,\n",
       "        1.6561504e-01, 1.6474429e-01],\n",
       "       [1.6795205e-01, 1.6399360e-01, 1.6680361e-01, 1.7317393e-01,\n",
       "        1.6278324e-01, 1.6529359e-01],\n",
       "       [1.6631329e-01, 1.6423592e-01, 1.6758707e-01, 1.7274548e-01,\n",
       "        1.6445500e-01, 1.6466327e-01],\n",
       "       [1.6552283e-01, 1.6411184e-01, 1.6780838e-01, 1.7218633e-01,\n",
       "        1.6567139e-01, 1.6469926e-01],\n",
       "       [5.2417821e-01, 4.7177322e-02, 1.5954134e-01, 1.2334743e-01,\n",
       "        4.3829091e-02, 1.0192662e-01],\n",
       "       [1.6572592e-01, 1.6428588e-01, 1.6782886e-01, 1.7212579e-01,\n",
       "        1.6535582e-01, 1.6467778e-01],\n",
       "       [1.6550466e-01, 1.6415033e-01, 1.6782215e-01, 1.7217474e-01,\n",
       "        1.6563879e-01, 1.6470928e-01],\n",
       "       [1.6552886e-01, 1.6411325e-01, 1.6780360e-01, 1.7218177e-01,\n",
       "        1.6567136e-01, 1.6470113e-01],\n",
       "       [1.6552025e-01, 1.6411662e-01, 1.6780831e-01, 1.7217875e-01,\n",
       "        1.6567326e-01, 1.6470283e-01],\n",
       "       [1.7143871e-01, 1.6112597e-01, 1.6808373e-01, 1.7510611e-01,\n",
       "        1.5988258e-01, 1.6436288e-01],\n",
       "       [1.6564979e-01, 1.6419575e-01, 1.6780889e-01, 1.7199492e-01,\n",
       "        1.6563885e-01, 1.6471185e-01],\n",
       "       [1.6564167e-01, 1.6421029e-01, 1.6774113e-01, 1.7222595e-01,\n",
       "        1.6547096e-01, 1.6470993e-01],\n",
       "       [1.6565458e-01, 1.6433890e-01, 1.6775851e-01, 1.7221387e-01,\n",
       "        1.6532469e-01, 1.6470936e-01],\n",
       "       [1.8651618e-01, 1.5176001e-01, 1.7028604e-01, 1.7579412e-01,\n",
       "        1.5541960e-01, 1.6022404e-01],\n",
       "       [1.6552345e-01, 1.6411029e-01, 1.6780578e-01, 1.7218904e-01,\n",
       "        1.6567141e-01, 1.6470008e-01],\n",
       "       [1.6573833e-01, 1.6404468e-01, 1.6809201e-01, 1.7253512e-01,\n",
       "        1.6497000e-01, 1.6461985e-01],\n",
       "       [2.1681355e-01, 1.3063623e-01, 1.7752816e-01, 1.8383680e-01,\n",
       "        1.3824853e-01, 1.5293671e-01],\n",
       "       [1.6564217e-01, 1.6421415e-01, 1.6783522e-01, 1.7203093e-01,\n",
       "        1.6558394e-01, 1.6469358e-01],\n",
       "       [1.6557157e-01, 1.6420162e-01, 1.6780326e-01, 1.7206466e-01,\n",
       "        1.6566336e-01, 1.6469547e-01],\n",
       "       [1.6562892e-01, 1.6426626e-01, 1.6777238e-01, 1.7197686e-01,\n",
       "        1.6562986e-01, 1.6472568e-01],\n",
       "       [1.6555765e-01, 1.6436258e-01, 1.6782664e-01, 1.7207307e-01,\n",
       "        1.6538911e-01, 1.6479096e-01],\n",
       "       [1.6583505e-01, 1.6407523e-01, 1.6788734e-01, 1.7215262e-01,\n",
       "        1.6555707e-01, 1.6449270e-01],\n",
       "       [1.7343424e-01, 1.5750146e-01, 1.6838624e-01, 1.7556764e-01,\n",
       "        1.6283892e-01, 1.6227148e-01],\n",
       "       [1.6543451e-01, 1.6427065e-01, 1.6783257e-01, 1.7202182e-01,\n",
       "        1.6550072e-01, 1.6493972e-01],\n",
       "       [1.6679934e-01, 1.6294402e-01, 1.6851301e-01, 1.7315359e-01,\n",
       "        1.6459215e-01, 1.6399787e-01],\n",
       "       [1.6616799e-01, 1.6411826e-01, 1.6725293e-01, 1.7290527e-01,\n",
       "        1.6419184e-01, 1.6536374e-01],\n",
       "       [1.9361159e-01, 1.4807175e-01, 1.7347446e-01, 1.7428088e-01,\n",
       "        1.4882150e-01, 1.6173980e-01],\n",
       "       [1.6557685e-01, 1.6425450e-01, 1.6778445e-01, 1.7209965e-01,\n",
       "        1.6556545e-01, 1.6471909e-01],\n",
       "       [1.6554634e-01, 1.6426100e-01, 1.6780366e-01, 1.7204323e-01,\n",
       "        1.6561016e-01, 1.6473554e-01],\n",
       "       [1.6554673e-01, 1.6417210e-01, 1.6778460e-01, 1.7212699e-01,\n",
       "        1.6564575e-01, 1.6472375e-01],\n",
       "       [1.6562125e-01, 1.6425398e-01, 1.6777794e-01, 1.7202656e-01,\n",
       "        1.6558516e-01, 1.6473515e-01],\n",
       "       [1.6553511e-01, 1.6412206e-01, 1.6780339e-01, 1.7217268e-01,\n",
       "        1.6566856e-01, 1.6469827e-01],\n",
       "       [1.6551116e-01, 1.6438162e-01, 1.6788577e-01, 1.7231473e-01,\n",
       "        1.6460179e-01, 1.6530490e-01],\n",
       "       [1.6742319e-01, 1.6433416e-01, 1.6708912e-01, 1.7242779e-01,\n",
       "        1.6318905e-01, 1.6553667e-01],\n",
       "       [1.6558897e-01, 1.6417781e-01, 1.6782901e-01, 1.7209694e-01,\n",
       "        1.6563615e-01, 1.6467109e-01],\n",
       "       [1.6557850e-01, 1.6421841e-01, 1.6777708e-01, 1.7202672e-01,\n",
       "        1.6568950e-01, 1.6470978e-01]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.91959911e+09, 9.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [1.38832815e+09, 4.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
       "        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [2.33388099e+09, 0.00000000e+00, 2.00000000e+00, 5.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.00000000e+00],\n",
       "       [2.42874105e+08, 1.00000000e+00, 3.00000000e+00, 3.00000000e+00,\n",
       "        0.00000000e+00, 2.30769231e-01, 0.00000000e+00, 3.84615385e-01,\n",
       "        0.00000000e+00, 3.84615385e-01],\n",
       "       [2.56055520e+09, 0.00000000e+00, 4.00000000e+00, 5.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.00000000e+00],\n",
       "       [2.37763612e+09, 5.00000000e+00, 5.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00, 3.33333333e-01, 3.33333333e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 3.33333333e-01],\n",
       "       [5.25664301e+08, 2.90000000e+01, 6.00000000e+00, 3.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [1.11331323e+09, 1.00000000e+00, 7.00000000e+00, 4.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.00000000e+00, 0.00000000e+00],\n",
       "       [4.24820941e+09, 0.00000000e+00, 8.00000000e+00, 3.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [3.55667367e+09, 0.00000000e+00, 9.00000000e+00, 5.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.00000000e+00],\n",
       "       [2.50865956e+09, 0.00000000e+00, 1.00000000e+01, 2.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [8.48986991e+08, 2.00000000e+00, 1.10000000e+01, 4.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.00000000e+00, 0.00000000e+00],\n",
       "       [8.02594878e+08, 0.00000000e+00, 1.20000000e+01, 3.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [9.69654359e+08, 2.50000000e+01, 1.30000000e+01, 3.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [4.06018243e+09, 3.00000000e+00, 1.40000000e+01, 4.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.00000000e+00, 0.00000000e+00],\n",
       "       [1.17484321e+09, 1.00000000e+00, 1.50000000e+01, 5.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        2.50000000e-01, 7.50000000e-01],\n",
       "       [2.73063247e+09, 0.00000000e+00, 1.60000000e+01, 1.00000000e+00,\n",
       "        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [2.14758250e+09, 0.00000000e+00, 1.70000000e+01, 3.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [2.70471245e+09, 1.00000000e+00, 1.80000000e+01, 0.00000000e+00,\n",
       "        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [2.58386963e+09, 0.00000000e+00, 1.90000000e+01, 3.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [9.06380423e+08, 0.00000000e+00, 2.00000000e+01, 1.00000000e+00,\n",
       "        1.42857143e-01, 7.85714286e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 7.14285714e-02],\n",
       "       [1.71996222e+09, 9.00000000e+00, 2.10000000e+01, 2.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [2.76508060e+09, 0.00000000e+00, 2.20000000e+01, 2.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [5.67559631e+08, 1.00000000e+00, 2.30000000e+01, 0.00000000e+00,\n",
       "        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [2.47726601e+09, 7.00000000e+00, 2.40000000e+01, 0.00000000e+00,\n",
       "        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [1.42901500e+08, 1.00000000e+00, 2.50000000e+01, 2.00000000e+00,\n",
       "        0.00000000e+00, 1.66666667e-01, 8.33333333e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [1.97395593e+08, 1.00000000e+00, 2.60000000e+01, 3.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.33333333e-01,\n",
       "        3.33333333e-01, 3.33333333e-01],\n",
       "       [3.67066932e+09, 4.20000000e+01, 2.70000000e+01, 4.00000000e+00,\n",
       "        0.00000000e+00, 1.00000000e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        7.00000000e-01, 2.00000000e-01],\n",
       "       [3.19845618e+08, 0.00000000e+00, 2.80000000e+01, 1.00000000e+00,\n",
       "        0.00000000e+00, 5.29411765e-01, 0.00000000e+00, 2.94117647e-01,\n",
       "        0.00000000e+00, 1.76470588e-01],\n",
       "       [2.01992036e+09, 0.00000000e+00, 2.90000000e+01, 1.00000000e+00,\n",
       "        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [3.45872845e+09, 3.00000000e+00, 3.00000000e+01, 4.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.00000000e+00, 0.00000000e+00],\n",
       "       [4.14350093e+09, 1.10000000e+01, 3.10000000e+01, 0.00000000e+00,\n",
       "        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [3.86706218e+08, 5.00000000e+00, 3.20000000e+01, 4.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.00000000e+00, 0.00000000e+00],\n",
       "       [2.91962930e+09, 2.00000000e+00, 3.30000000e+01, 3.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.62500000e-01,\n",
       "        0.00000000e+00, 4.37500000e-01],\n",
       "       [3.57834966e+09, 0.00000000e+00, 3.40000000e+01, 2.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [5.25664301e+08, 4.65000000e+02, 3.50000000e+01, 3.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [1.58444166e+09, 1.00000000e+00, 3.60000000e+01, 1.00000000e+00,\n",
       "        7.69230769e-02, 3.07692308e-01, 1.53846154e-01, 7.69230769e-02,\n",
       "        7.69230769e-02, 3.07692308e-01],\n",
       "       [9.05759334e+08, 0.00000000e+00, 3.70000000e+01, 1.00000000e+00,\n",
       "        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [3.53267138e+09, 0.00000000e+00, 3.80000000e+01, 5.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.00000000e+00],\n",
       "       [5.25664301e+08, 4.94000000e+02, 3.90000000e+01, 3.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [5.25664301e+08, 3.77000000e+02, 4.00000000e+01, 3.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [3.04695192e+09, 0.00000000e+00, 4.10000000e+01, 2.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 5.00000000e-01, 0.00000000e+00,\n",
       "        5.00000000e-01, 0.00000000e+00],\n",
       "       [3.71322389e+09, 9.00000000e+00, 4.20000000e+01, 3.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [1.09368373e+09, 0.00000000e+00, 4.30000000e+01, 1.00000000e+00,\n",
       "        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [4.13019806e+09, 0.00000000e+00, 4.40000000e+01, 2.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [1.23920506e+09, 6.50000000e+01, 4.50000000e+01, 4.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.00000000e+00, 0.00000000e+00],\n",
       "       [1.07842983e+09, 0.00000000e+00, 4.60000000e+01, 2.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 6.66666667e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 3.33333333e-01],\n",
       "       [3.63306862e+09, 0.00000000e+00, 4.70000000e+01, 0.00000000e+00,\n",
       "        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [2.94729880e+09, 1.00000000e+00, 4.80000000e+01, 2.00000000e+00,\n",
       "        0.00000000e+00, 3.33333333e-01, 6.66666667e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [4.06155041e+08, 0.00000000e+00, 4.90000000e+01, 1.00000000e+00,\n",
       "        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [1.15618892e+09, 0.00000000e+00, 5.00000000e+01, 3.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [1.22345256e+09, 2.00000000e+00, 5.10000000e+01, 0.00000000e+00,\n",
       "        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [3.55917303e+09, 0.00000000e+00, 5.20000000e+01, 1.00000000e+00,\n",
       "        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [3.61805312e+08, 6.00000000e+00, 5.30000000e+01, 0.00000000e+00,\n",
       "        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [4.04286068e+09, 1.00000000e+02, 5.40000000e+01, 3.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [3.11263816e+09, 0.00000000e+00, 5.50000000e+01, 0.00000000e+00,\n",
       "        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [4.18825358e+09, 1.00000000e+00, 5.60000000e+01, 0.00000000e+00,\n",
       "        3.33333333e-01, 0.00000000e+00, 3.33333333e-01, 0.00000000e+00,\n",
       "        3.33333333e-01, 0.00000000e+00],\n",
       "       [1.89574950e+09, 0.00000000e+00, 5.70000000e+01, 2.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [4.04079087e+09, 4.00000000e+00, 5.80000000e+01, 5.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        3.33333333e-01, 6.66666667e-01],\n",
       "       [4.21788664e+08, 0.00000000e+00, 5.90000000e+01, 5.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.33333333e-01,\n",
       "        0.00000000e+00, 6.66666667e-01],\n",
       "       [3.17347873e+09, 1.00000000e+00, 6.00000000e+01, 0.00000000e+00,\n",
       "        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [1.23920506e+09, 4.70000000e+01, 6.10000000e+01, 4.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.00000000e+00, 0.00000000e+00],\n",
       "       [2.98116242e+09, 3.00000000e+00, 6.20000000e+01, 1.00000000e+00,\n",
       "        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [3.12964357e+09, 0.00000000e+00, 6.30000000e+01, 5.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.69230769e-02,\n",
       "        0.00000000e+00, 9.23076923e-01],\n",
       "       [3.06763547e+09, 2.60000000e+01, 6.40000000e+01, 4.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.00000000e+00, 0.00000000e+00],\n",
       "       [1.25090158e+09, 0.00000000e+00, 6.50000000e+01, 4.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.00000000e+00, 0.00000000e+00],\n",
       "       [1.58208938e+08, 5.20000000e+01, 6.60000000e+01, 2.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 6.66666667e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 3.33333333e-01],\n",
       "       [3.48744315e+09, 1.00000000e+00, 6.70000000e+01, 5.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.42857143e-01, 8.57142857e-01],\n",
       "       [2.64870641e+09, 0.00000000e+00, 6.80000000e+01, 2.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [3.68127977e+09, 2.00000000e+00, 6.90000000e+01, 4.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.00000000e+00, 0.00000000e+00],\n",
       "       [4.45684127e+08, 0.00000000e+00, 7.00000000e+01, 4.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.00000000e+00, 0.00000000e+00],\n",
       "       [1.46761148e+09, 1.00000000e+00, 7.10000000e+01, 4.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.00000000e+00, 0.00000000e+00],\n",
       "       [3.32268851e+09, 2.00000000e+00, 7.20000000e+01, 4.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.00000000e+00, 0.00000000e+00],\n",
       "       [1.17380216e+09, 0.00000000e+00, 7.30000000e+01, 5.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.00000000e+00],\n",
       "       [1.73597285e+09, 4.80000000e+01, 7.40000000e+01, 2.00000000e+00,\n",
       "        6.66666667e-02, 0.00000000e+00, 8.66666667e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 6.66666667e-02],\n",
       "       [3.56429865e+08, 0.00000000e+00, 7.50000000e+01, 3.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [3.65310222e+09, 0.00000000e+00, 7.60000000e+01, 1.00000000e+00,\n",
       "        0.00000000e+00, 3.33333333e-01, 3.33333333e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 3.33333333e-01],\n",
       "       [2.68930207e+09, 7.00000000e+00, 7.70000000e+01, 0.00000000e+00,\n",
       "        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [4.14438896e+09, 9.60000000e+01, 7.80000000e+01, 4.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.00000000e+00, 0.00000000e+00],\n",
       "       [1.13938791e+08, 0.00000000e+00, 7.90000000e+01, 2.00000000e+00,\n",
       "        0.00000000e+00, 6.66666667e-02, 4.00000000e-01, 0.00000000e+00,\n",
       "        1.33333333e-01, 4.00000000e-01],\n",
       "       [2.21863081e+09, 1.00000000e+00, 8.00000000e+01, 5.00000000e+00,\n",
       "        1.66666667e-01, 0.00000000e+00, 1.66666667e-01, 0.00000000e+00,\n",
       "        1.66666667e-01, 5.00000000e-01],\n",
       "       [3.85895478e+09, 1.00000000e+00, 8.10000000e+01, 4.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.00000000e+00, 0.00000000e+00],\n",
       "       [1.83420300e+08, 4.00000000e+00, 8.20000000e+01, 4.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.33333333e-01,\n",
       "        6.66666667e-01, 0.00000000e+00],\n",
       "       [4.20477688e+09, 0.00000000e+00, 8.30000000e+01, 5.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.00000000e+00],\n",
       "       [2.67973332e+09, 0.00000000e+00, 8.40000000e+01, 0.00000000e+00,\n",
       "        7.14285714e-01, 0.00000000e+00, 1.42857143e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.42857143e-01],\n",
       "       [7.72660133e+08, 5.00000000e+00, 8.50000000e+01, 4.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        6.66666667e-01, 3.33333333e-01],\n",
       "       [9.53734706e+08, 1.00000000e+00, 8.60000000e+01, 5.00000000e+00,\n",
       "        0.00000000e+00, 2.50000000e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        2.50000000e-01, 5.00000000e-01],\n",
       "       [4.06018243e+09, 1.00000000e+00, 8.70000000e+01, 4.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.00000000e+00, 0.00000000e+00],\n",
       "       [3.54812160e+09, 3.00000000e+00, 8.80000000e+01, 2.00000000e+00,\n",
       "        0.00000000e+00, 3.84615385e-01, 5.38461538e-01, 7.69230769e-02,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [3.69081455e+09, 0.00000000e+00, 8.90000000e+01, 2.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [3.38080421e+08, 0.00000000e+00, 9.00000000e+01, 5.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.00000000e+00],\n",
       "       [3.65570213e+09, 0.00000000e+00, 9.10000000e+01, 5.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.00000000e+00],\n",
       "       [9.72017313e+08, 0.00000000e+00, 9.20000000e+01, 0.00000000e+00,\n",
       "        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [1.80945760e+09, 3.00000000e+00, 9.30000000e+01, 3.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [3.25706176e+09, 0.00000000e+00, 9.40000000e+01, 5.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.00000000e+00],\n",
       "       [3.01572528e+09, 4.00000000e+00, 9.50000000e+01, 2.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 3.33333333e-01, 0.00000000e+00,\n",
       "        3.33333333e-01, 3.33333333e-01],\n",
       "       [7.36099120e+08, 0.00000000e+00, 9.60000000e+01, 5.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.00000000e+00],\n",
       "       [3.81612200e+09, 0.00000000e+00, 9.70000000e+01, 1.00000000e+00,\n",
       "        0.00000000e+00, 3.33333333e-01, 0.00000000e+00, 3.33333333e-01,\n",
       "        0.00000000e+00, 3.33333333e-01],\n",
       "       [2.67691443e+09, 1.90000000e+01, 9.80000000e+01, 3.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.66666667e-01,\n",
       "        3.33333333e-01, 0.00000000e+00],\n",
       "       [8.80102017e+08, 0.00000000e+00, 9.90000000e+01, 5.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.00000000e+00]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_items = np.load(f'{devset_dir}/03_single_spectrograms_v1_test_items.npy')\n",
    "test_items = np.load(f'{devset_dir}/03_single_spectrograms_reduced_v1_test_items.npy')\n",
    "test_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2919599106</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1388328149</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2333880986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>242874105</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2560555204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>3015725284</td>\n",
       "      <td>4.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>736099120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>3816121998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2676914434</td>\n",
       "      <td>19.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>880102017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0     1     2    3    4         5         6         7         8  \\\n",
       "0   2919599106   9.0   0.0  0.0  1.0  0.000000  0.000000  0.000000  0.000000   \n",
       "1   1388328149   4.0   1.0  0.0  1.0  0.000000  0.000000  0.000000  0.000000   \n",
       "2   2333880986   0.0   2.0  5.0  0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "3    242874105   1.0   3.0  3.0  0.0  0.230769  0.000000  0.384615  0.000000   \n",
       "4   2560555204   0.0   4.0  5.0  0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "..         ...   ...   ...  ...  ...       ...       ...       ...       ...   \n",
       "95  3015725284   4.0  95.0  2.0  0.0  0.000000  0.333333  0.000000  0.333333   \n",
       "96   736099120   0.0  96.0  5.0  0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "97  3816121998   0.0  97.0  1.0  0.0  0.333333  0.000000  0.333333  0.000000   \n",
       "98  2676914434  19.0  98.0  3.0  0.0  0.000000  0.000000  0.666667  0.333333   \n",
       "99   880102017   0.0  99.0  5.0  0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "           9  \n",
       "0   0.000000  \n",
       "1   0.000000  \n",
       "2   1.000000  \n",
       "3   0.384615  \n",
       "4   1.000000  \n",
       "..       ...  \n",
       "95  0.333333  \n",
       "96  1.000000  \n",
       "97  0.333333  \n",
       "98  0.000000  \n",
       "99  1.000000  \n",
       "\n",
       "[100 rows x 10 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_items = pd.DataFrame(test_items)\n",
    "df_test_items[0] = df_test_items[0].astype(int)\n",
    "df_test_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>seizure_vote</th>\n",
       "      <th>lpd_vote</th>\n",
       "      <th>gpd_vote</th>\n",
       "      <th>lrda_vote</th>\n",
       "      <th>grda_vote</th>\n",
       "      <th>other_vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2919599106</td>\n",
       "      <td>0.165775</td>\n",
       "      <td>0.164264</td>\n",
       "      <td>0.167858</td>\n",
       "      <td>0.172230</td>\n",
       "      <td>0.165196</td>\n",
       "      <td>0.164676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1388328149</td>\n",
       "      <td>0.301435</td>\n",
       "      <td>0.097424</td>\n",
       "      <td>0.171351</td>\n",
       "      <td>0.169345</td>\n",
       "      <td>0.118289</td>\n",
       "      <td>0.142156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2333880986</td>\n",
       "      <td>0.165691</td>\n",
       "      <td>0.164168</td>\n",
       "      <td>0.167854</td>\n",
       "      <td>0.172094</td>\n",
       "      <td>0.165522</td>\n",
       "      <td>0.164670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>242874105</td>\n",
       "      <td>0.165537</td>\n",
       "      <td>0.164154</td>\n",
       "      <td>0.167782</td>\n",
       "      <td>0.172139</td>\n",
       "      <td>0.165670</td>\n",
       "      <td>0.164718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2560555204</td>\n",
       "      <td>0.165576</td>\n",
       "      <td>0.164221</td>\n",
       "      <td>0.167756</td>\n",
       "      <td>0.172314</td>\n",
       "      <td>0.165392</td>\n",
       "      <td>0.164740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>3015725284</td>\n",
       "      <td>0.165535</td>\n",
       "      <td>0.164122</td>\n",
       "      <td>0.167803</td>\n",
       "      <td>0.172173</td>\n",
       "      <td>0.165669</td>\n",
       "      <td>0.164698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>736099120</td>\n",
       "      <td>0.165511</td>\n",
       "      <td>0.164382</td>\n",
       "      <td>0.167886</td>\n",
       "      <td>0.172315</td>\n",
       "      <td>0.164602</td>\n",
       "      <td>0.165305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>3816121998</td>\n",
       "      <td>0.167423</td>\n",
       "      <td>0.164334</td>\n",
       "      <td>0.167089</td>\n",
       "      <td>0.172428</td>\n",
       "      <td>0.163189</td>\n",
       "      <td>0.165537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2676914434</td>\n",
       "      <td>0.165589</td>\n",
       "      <td>0.164178</td>\n",
       "      <td>0.167829</td>\n",
       "      <td>0.172097</td>\n",
       "      <td>0.165636</td>\n",
       "      <td>0.164671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>880102017</td>\n",
       "      <td>0.165578</td>\n",
       "      <td>0.164218</td>\n",
       "      <td>0.167777</td>\n",
       "      <td>0.172027</td>\n",
       "      <td>0.165690</td>\n",
       "      <td>0.164710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        eeg_id  seizure_vote  lpd_vote  gpd_vote  lrda_vote  grda_vote  \\\n",
       "0   2919599106      0.165775  0.164264  0.167858   0.172230   0.165196   \n",
       "1   1388328149      0.301435  0.097424  0.171351   0.169345   0.118289   \n",
       "2   2333880986      0.165691  0.164168  0.167854   0.172094   0.165522   \n",
       "3    242874105      0.165537  0.164154  0.167782   0.172139   0.165670   \n",
       "4   2560555204      0.165576  0.164221  0.167756   0.172314   0.165392   \n",
       "..         ...           ...       ...       ...        ...        ...   \n",
       "95  3015725284      0.165535  0.164122  0.167803   0.172173   0.165669   \n",
       "96   736099120      0.165511  0.164382  0.167886   0.172315   0.164602   \n",
       "97  3816121998      0.167423  0.164334  0.167089   0.172428   0.163189   \n",
       "98  2676914434      0.165589  0.164178  0.167829   0.172097   0.165636   \n",
       "99   880102017      0.165578  0.164218  0.167777   0.172027   0.165690   \n",
       "\n",
       "    other_vote  \n",
       "0     0.164676  \n",
       "1     0.142156  \n",
       "2     0.164670  \n",
       "3     0.164718  \n",
       "4     0.164740  \n",
       "..         ...  \n",
       "95    0.164698  \n",
       "96    0.165305  \n",
       "97    0.165537  \n",
       "98    0.164671  \n",
       "99    0.164710  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sub = pd.DataFrame({'eeg_id':df_test_items[0]})\n",
    "sub[TARGETS] = np.round(y_pred,6)\n",
    "sub.to_csv('submission.csv',index=False)\n",
    "sub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>seizure_vote</th>\n",
       "      <th>lpd_vote</th>\n",
       "      <th>gpd_vote</th>\n",
       "      <th>lrda_vote</th>\n",
       "      <th>grda_vote</th>\n",
       "      <th>other_vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2919599106</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1388328149</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2333880986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>242874105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2560555204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>3015725284</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>736099120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>3816121998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2676914434</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>880102017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        eeg_id  seizure_vote  lpd_vote  gpd_vote  lrda_vote  grda_vote  \\\n",
       "0   2919599106           1.0  0.000000  0.000000   0.000000   0.000000   \n",
       "1   1388328149           1.0  0.000000  0.000000   0.000000   0.000000   \n",
       "2   2333880986           0.0  0.000000  0.000000   0.000000   0.000000   \n",
       "3    242874105           0.0  0.230769  0.000000   0.384615   0.000000   \n",
       "4   2560555204           0.0  0.000000  0.000000   0.000000   0.000000   \n",
       "..         ...           ...       ...       ...        ...        ...   \n",
       "95  3015725284           0.0  0.000000  0.333333   0.000000   0.333333   \n",
       "96   736099120           0.0  0.000000  0.000000   0.000000   0.000000   \n",
       "97  3816121998           0.0  0.333333  0.000000   0.333333   0.000000   \n",
       "98  2676914434           0.0  0.000000  0.000000   0.666667   0.333333   \n",
       "99   880102017           0.0  0.000000  0.000000   0.000000   0.000000   \n",
       "\n",
       "    other_vote  \n",
       "0     0.000000  \n",
       "1     0.000000  \n",
       "2     1.000000  \n",
       "3     0.384615  \n",
       "4     1.000000  \n",
       "..         ...  \n",
       "95    0.333333  \n",
       "96    1.000000  \n",
       "97    0.333333  \n",
       "98    0.000000  \n",
       "99    1.000000  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_scoring = df_test_items[[0,4,5,6,7,8,9]]\n",
    "df_test_scoring.columns = sub.columns\n",
    "df_test_scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_54191/1033736718.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  solution[col] = solution[col].astype(float)\n",
      "/tmp/ipykernel_54191/1033736718.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  solution[col] = solution[col].astype(float)\n",
      "/tmp/ipykernel_54191/1033736718.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  solution[col] = solution[col].astype(float)\n",
      "/tmp/ipykernel_54191/1033736718.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  solution[col] = solution[col].astype(float)\n",
      "/tmp/ipykernel_54191/1033736718.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  solution[col] = solution[col].astype(float)\n",
      "/tmp/ipykernel_54191/1033736718.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  solution[col] = solution[col].astype(float)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.2980015586907085"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(df_test_scoring, sub, 'eeg_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gsdc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
