{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ce1a051",
   "metadata": {
    "papermill": {
     "duration": 0.006496,
     "end_time": "2024-03-10T18:18:35.037364",
     "exception": false,
     "start_time": "2024-03-10T18:18:35.030868",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CWT hyperparameters tuning\n",
    "\n",
    "Use GPU T4 x 2  \n",
    "When using GP100, there are XLA errors.  \n",
    "\n",
    "5 channels (LT, RT, LP, RP, C).\n",
    "\n",
    "Implementing tf.keras.metrics.KLDivergence().\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a159655",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 10:42:51.416753: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras_tuner'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers, regularizers\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras_tuner'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers, regularizers\n",
    "import keras_tuner as kt\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "# ----------------------------------------\n",
    "# Flags for working on my different machines.\n",
    "# flag_kaggle = True\n",
    "flag_FW = True\n",
    "# flag_LN = True\n",
    "\n",
    "try:\n",
    "    if flag_kaggle:\n",
    "        # sys.path.insert(0, '/kaggle/input/hms-lib')\n",
    "        base_dir = '/kaggle/input/hms-harmful-brain-activity-classification'\n",
    "        devset_dir = '/kaggle/input/hms-cwt-scalograms-single-numpy-v1'\n",
    "except:\n",
    "    pass \n",
    "\n",
    "try:\n",
    "    if flag_FW:\n",
    "        # sys.path.insert(0, '../lib')\n",
    "        base_dir = '../../kaggle_data/hms'\n",
    "        devset_dir = '../data'\n",
    "except:\n",
    "    pass \n",
    "\n",
    "try:\n",
    "    if flag_LN:\n",
    "        # sys.path.insert(0, '../lib')\n",
    "        base_dir = '../../data/hms'\n",
    "        devset_dir = '../data'\n",
    "except:\n",
    "    pass \n",
    "# ----------------------------------------\n",
    "\n",
    "\n",
    "# path_train = f'{devset_dir}/05_single_cwt_v1_train.npy'\n",
    "# path_train_items = f'{devset_dir}/05_single_cwt_v1_train_items.npy'\n",
    "# path_val = f'{devset_dir}/05_single_cwt_v1_val.npy'\n",
    "# path_val_items = f'{devset_dir}/05_single_cwt_v1_val_items.npy'\n",
    "# path_test = f'{devset_dir}/05_single_cwt_v1_test.npy'\n",
    "# path_test_items = f'{devset_dir}/05_single_cwt_v1_test_items.npy'\n",
    "\n",
    "path_train = f'{devset_dir}/05_reduced_single_cwt_v1_train.npy'\n",
    "path_train_items = f'{devset_dir}/05_reduced_single_cwt_v1_train_items.npy'\n",
    "path_val = f'{devset_dir}/05_reduced_single_cwt_v1_val.npy'\n",
    "path_val_items = f'{devset_dir}/05_reduced_single_cwt_v1_val_items.npy'\n",
    "path_test = f'{devset_dir}/05_reduced_single_cwt_v1_test.npy'\n",
    "path_test_items = f'{devset_dir}/05_reduced_single_cwt_v1_test_items.npy'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0cf1c6",
   "metadata": {
    "papermill": {
     "duration": 0.005678,
     "end_time": "2024-03-10T18:18:56.105732",
     "exception": false,
     "start_time": "2024-03-10T18:18:56.100054",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91fdf23d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T18:18:56.118838Z",
     "iopub.status.busy": "2024-03-10T18:18:56.118505Z",
     "iopub.status.idle": "2024-03-10T18:18:56.131377Z",
     "shell.execute_reply": "2024-03-10T18:18:56.130470Z"
    },
    "papermill": {
     "duration": 0.021808,
     "end_time": "2024-03-10T18:18:56.133354",
     "exception": false,
     "start_time": "2024-03-10T18:18:56.111546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Data generator for training.\n",
    "#\n",
    "# coefficients of cwt's arrays\n",
    "# 5 channels (LP, RP, LT, RP, C)\n",
    "#\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, path_to_items, path_to_data, batch_size=32, n_classes=6, shuffle=True):\n",
    "        ''' Initialization\n",
    "        item: [eeg_id, eeg_sub_id, idx in sgrams (1st index), target,\n",
    "        seizure_vote, lpd_vote, gpd_vote, lrda_vote,\n",
    "        grda_vote, other_vote]\n",
    "        '''\n",
    "        self.n_channels = 5\n",
    "        # self.n_freqs = 40\n",
    "\n",
    "        self.data = np.load(path_to_data)\n",
    "        self.items = np.load(path_to_items)\n",
    "        self.dim = (self.data.shape[1], self.data.shape[2])\n",
    "        self.batch_size = batch_size\n",
    "        self.len = self.data.shape[0]\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.ceil(self.len / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(indexes)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def get_dim(self):\n",
    "        'Dimensions for the input layer.'\n",
    "        return (self.dim[0], self.dim[1], self.n_channels)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(self.len)\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, indexes):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        true_size = len(indexes)\n",
    "        X = np.empty((true_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((true_size, self.n_classes), dtype=float)\n",
    "\n",
    "        # Generate data\n",
    "        for i, idx in enumerate(indexes):\n",
    "            item = self.items[idx]\n",
    "            # print(item)  # Uncomment for testing.\n",
    "            X[i,:,:,:] = self.data[np.int32(item[2]), :, :, :]\n",
    "            # Store solution\n",
    "            y[i,:] = item[-6:]\n",
    "\n",
    "        return X, y\n",
    "\n",
    "\n",
    "# #\n",
    "# # Test Data generator for predicting\n",
    "# # \n",
    "\n",
    "# class TestDataGenerator(keras.utils.Sequence):\n",
    "#     'Generates data for Keras'\n",
    "#     def __init__(self, path_to_items, path_to_data, batch_size=32, n_classes=6, shuffle=False):\n",
    "#         ''' Initialization\n",
    "#         item: [eeg_id, eeg_sub_id, idx in sgrams (1st index), target,\n",
    "#         seizure_vote, lpd_vote, gpd_vote, lrda_vote,\n",
    "#         grda_vote, other_vote]\n",
    "#         '''\n",
    "#         self.n_channels = 5\n",
    "#         self.data = np.load(path_to_data)\n",
    "#         self.items = np.load(path_to_items)\n",
    "#         self.dim = (self.data.shape[1], self.data.shape[2])\n",
    "#         self.batch_size = batch_size\n",
    "#         self.len = self.data.shape[0]\n",
    "#         self.n_classes = n_classes\n",
    "#         self.shuffle = shuffle\n",
    "#         self.on_epoch_end()\n",
    "\n",
    "#     def __len__(self):\n",
    "#         'Denotes the number of batches per epoch'\n",
    "#         return int(np.ceil(self.len / self.batch_size))\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         'Generate one batch of data'\n",
    "#         # Generate indexes of the batch\n",
    "#         indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "#         # Generate data\n",
    "#         X = self.__data_generation(indexes)\n",
    "\n",
    "#         return X\n",
    "\n",
    "#     def get_dim(self):\n",
    "#         'Dimensions for the input layer.'\n",
    "#         return (self.dim[0], self.dim[1], self.n_channels)\n",
    "\n",
    "#     def on_epoch_end(self):\n",
    "#         'Updates indexes after each epoch'\n",
    "#         self.indexes = np.arange(self.len)\n",
    "#         # pass \n",
    "        \n",
    "#     def __data_generation(self, indexes):\n",
    "#         'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "#         # Initialization\n",
    "#         true_size = len(indexes)\n",
    "#         X = np.empty((true_size, *self.dim, self.n_channels))\n",
    "\n",
    "#         # Generate data\n",
    "#         for i, idx in enumerate(indexes):\n",
    "#             item = self.items[idx]\n",
    "#             # print(item)  # Uncomment for testing.\n",
    "#             X[i,:,:,:] = self.data[np.int32(item[2]), :, :, :]\n",
    "\n",
    "#         return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b7e39b",
   "metadata": {},
   "source": [
    "## HP tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69b4991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Flatten())\n",
    "    # Tune the number of layers.\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 3)):\n",
    "        model.add(\n",
    "            layers.Dense(\n",
    "                # Tune number of units separately.\n",
    "                units=hp.Int(f\"units_{i}\", min_value=32, max_value=512, step=32),\n",
    "                activation=hp.Choice(\"activation\", [\"relu\", \"tanh\"]),\n",
    "            )\n",
    "        )\n",
    "    if hp.Boolean(\"dropout\"):\n",
    "        model.add(layers.Dropout(rate=0.25))\n",
    "    model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "    # learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "    learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "build_model(kt.HyperParameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56942957",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = keras_tuner.RandomSearch(\n",
    "    hypermodel=build_model,\n",
    "    # objective=\"val_accuracy\",\n",
    "    objective=keras_tuner.Objective(\"val_mean_absolute_error\", direction=\"min\"),\n",
    "    max_trials=3,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"helloworld\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6e2c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4adc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(x_train, y_train, epochs=2, validation_data=(x_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d51582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 2 models.\n",
    "models = tuner.get_best_models(num_models=2)\n",
    "best_model = models[0]\n",
    "best_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9712704a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195946bc",
   "metadata": {},
   "source": [
    "## Retrain the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0d5872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 2 hyperparameters.\n",
    "best_hps = tuner.get_best_hyperparameters(5)\n",
    "# Build the model with the best hp.\n",
    "model = build_model(best_hps[0])\n",
    "# Fit with the entire dataset.\n",
    "x_all = np.concatenate((x_train, x_val))\n",
    "y_all = np.concatenate((y_train, y_val))\n",
    "model.fit(x=x_all, y=y_all, epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "049d1a54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T18:18:56.146419Z",
     "iopub.status.busy": "2024-03-10T18:18:56.146114Z",
     "iopub.status.idle": "2024-03-10T18:18:56.154477Z",
     "shell.execute_reply": "2024-03-10T18:18:56.153798Z"
    },
    "papermill": {
     "duration": 0.016959,
     "end_time": "2024-03-10T18:18:56.156327",
     "exception": false,
     "start_time": "2024-03-10T18:18:56.139368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def make_model(input_shape, num_classes):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "\n",
    "    #max1 = keras.layers.MaxPooling1D(pool_size=2)(input_layer)\n",
    "    \n",
    "    conv1 = keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\")(input_layer)\n",
    "    #conv1 = keras.layers.BatchNormalization()(conv1)\n",
    "    # conv1 = keras.layers.MaxPooling2D(pool_size=8)(conv1)\n",
    "    conv1 = keras.layers.ReLU()(conv1)\n",
    "    \n",
    "    conv2 = keras.layers.Conv2D(filters=64, kernel_size=5, padding=\"same\")(conv1)\n",
    "    #conv2 = keras.layers.BatchNormalization()(conv2)\n",
    "    # conv2 = keras.layers.MaxPooling2D(pool_size=8)(conv2)\n",
    "    conv2 = keras.layers.ReLU()(conv2)\n",
    "\n",
    "    conv3 = keras.layers.Conv2D(filters=256, kernel_size=3, padding=\"same\")(conv2)\n",
    "    #conv3 = keras.layers.BatchNormalization()(conv3)\n",
    "    conv3 = keras.layers.MaxPooling2D(pool_size=2)(conv3)\n",
    "    conv3 = keras.layers.ReLU()(conv3)\n",
    "\n",
    "#     conv4 = keras.layers.Conv2D(filters=512, kernel_size=3, padding=\"same\")(conv3)\n",
    "#     conv4 = keras.layers.BatchNormalization()(conv4)\n",
    "#     conv4 = keras.layers.MaxPooling2D(pool_size=4)(conv4)\n",
    "#     conv4 = keras.layers.ReLU()(conv4)\n",
    "\n",
    "    fltn  = keras.layers.Flatten()(conv3) \n",
    "    \n",
    "    relu1 = keras.layers.Dense(128)(fltn)\n",
    "    relu1 = keras.layers.ReLU()(relu1)\n",
    "\n",
    "#     relu2 = keras.layers.Dense(64)(relu1)\n",
    "#     relu2 = keras.layers.ReLU(64)(relu2)\n",
    "\n",
    "#     lin = keras.layers.Dense(2)(relu2)\n",
    "\n",
    "    output_layer = keras.layers.Dense(num_classes, activation=\"softmax\")(relu1)\n",
    "\n",
    "    return keras.models.Model(inputs=input_layer, outputs=output_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94d7713a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T18:18:56.168383Z",
     "iopub.status.busy": "2024-03-10T18:18:56.168110Z",
     "iopub.status.idle": "2024-03-10T18:20:40.646261Z",
     "shell.execute_reply": "2024-03-10T18:20:40.645338Z"
    },
    "papermill": {
     "duration": 104.492282,
     "end_time": "2024-03-10T18:20:40.654131",
     "exception": false,
     "start_time": "2024-03-10T18:18:56.161849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations in training set: 12192\n",
      "Observations in validation set: 2176\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "params = {\n",
    "    'batch_size': 32,\n",
    "    'n_classes': 6,\n",
    "    'shuffle': True\n",
    "    }\n",
    "\n",
    "training_generator = DataGenerator(path_train_items, path_train , **params)\n",
    "validation_generator = DataGenerator(path_val_items, path_val, **params)\n",
    "\n",
    "print(\"Observations in training set:\", training_generator.__len__()*params['batch_size'])\n",
    "print(\"Observations in validation set:\", validation_generator.__len__()*params['batch_size'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a0e23ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T18:20:40.667070Z",
     "iopub.status.busy": "2024-03-10T18:20:40.666804Z",
     "iopub.status.idle": "2024-03-10T18:20:40.671134Z",
     "shell.execute_reply": "2024-03-10T18:20:40.670248Z"
    },
    "papermill": {
     "duration": 0.013241,
     "end_time": "2024-03-10T18:20:40.673351",
     "exception": false,
     "start_time": "2024-03-10T18:20:40.660110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint_filepath = 'checkpoint2.model.keras'\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='val_kl_divergence',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e85144a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T18:20:40.685912Z",
     "iopub.status.busy": "2024-03-10T18:20:40.685432Z",
     "iopub.status.idle": "2024-03-10T18:40:41.572648Z",
     "shell.execute_reply": "2024-03-10T18:40:41.571736Z"
    },
    "papermill": {
     "duration": 1200.89593,
     "end_time": "2024-03-10T18:40:41.574772",
     "exception": false,
     "start_time": "2024-03-10T18:20:40.678842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/381\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:11:27\u001b[0m 30s/step - kl_divergence: 0.0373 - loss: 0.0373"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1710094887.885214      74 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "W0000 00:00:1710094887.906206      74 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - kl_divergence: 0.0754 - loss: 0.0754"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1710094980.422426      74 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 276ms/step - kl_divergence: 0.0754 - loss: 0.0754 - val_kl_divergence: 0.6311 - val_loss: 0.6233\n",
      "Epoch 2/15\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 196ms/step - kl_divergence: 0.0502 - loss: 0.0503 - val_kl_divergence: 0.6588 - val_loss: 0.6506\n",
      "Epoch 3/15\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 196ms/step - kl_divergence: 0.0418 - loss: 0.0418 - val_kl_divergence: 0.6829 - val_loss: 0.6751\n",
      "Epoch 4/15\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 196ms/step - kl_divergence: 0.0443 - loss: 0.0443 - val_kl_divergence: 0.6666 - val_loss: 0.6802\n",
      "Epoch 5/15\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 196ms/step - kl_divergence: 0.0446 - loss: 0.0446 - val_kl_divergence: 0.7022 - val_loss: 0.6935\n",
      "Epoch 6/15\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 196ms/step - kl_divergence: 0.0462 - loss: 0.0462 - val_kl_divergence: 0.6773 - val_loss: 0.6709\n",
      "Epoch 7/15\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 196ms/step - kl_divergence: 0.0430 - loss: 0.0430 - val_kl_divergence: 0.6678 - val_loss: 0.6702\n",
      "Epoch 8/15\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 196ms/step - kl_divergence: 0.0443 - loss: 0.0443 - val_kl_divergence: 0.6611 - val_loss: 0.6735\n",
      "Epoch 9/15\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 196ms/step - kl_divergence: 0.0421 - loss: 0.0421 - val_kl_divergence: 0.6744 - val_loss: 0.6658\n",
      "Epoch 10/15\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 196ms/step - kl_divergence: 0.0412 - loss: 0.0412 - val_kl_divergence: 0.6756 - val_loss: 0.6674\n",
      "Epoch 11/15\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 196ms/step - kl_divergence: 0.0376 - loss: 0.0376 - val_kl_divergence: 0.6891 - val_loss: 0.6946\n",
      "Epoch 12/15\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 196ms/step - kl_divergence: 0.0352 - loss: 0.0352 - val_kl_divergence: 0.6807 - val_loss: 0.6761\n",
      "Epoch 13/15\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 196ms/step - kl_divergence: 0.0369 - loss: 0.0368 - val_kl_divergence: 0.6903 - val_loss: 0.7090\n",
      "Epoch 14/15\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 196ms/step - kl_divergence: 0.0359 - loss: 0.0359 - val_kl_divergence: 0.6719 - val_loss: 0.6772\n",
      "Epoch 15/15\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 196ms/step - kl_divergence: 0.0334 - loss: 0.0334 - val_kl_divergence: 0.6940 - val_loss: 0.7021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x78bf12962500>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = keras.optimizers.SGD(\n",
    "    learning_rate=0.007,\n",
    "    momentum=0.01,\n",
    ")\n",
    "\n",
    "# opt = keras.optimizers.Adam(\n",
    "#     learning_rate=0.004,\n",
    "# )\n",
    "\n",
    "dim = training_generator.get_dim()\n",
    "\n",
    "model = make_model(input_shape=dim, num_classes=6)\n",
    "\n",
    "model.load_weights('/kaggle/input/hms-model-cwt-v1/checkpoint.model.keras')\n",
    "\n",
    "model.compile(optimizer=opt,\n",
    "            loss=tf.keras.losses.KLDivergence(),\n",
    "            metrics=[tf.keras.metrics.KLDivergence()])\n",
    "\n",
    "model.fit(training_generator, epochs=15,\n",
    "          validation_data=validation_generator,\n",
    "          callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd3b32c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T18:40:42.669540Z",
     "iopub.status.busy": "2024-03-10T18:40:42.669185Z",
     "iopub.status.idle": "2024-03-10T18:40:49.407414Z",
     "shell.execute_reply": "2024-03-10T18:40:49.406476Z"
    },
    "papermill": {
     "duration": 7.278809,
     "end_time": "2024-03-10T18:40:49.410080",
     "exception": false,
     "start_time": "2024-03-10T18:40:42.131271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save(\"model_cwt_031001_057.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc12244e",
   "metadata": {
    "papermill": {
     "duration": 0.478171,
     "end_time": "2024-03-10T18:40:50.370123",
     "exception": false,
     "start_time": "2024-03-10T18:40:49.891952",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2668dfda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T18:40:51.394244Z",
     "iopub.status.busy": "2024-03-10T18:40:51.393492Z",
     "iopub.status.idle": "2024-03-10T18:40:51.400345Z",
     "shell.execute_reply": "2024-03-10T18:40:51.399372Z"
    },
    "papermill": {
     "duration": 0.544821,
     "end_time": "2024-03-10T18:40:51.402383",
     "exception": false,
     "start_time": "2024-03-10T18:40:50.857562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TARGETS = ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n",
    "\n",
    "# #\n",
    "# # Test Data generator: for predicting\n",
    "# # using own test set.\n",
    "# # (Not for predicting LB)\n",
    "# #\n",
    "\n",
    "# class TestDataGenerator(keras.utils.Sequence):\n",
    "#     'Generates data for Keras'\n",
    "#     def __init__(self, path_to_items, path_to_data, batch_size=32, n_classes=6, shuffle=False):\n",
    "#         ''' Initialization\n",
    "#         item: [eeg_id, eeg_sub_id, idx in sgrams (1st index), target,\n",
    "#         seizure_vote, lpd_vote, gpd_vote, lrda_vote,\n",
    "#         grda_vote, other_vote]\n",
    "#         '''\n",
    "#         self.n_channels = 5\n",
    "#         self.data = np.load(path_to_data)\n",
    "#         self.items = np.load(path_to_items)\n",
    "#         self.dim = (self.data.shape[1], self.data.shape[2])\n",
    "#         self.batch_size = batch_size\n",
    "#         self.len = self.data.shape[0]\n",
    "#         self.n_classes = n_classes\n",
    "#         self.shuffle = shuffle\n",
    "#         self.on_epoch_end()\n",
    "\n",
    "#     def __len__(self):\n",
    "#         'Denotes the number of batches per epoch'\n",
    "#         return int(np.ceil(self.len / self.batch_size))\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         'Generate one batch of data'\n",
    "#         # Generate indexes of the batch\n",
    "#         indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "#         # Generate data\n",
    "#         X = self.__data_generation(indexes)\n",
    "\n",
    "#         return X\n",
    "\n",
    "#     def get_dim(self):\n",
    "#         'Dimensions for the input layer.'\n",
    "#         return (self.dim[0], self.dim[1], self.n_channels)\n",
    "\n",
    "#     def on_epoch_end(self):\n",
    "#         'Updates indexes after each epoch'\n",
    "#         self.indexes = np.arange(self.len)\n",
    "#         # pass \n",
    "        \n",
    "#     def __data_generation(self, indexes):\n",
    "#         'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "#         # Initialization\n",
    "#         true_size = len(indexes)\n",
    "#         X = np.empty((true_size, *self.dim, self.n_channels))\n",
    "\n",
    "#         # Generate data\n",
    "#         for i, idx in enumerate(indexes):\n",
    "#             item = self.items[idx]\n",
    "#             # print(item)  # Uncomment for testing.\n",
    "#             X[i,:,:,:] = self.data[np.int32(item[2]), :, :, :]\n",
    "\n",
    "#         return X\n",
    "    \n",
    "                \n",
    "# params = {\n",
    "#     'batch_size': 32,\n",
    "#     'n_classes': 6,\n",
    "#     }\n",
    "\n",
    "# test_generator = TestDataGenerator(path_test_items, path_test, **params)\n",
    "\n",
    "# y_pred = model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1836d269",
   "metadata": {
    "papermill": {
     "duration": 0.480662,
     "end_time": "2024-03-10T18:40:52.363886",
     "exception": false,
     "start_time": "2024-03-10T18:40:51.883224",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Scoring without submission\n",
    "\n",
    "Using a local test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a79602d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T18:40:53.316543Z",
     "iopub.status.busy": "2024-03-10T18:40:53.315744Z",
     "iopub.status.idle": "2024-03-10T18:40:53.320351Z",
     "shell.execute_reply": "2024-03-10T18:40:53.319446Z"
    },
    "papermill": {
     "duration": 0.477216,
     "end_time": "2024-03-10T18:40:53.322237",
     "exception": false,
     "start_time": "2024-03-10T18:40:52.845021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_items = np.load(path_test_items)\n",
    "# # test_items = np.load(f'{devset_dir}/03_single_spectrograms_reduced_v1_test_items.npy')\n",
    "# df_test_items = pd.DataFrame(test_items)\n",
    "# df_test_items[0] = df_test_items[0].astype(int)\n",
    "\n",
    "# sub = pd.DataFrame({'eeg_id':df_test_items[0]})\n",
    "# sub[TARGETS] = np.round(y_pred,6)\n",
    "# sub.to_csv('submission.csv',index=False)\n",
    "\n",
    "# df_test_scoring = df_test_items[[0,4,5,6,7,8,9]]\n",
    "# df_test_scoring.columns = sub.columns\n",
    "# # df_test_scoring\n",
    "\n",
    "# score(df_test_scoring, sub, 'eeg_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e41d1d",
   "metadata": {
    "papermill": {
     "duration": 0.551778,
     "end_time": "2024-03-10T18:40:54.415932",
     "exception": false,
     "start_time": "2024-03-10T18:40:53.864154",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Uniform probabilities classificator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdcd8ffb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T18:40:55.437526Z",
     "iopub.status.busy": "2024-03-10T18:40:55.437122Z",
     "iopub.status.idle": "2024-03-10T18:40:55.441857Z",
     "shell.execute_reply": "2024-03-10T18:40:55.440875Z"
    },
    "papermill": {
     "duration": 0.497398,
     "end_time": "2024-03-10T18:40:55.444381",
     "exception": false,
     "start_time": "2024-03-10T18:40:54.946983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_npy = np.load(path_test)\n",
    "# test_items = np.load(path_test_items)\n",
    "\n",
    "# y_pred = np.ones((test_items.shape[0],6),dtype=float)\n",
    "# y_pred[:,0:4] = y_pred[:,0:4] * 0.167\n",
    "# y_pred[:,4:] = y_pred[:,4:] * 0.166\n",
    "\n",
    "# df_test_items = pd.DataFrame(test_items)\n",
    "# df_test_items[0] = df_test_items[0].astype(int)\n",
    "\n",
    "# sub = pd.DataFrame({'eeg_id':df_test_items[0]})\n",
    "# sub[TARGETS] = np.round(y_pred,6)\n",
    "# # sub.to_csv('submission.csv',index=False)\n",
    "\n",
    "# df_test_scoring = df_test_items[[0,4,5,6,7,8,9]]\n",
    "# df_test_scoring.columns = sub.columns\n",
    "\n",
    "# score(df_test_scoring, sub, 'eeg_id')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1377c5",
   "metadata": {
    "papermill": {
     "duration": 0.522395,
     "end_time": "2024-03-10T18:40:56.447174",
     "exception": false,
     "start_time": "2024-03-10T18:40:55.924779",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submit to LB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6fef7d",
   "metadata": {
    "papermill": {
     "duration": 0.476047,
     "end_time": "2024-03-10T18:40:57.413213",
     "exception": false,
     "start_time": "2024-03-10T18:40:56.937166",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 7469972,
     "sourceId": 59093,
     "sourceType": "competition"
    },
    {
     "datasetId": 4432380,
     "sourceId": 7611741,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4551183,
     "sourceId": 7777833,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4573788,
     "sourceId": 7809333,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1350.918643,
   "end_time": "2024-03-10T18:41:01.896576",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-10T18:18:30.977933",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
