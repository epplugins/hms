{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split spectrograms into channels\n",
    "\n",
    "Running time: Comparison between using only numpy and loading parquet files inside the data generators.\n",
    "\n",
    "Reading parquet files in data generator: TOO SLOW, it does not use GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "base_dir = '../../kaggle_data/hms'\n",
    "# base_dir = '../../data/hms'\n",
    "# base_dir = '/kaggle/input/hms-harmful-brain-activity-classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train.csv. Added target column.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>eeg_sub_id</th>\n",
       "      <th>eeg_label_offset_seconds</th>\n",
       "      <th>spectrogram_id</th>\n",
       "      <th>spectrogram_sub_id</th>\n",
       "      <th>spectrogram_label_offset_seconds</th>\n",
       "      <th>label_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>expert_consensus</th>\n",
       "      <th>seizure_vote</th>\n",
       "      <th>lpd_vote</th>\n",
       "      <th>gpd_vote</th>\n",
       "      <th>lrda_vote</th>\n",
       "      <th>grda_vote</th>\n",
       "      <th>other_vote</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1628180742</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353733</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127492639</td>\n",
       "      <td>42516</td>\n",
       "      <td>Seizure</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1628180742</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>353733</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3887563113</td>\n",
       "      <td>42516</td>\n",
       "      <td>Seizure</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1628180742</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>353733</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1142670488</td>\n",
       "      <td>42516</td>\n",
       "      <td>Seizure</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1628180742</td>\n",
       "      <td>3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>353733</td>\n",
       "      <td>3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2718991173</td>\n",
       "      <td>42516</td>\n",
       "      <td>Seizure</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1628180742</td>\n",
       "      <td>4</td>\n",
       "      <td>24.0</td>\n",
       "      <td>353733</td>\n",
       "      <td>4</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3080632009</td>\n",
       "      <td>42516</td>\n",
       "      <td>Seizure</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       eeg_id  eeg_sub_id  eeg_label_offset_seconds  spectrogram_id  \\\n",
       "0  1628180742           0                       0.0          353733   \n",
       "1  1628180742           1                       6.0          353733   \n",
       "2  1628180742           2                       8.0          353733   \n",
       "3  1628180742           3                      18.0          353733   \n",
       "4  1628180742           4                      24.0          353733   \n",
       "\n",
       "   spectrogram_sub_id  spectrogram_label_offset_seconds    label_id  \\\n",
       "0                   0                               0.0   127492639   \n",
       "1                   1                               6.0  3887563113   \n",
       "2                   2                               8.0  1142670488   \n",
       "3                   3                              18.0  2718991173   \n",
       "4                   4                              24.0  3080632009   \n",
       "\n",
       "   patient_id expert_consensus  seizure_vote  lpd_vote  gpd_vote  lrda_vote  \\\n",
       "0       42516          Seizure             3         0         0          0   \n",
       "1       42516          Seizure             3         0         0          0   \n",
       "2       42516          Seizure             3         0         0          0   \n",
       "3       42516          Seizure             3         0         0          0   \n",
       "4       42516          Seizure             3         0         0          0   \n",
       "\n",
       "   grda_vote  other_vote  target  \n",
       "0          0           0     0.0  \n",
       "1          0           0     0.0  \n",
       "2          0           0     0.0  \n",
       "3          0           0     0.0  \n",
       "4          0           0     0.0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_traincsv = pd.read_csv(f'{base_dir}/train.csv')\n",
    "\n",
    "TARGETS = ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n",
    "\n",
    "df_traincsv = pd.read_csv(f'{base_dir}/train.csv')\n",
    "df_traincsv.loc[df_traincsv.expert_consensus == 'Seizure', 'target'] = 0\n",
    "df_traincsv.loc[df_traincsv.expert_consensus == 'LPD', 'target'] = 1\n",
    "df_traincsv.loc[df_traincsv.expert_consensus == 'GPD', 'target'] = 2\n",
    "df_traincsv.loc[df_traincsv.expert_consensus == 'LRDA', 'target'] = 3\n",
    "df_traincsv.loc[df_traincsv.expert_consensus == 'GRDA', 'target'] = 4\n",
    "df_traincsv.loc[df_traincsv.expert_consensus == 'Other', 'target'] = 5\n",
    "\n",
    "idxs_wo_nan = np.load(\"../data/02_eegs_idxs_up_to_5_nan.npy\")\n",
    "\n",
    "# Removing observations where eeg has more than 5 NaN rows.\n",
    "df = df_traincsv.iloc[idxs_wo_nan]\n",
    "\n",
    "print(\"Loaded train.csv. Added target column.\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 84191\n",
      "Validation samples: 22167\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Train/Val split (v1)\n",
    "#\n",
    "\n",
    "ptrain = 0.8\n",
    "\n",
    "# Set the seed for reproducibility.\n",
    "rng = np.random.default_rng(113)\n",
    "# rng = np.random.default_rng(45163)\n",
    "# rng = np.random.default_rng(3233)\n",
    "\n",
    "ids = rng.permutation(np.unique(df['patient_id']))\n",
    "cut = int(ptrain * len(ids))\n",
    "idxs_train = df.loc[df['patient_id'].isin(ids[0:cut])].index\n",
    "idxs_val = df.loc[df['patient_id'].isin(ids[cut:])].index\n",
    "\n",
    "print(\"Train samples:\", len(idxs_train))\n",
    "print(\"Validation samples:\", len(idxs_val))\n",
    "\n",
    "#\n",
    "# -----------------\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Data generator to load parquet files for each batch.\n",
    "#\n",
    "# Original spectrograms.\n",
    "# 50 seconds slice\n",
    "# 4 channels\n",
    "#\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, df, path_to_data, batch_size=32, n_classes=6, shuffle=True):\n",
    "        ''' Initialization\n",
    "        df: dataframe extracted from train.csv with training set.\n",
    "        path_to_data: folder with parquet files.\n",
    "        '''\n",
    "        self.n_channels = 4\n",
    "        # self.max_freq = 30  # Max freq. is 19.92 Hz in given spectrograms.\n",
    "\n",
    "        # 62 features: frequencies above 8 Hz (and less than 20 Hz)\n",
    "        self.dim = (25, 62)\n",
    "\n",
    "        self.path_to_data = path_to_data\n",
    "        # self.idxs = idxs\n",
    "        self.df = df\n",
    "        self.batch_size = batch_size\n",
    "        self.len = len(df)\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.ceil(self.len / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(indexes)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(self.len)\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, indexes):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        true_size = len(indexes)\n",
    "        X = np.empty((true_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((true_size), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, idx in enumerate(indexes):\n",
    "            item = self.df.iloc[idx]\n",
    "            df_spec = pd.read_parquet(f'{self.path_to_data}/{item.spectrogram_id}.parquet')\n",
    "            offset = item.spectrogram_label_offset_seconds\n",
    "            # 50 seconds centered in the 10 minutes slice.\n",
    "            spectrogram = df_spec.loc[(df_spec.time>=(offset+275)) & (df_spec.time<(offset+325))].values\n",
    "            #replace NaNs\n",
    "\n",
    "            for c in np.arange(self.n_channels):\n",
    "                cinitial = c * 100\n",
    "                cfinal = cinitial + 62\n",
    "                X[i,:,:,c] = spectrogram[:, cinitial:cfinal]\n",
    "            # Store class\n",
    "            y[i] = item.target\n",
    "\n",
    "        return X, keras.utils.to_categorical(y, num_classes=self.n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #\n",
    "# # Data generator using numpy and no pandas.\n",
    "# #\n",
    "# # Original spectrograms.\n",
    "# # 50 seconds slice\n",
    "# # 4 channels\n",
    "# #\n",
    "\n",
    "# class DataGenerator(keras.utils.Sequence):\n",
    "#     'Generates data for Keras'\n",
    "#     def __init__(self, items, data, batch_size=32, n_classes=6, shuffle=True):\n",
    "#         ''' Initialization\n",
    "#         items: [eeg_id, eeg_sub_id, idx of offset, target]\n",
    "#         '''\n",
    "#         self.n_channels = 4\n",
    "#         self.n_freqs = 40\n",
    "#         self.dim = (25, self.n_freqs)\n",
    "\n",
    "#         self.data = data\n",
    "#         self.items = items\n",
    "#         self.batch_size = batch_size\n",
    "#         self.len = items.shape[0]\n",
    "#         self.n_classes = n_classes\n",
    "#         self.shuffle = shuffle\n",
    "#         self.on_epoch_end()\n",
    "\n",
    "#     def __len__(self):\n",
    "#         'Denotes the number of batches per epoch'\n",
    "#         return int(np.ceil(self.len / self.batch_size))\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         'Generate one batch of data'\n",
    "#         # Generate indexes of the batch\n",
    "#         indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "#         # Generate data\n",
    "#         X, y = self.__data_generation(indexes)\n",
    "\n",
    "#         return X, y\n",
    "\n",
    "#     def on_epoch_end(self):\n",
    "#         'Updates indexes after each epoch'\n",
    "#         self.indexes = np.arange(self.len)\n",
    "#         if self.shuffle == True:\n",
    "#             np.random.shuffle(self.indexes)\n",
    "\n",
    "#     def __data_generation(self, indexes):\n",
    "#         'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "#         # Initialization\n",
    "#         true_size = len(indexes)\n",
    "#         X = np.empty((true_size, *self.dim, self.n_channels))\n",
    "#         y = np.empty((true_size), dtype=int)\n",
    "\n",
    "#         # Generate data\n",
    "#         for i, idx in enumerate(indexes):\n",
    "#             item = self.items[idx]\n",
    "#             # print(item)  # Uncomment for testing.\n",
    "#             # Sample is 50 second long, that's 25 rows.\n",
    "#             initial = item[2] + 137\n",
    "#             final = initial + 25\n",
    "#             for c in np.arange(self.n_channels):\n",
    "#                 cinitial = c * 100\n",
    "#                 cfinal = cinitial + self.n_freqs\n",
    "#                 X[i,:,:,c] = self.data[initial:final, cinitial:cfinal]\n",
    "#             # Store class\n",
    "#             y[i] = item[3]\n",
    "\n",
    "#         return X, keras.utils.to_categorical(y, num_classes=self.n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_model(input_shape, num_classes):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "\n",
    "    conv1 = keras.layers.Conv2D(filters=32,\n",
    "                                kernel_size=3,\n",
    "                                strides=1,\n",
    "                                padding=\"same\",\n",
    "                                data_format=\"channels_last\",\n",
    "                                # kernel_regularizer=regularizers.l2(0.001),\n",
    "                                # use_bias=True,\n",
    "                                )(input_layer)\n",
    "    conv1 = keras.layers.BatchNormalization()(conv1)\n",
    "    # conv1 = keras.layers.MaxPooling2D(pool_size=8)(conv1)\n",
    "    conv1 = keras.layers.ReLU()(conv1)\n",
    "    \n",
    "    conv2 = keras.layers.Conv2D(filters=32,\n",
    "                                kernel_size=5,\n",
    "                                padding=\"same\",\n",
    "                                data_format=\"channels_last\",\n",
    "                                )(conv1)\n",
    "    #conv2 = keras.layers.BatchNormalization()(conv2)\n",
    "    # conv2 = keras.layers.MaxPooling2D(pool_size=8)(conv2)\n",
    "    conv2 = keras.layers.ReLU()(conv2)\n",
    "\n",
    "    conv3 = keras.layers.Conv2D(filters=64,\n",
    "                                kernel_size=7,\n",
    "                                padding=\"same\",\n",
    "                                data_format=\"channels_last\",\n",
    "                                )(conv2)\n",
    "    conv3 = keras.layers.ReLU()(conv3)\n",
    "    # conv3 = keras.layers.MaxPooling2D(pool_size=2)(conv3)\n",
    "\n",
    "    conv4 = keras.layers.Conv2D(filters=64,\n",
    "                                kernel_size=3,\n",
    "                                padding=\"same\",\n",
    "                                data_format=\"channels_last\",\n",
    "                                )(conv3)\n",
    "    # conv4 = keras.layers.BatchNormalization()(conv4)\n",
    "    conv4 = keras.layers.ReLU()(conv4)\n",
    "    conv4 = keras.layers.MaxPooling2D(pool_size=2)(conv4)\n",
    "\n",
    "    fltn  = keras.layers.Flatten()(conv4) \n",
    "    dense1 = keras.layers.Dense(256)(fltn)\n",
    "    # dout1 = keras.layers.Dropout(rate=0.4)(dense1)\n",
    "    \n",
    "    # relu1 = keras.layers.Dense(256)(fltn)\n",
    "    # relu1 = keras.layers.ReLU()(relu1)\n",
    "\n",
    "    # relu2 = keras.layers.Dense(64)(relu1)\n",
    "    # relu2 = keras.layers.ReLU(64)(relu2)\n",
    "\n",
    "#     lin = keras.layers.Dense(2)(relu2)\n",
    "\n",
    "    output_layer = keras.layers.Dense(num_classes, activation=\"softmax\")(dense1)\n",
    "\n",
    "    return keras.models.Model(inputs=input_layer, outputs=output_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      " 164/2631 [>.............................] - ETA: 28:55 - loss: 1.7906 - accuracy: 0.1879"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 18\u001b[0m\n\u001b[1;32m     13\u001b[0m model \u001b[38;5;241m=\u001b[39m make_model(input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m25\u001b[39m,\u001b[38;5;241m62\u001b[39m,\u001b[38;5;241m4\u001b[39m), num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m)\n\u001b[1;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msgd\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     15\u001b[0m             loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     16\u001b[0m             metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 18\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/gsdc/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/gsdc/lib/python3.10/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/gsdc/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/gsdc/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/gsdc/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/gsdc/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/gsdc/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/gsdc/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/gsdc/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/gsdc/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/envs/gsdc/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "params = {\n",
    "    'batch_size': 32,\n",
    "    'n_classes': 6,\n",
    "    'shuffle': True\n",
    "    }\n",
    "\n",
    "path_to_data = f'{base_dir}/train_spectrograms'\n",
    "\n",
    "training_generator = DataGenerator(df.loc[idxs_train], path_to_data, **params)\n",
    "validation_generator = DataGenerator(df.loc[idxs_val], path_to_data, **params)\n",
    "\n",
    "model = make_model(input_shape=(25,62,4), num_classes=6)\n",
    "model.compile(optimizer='sgd',\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "model.fit(training_generator, epochs=2, validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 624ms/step\n"
     ]
    }
   ],
   "source": [
    "TARGETS = ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n",
    "\n",
    "#\n",
    "# Test Data generator: for predicting.\n",
    "#\n",
    "\n",
    "class test_DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, ids, path_to_test_data, batch_size=32, n_classes=6):\n",
    "        'Initialization'\n",
    "        self.n_channels = 4\n",
    "        self.dim = (25,40)\n",
    "        self.n_freqs = 40\n",
    "\n",
    "        self.path = path_to_test_data\n",
    "        # self.files = os.listdir(path_to_test_data)\n",
    "        self.ids = ids\n",
    "        self.indexes = np.arange(len(self.ids))\n",
    "        # self.columns = self.data.columns[2:]\n",
    "        self.batch_size = batch_size\n",
    "        self.n_classes = n_classes\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.ceil(len(self.ids) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        # items_temp = self.items.iloc[indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X = self.__data_generation(indexes)\n",
    "\n",
    "        return X\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        # self.indexes = np.arange(self.len)\n",
    "        # if self.shuffle == True:\n",
    "        #     np.random.shuffle(self.indexes)\n",
    "        pass\n",
    "\n",
    "    def __data_generation(self, indexes):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((len(indexes), *self.dim, self.n_channels))\n",
    "\n",
    "        # Generate data\n",
    "        for i, idx in enumerate(indexes):\n",
    "            # item = self.items.iloc[idx]\n",
    "            test_spectrogram = pd.read_parquet(f'{self.path}{self.ids[idx]}.parquet')\n",
    "            test_spectrogram.replace(np.nan, 0, inplace=True)\n",
    "\n",
    "            initial = 137\n",
    "            final = initial + 25\n",
    "            for c in np.arange(self.n_channels):\n",
    "                cinitial = c * 100 + 1\n",
    "                cfinal = cinitial + self.n_freqs\n",
    "                # X[i,:,:,c] = self.data[initial:final, cinitial:cfinal]\n",
    "                X[i,:,:,c] = test_spectrogram.iloc[initial:final,cinitial:cfinal].to_numpy(copy=True)\n",
    "\n",
    "        return X\n",
    "\n",
    "\n",
    "# Parameters\n",
    "params = {\n",
    "    'batch_size': 32,\n",
    "    'n_classes': 6,\n",
    "    }\n",
    "\n",
    "\n",
    "base_dir = \"../toy_data\"\n",
    "\n",
    "path_to_test_data = f'{base_dir}/test_spectrograms/'\n",
    "test = pd.read_csv(f'{base_dir}/test.csv')\n",
    "ids = test['spectrogram_id'].values\n",
    "\n",
    "test_generator = test_DataGenerator(ids, path_to_test_data, **params)\n",
    "\n",
    "y_pred = model.predict(test_generator)\n",
    "\n",
    "sub = pd.DataFrame({'eeg_id':test.eeg_id.values})\n",
    "sub[TARGETS] = np.round(y_pred,6)\n",
    "sub.to_csv('submission.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>seizure_vote</th>\n",
       "      <th>lpd_vote</th>\n",
       "      <th>gpd_vote</th>\n",
       "      <th>lrda_vote</th>\n",
       "      <th>grda_vote</th>\n",
       "      <th>other_vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>704367771</td>\n",
       "      <td>0.176074</td>\n",
       "      <td>0.171767</td>\n",
       "      <td>0.154017</td>\n",
       "      <td>0.170628</td>\n",
       "      <td>0.152159</td>\n",
       "      <td>0.175355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4044323427</td>\n",
       "      <td>0.176056</td>\n",
       "      <td>0.171850</td>\n",
       "      <td>0.154020</td>\n",
       "      <td>0.170587</td>\n",
       "      <td>0.152200</td>\n",
       "      <td>0.175287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3403081220</td>\n",
       "      <td>0.176007</td>\n",
       "      <td>0.171779</td>\n",
       "      <td>0.153979</td>\n",
       "      <td>0.170692</td>\n",
       "      <td>0.152176</td>\n",
       "      <td>0.175367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2936526887</td>\n",
       "      <td>0.176003</td>\n",
       "      <td>0.171786</td>\n",
       "      <td>0.153965</td>\n",
       "      <td>0.170708</td>\n",
       "      <td>0.152171</td>\n",
       "      <td>0.175367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2918575845</td>\n",
       "      <td>0.176014</td>\n",
       "      <td>0.171784</td>\n",
       "      <td>0.153964</td>\n",
       "      <td>0.170664</td>\n",
       "      <td>0.152194</td>\n",
       "      <td>0.175381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>615255846</td>\n",
       "      <td>0.176028</td>\n",
       "      <td>0.171788</td>\n",
       "      <td>0.154030</td>\n",
       "      <td>0.170622</td>\n",
       "      <td>0.152187</td>\n",
       "      <td>0.175345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2493948338</td>\n",
       "      <td>0.176003</td>\n",
       "      <td>0.171776</td>\n",
       "      <td>0.153956</td>\n",
       "      <td>0.170690</td>\n",
       "      <td>0.152190</td>\n",
       "      <td>0.175384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1405667816</td>\n",
       "      <td>0.176008</td>\n",
       "      <td>0.171774</td>\n",
       "      <td>0.153966</td>\n",
       "      <td>0.170692</td>\n",
       "      <td>0.152180</td>\n",
       "      <td>0.175379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>983495114</td>\n",
       "      <td>0.176018</td>\n",
       "      <td>0.171787</td>\n",
       "      <td>0.153957</td>\n",
       "      <td>0.170683</td>\n",
       "      <td>0.152176</td>\n",
       "      <td>0.175378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2676914434</td>\n",
       "      <td>0.176008</td>\n",
       "      <td>0.171774</td>\n",
       "      <td>0.153966</td>\n",
       "      <td>0.170695</td>\n",
       "      <td>0.152181</td>\n",
       "      <td>0.175376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>158208938</td>\n",
       "      <td>0.176044</td>\n",
       "      <td>0.171774</td>\n",
       "      <td>0.154008</td>\n",
       "      <td>0.170668</td>\n",
       "      <td>0.152150</td>\n",
       "      <td>0.175356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4431217</td>\n",
       "      <td>0.175998</td>\n",
       "      <td>0.171783</td>\n",
       "      <td>0.153951</td>\n",
       "      <td>0.170694</td>\n",
       "      <td>0.152189</td>\n",
       "      <td>0.175385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3858164382</td>\n",
       "      <td>0.176012</td>\n",
       "      <td>0.171779</td>\n",
       "      <td>0.153984</td>\n",
       "      <td>0.170700</td>\n",
       "      <td>0.152173</td>\n",
       "      <td>0.175352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2573243971</td>\n",
       "      <td>0.176020</td>\n",
       "      <td>0.171758</td>\n",
       "      <td>0.154011</td>\n",
       "      <td>0.170709</td>\n",
       "      <td>0.152146</td>\n",
       "      <td>0.175356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>883644014</td>\n",
       "      <td>0.290165</td>\n",
       "      <td>0.124527</td>\n",
       "      <td>0.066796</td>\n",
       "      <td>0.212982</td>\n",
       "      <td>0.103306</td>\n",
       "      <td>0.202224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1570899544</td>\n",
       "      <td>0.176114</td>\n",
       "      <td>0.171697</td>\n",
       "      <td>0.154042</td>\n",
       "      <td>0.170808</td>\n",
       "      <td>0.151929</td>\n",
       "      <td>0.175411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1198459412</td>\n",
       "      <td>0.176003</td>\n",
       "      <td>0.171752</td>\n",
       "      <td>0.154007</td>\n",
       "      <td>0.170730</td>\n",
       "      <td>0.152147</td>\n",
       "      <td>0.175360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3525185677</td>\n",
       "      <td>0.175938</td>\n",
       "      <td>0.171719</td>\n",
       "      <td>0.153920</td>\n",
       "      <td>0.171222</td>\n",
       "      <td>0.151926</td>\n",
       "      <td>0.175274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1891953107</td>\n",
       "      <td>0.176007</td>\n",
       "      <td>0.171774</td>\n",
       "      <td>0.153966</td>\n",
       "      <td>0.170695</td>\n",
       "      <td>0.152179</td>\n",
       "      <td>0.175379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4238698455</td>\n",
       "      <td>0.176048</td>\n",
       "      <td>0.171781</td>\n",
       "      <td>0.153963</td>\n",
       "      <td>0.170662</td>\n",
       "      <td>0.152173</td>\n",
       "      <td>0.175373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        eeg_id  seizure_vote  lpd_vote  gpd_vote  lrda_vote  grda_vote  \\\n",
       "0    704367771      0.176074  0.171767  0.154017   0.170628   0.152159   \n",
       "1   4044323427      0.176056  0.171850  0.154020   0.170587   0.152200   \n",
       "2   3403081220      0.176007  0.171779  0.153979   0.170692   0.152176   \n",
       "3   2936526887      0.176003  0.171786  0.153965   0.170708   0.152171   \n",
       "4   2918575845      0.176014  0.171784  0.153964   0.170664   0.152194   \n",
       "5    615255846      0.176028  0.171788  0.154030   0.170622   0.152187   \n",
       "6   2493948338      0.176003  0.171776  0.153956   0.170690   0.152190   \n",
       "7   1405667816      0.176008  0.171774  0.153966   0.170692   0.152180   \n",
       "8    983495114      0.176018  0.171787  0.153957   0.170683   0.152176   \n",
       "9   2676914434      0.176008  0.171774  0.153966   0.170695   0.152181   \n",
       "10   158208938      0.176044  0.171774  0.154008   0.170668   0.152150   \n",
       "11     4431217      0.175998  0.171783  0.153951   0.170694   0.152189   \n",
       "12  3858164382      0.176012  0.171779  0.153984   0.170700   0.152173   \n",
       "13  2573243971      0.176020  0.171758  0.154011   0.170709   0.152146   \n",
       "14   883644014      0.290165  0.124527  0.066796   0.212982   0.103306   \n",
       "15  1570899544      0.176114  0.171697  0.154042   0.170808   0.151929   \n",
       "16  1198459412      0.176003  0.171752  0.154007   0.170730   0.152147   \n",
       "17  3525185677      0.175938  0.171719  0.153920   0.171222   0.151926   \n",
       "18  1891953107      0.176007  0.171774  0.153966   0.170695   0.152179   \n",
       "19  4238698455      0.176048  0.171781  0.153963   0.170662   0.152173   \n",
       "\n",
       "    other_vote  \n",
       "0     0.175355  \n",
       "1     0.175287  \n",
       "2     0.175367  \n",
       "3     0.175367  \n",
       "4     0.175381  \n",
       "5     0.175345  \n",
       "6     0.175384  \n",
       "7     0.175379  \n",
       "8     0.175378  \n",
       "9     0.175376  \n",
       "10    0.175356  \n",
       "11    0.175385  \n",
       "12    0.175352  \n",
       "13    0.175356  \n",
       "14    0.202224  \n",
       "15    0.175411  \n",
       "16    0.175360  \n",
       "17    0.175274  \n",
       "18    0.175379  \n",
       "19    0.175373  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 3s 61ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (1486) does not match length of index (20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(validation_generator)\n\u001b[1;32m      4\u001b[0m sub \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meeg_id\u001b[39m\u001b[38;5;124m'\u001b[39m:test\u001b[38;5;241m.\u001b[39meeg_id\u001b[38;5;241m.\u001b[39mvalues})\n\u001b[0;32m----> 5\u001b[0m \u001b[43msub\u001b[49m\u001b[43m[\u001b[49m\u001b[43mTARGETS\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mround(y_pred,\u001b[38;5;241m6\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/gsdc/lib/python3.10/site-packages/pandas/core/frame.py:4079\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4077\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_frame(key, value)\n\u001b[1;32m   4078\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, (Series, np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mlist\u001b[39m, Index)):\n\u001b[0;32m-> 4079\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4080\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, DataFrame):\n\u001b[1;32m   4081\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_item_frame_value(key, value)\n",
      "File \u001b[0;32m~/miniconda3/envs/gsdc/lib/python3.10/site-packages/pandas/core/frame.py:4130\u001b[0m, in \u001b[0;36mDataFrame._setitem_array\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4127\u001b[0m         \u001b[38;5;28mself\u001b[39m[col] \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m   4129\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m-> 4130\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iset_not_inplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4132\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(value) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4133\u001b[0m     \u001b[38;5;66;03m# list of lists\u001b[39;00m\n\u001b[1;32m   4134\u001b[0m     value \u001b[38;5;241m=\u001b[39m DataFrame(value)\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[0;32m~/miniconda3/envs/gsdc/lib/python3.10/site-packages/pandas/core/frame.py:4160\u001b[0m, in \u001b[0;36mDataFrame._iset_not_inplace\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4157\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumns must be same length as key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4159\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(key):\n\u001b[0;32m-> 4160\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m igetitem(value, i)\n\u001b[1;32m   4162\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4163\u001b[0m     ilocs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_indexer_non_unique(key)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/gsdc/lib/python3.10/site-packages/pandas/core/frame.py:4091\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4088\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   4089\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4090\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[0;32m-> 4091\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/gsdc/lib/python3.10/site-packages/pandas/core/frame.py:4300\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4290\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4291\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4292\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4293\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4298\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4299\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4300\u001b[0m     value, refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4302\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4303\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   4304\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   4305\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[1;32m   4306\u001b[0m     ):\n\u001b[1;32m   4307\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4308\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m~/miniconda3/envs/gsdc/lib/python3.10/site-packages/pandas/core/frame.py:5039\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   5036\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m   5038\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 5039\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5040\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/gsdc/lib/python3.10/site-packages/pandas/core/common.py:561\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[0;32m--> 561\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    562\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    563\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    564\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    565\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    566\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (1486) does not match length of index (20)"
     ]
    }
   ],
   "source": [
    "# On validation set\n",
    "\n",
    "y_pred = model.predict(validation_generator)\n",
    "sub = pd.DataFrame({'eeg_id':test.eeg_id.values})\n",
    "sub[TARGETS] = np.round(y_pred,6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spectrogram_id</th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>patient_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>647711672</td>\n",
       "      <td>704367771</td>\n",
       "      <td>53544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1279379926</td>\n",
       "      <td>4044323427</td>\n",
       "      <td>56411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1309472604</td>\n",
       "      <td>3403081220</td>\n",
       "      <td>24450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1878092388</td>\n",
       "      <td>2936526887</td>\n",
       "      <td>61262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1896553221</td>\n",
       "      <td>2918575845</td>\n",
       "      <td>17948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>536397604</td>\n",
       "      <td>615255846</td>\n",
       "      <td>49973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1987874958</td>\n",
       "      <td>2493948338</td>\n",
       "      <td>48272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>272214389</td>\n",
       "      <td>1405667816</td>\n",
       "      <td>54199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1222625047</td>\n",
       "      <td>983495114</td>\n",
       "      <td>58327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1802995379</td>\n",
       "      <td>2676914434</td>\n",
       "      <td>59198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1488564716</td>\n",
       "      <td>158208938</td>\n",
       "      <td>21996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1459125071</td>\n",
       "      <td>4431217</td>\n",
       "      <td>49713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1608390604</td>\n",
       "      <td>3858164382</td>\n",
       "      <td>50476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>815073191</td>\n",
       "      <td>2573243971</td>\n",
       "      <td>31417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1478824578</td>\n",
       "      <td>883644014</td>\n",
       "      <td>60074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>373481718</td>\n",
       "      <td>1570899544</td>\n",
       "      <td>16401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1017927461</td>\n",
       "      <td>1198459412</td>\n",
       "      <td>1657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2011177737</td>\n",
       "      <td>3525185677</td>\n",
       "      <td>56885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>731201762</td>\n",
       "      <td>1891953107</td>\n",
       "      <td>54199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1999336047</td>\n",
       "      <td>4238698455</td>\n",
       "      <td>64751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    spectrogram_id      eeg_id  patient_id\n",
       "0        647711672   704367771       53544\n",
       "1       1279379926  4044323427       56411\n",
       "2       1309472604  3403081220       24450\n",
       "3       1878092388  2936526887       61262\n",
       "4       1896553221  2918575845       17948\n",
       "5        536397604   615255846       49973\n",
       "6       1987874958  2493948338       48272\n",
       "7        272214389  1405667816       54199\n",
       "8       1222625047   983495114       58327\n",
       "9       1802995379  2676914434       59198\n",
       "10      1488564716   158208938       21996\n",
       "11      1459125071     4431217       49713\n",
       "12      1608390604  3858164382       50476\n",
       "13       815073191  2573243971       31417\n",
       "14      1478824578   883644014       60074\n",
       "15       373481718  1570899544       16401\n",
       "16      1017927461  1198459412        1657\n",
       "17      2011177737  3525185677       56885\n",
       "18       731201762  1891953107       54199\n",
       "19      1999336047  4238698455       64751"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading each parquet file inside the data generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# FIX THIS\n",
    "# using train.csv\n",
    "#\n",
    "\n",
    "path_to_data = \"../data/00_spectrograms_reduced.npy\"\n",
    "path_to_items = \"../data/00_sub_spectrograms_idxs_reduced.npy\"\n",
    "\n",
    "data = np.load(path_to_data)\n",
    "items = np.load(path_to_items)\n",
    "n_total_samples = items.shape[0]\n",
    "\n",
    "ptrain = 0.8\n",
    "\n",
    "idx_train = np.array([], dtype=int)\n",
    "idx_val = np.array([], dtype=int)\n",
    "for i in np.arange(6):\n",
    "    idx = np.where(items[:,3] == i)[0]\n",
    "    idx = np.random.permutation(idx)\n",
    "    cut = int(ptrain*idx.shape[0])\n",
    "    idx_train = np.append(idx_train, idx[0:cut])\n",
    "    idx_val = np.append(idx_val, idx[cut:])\n",
    "\n",
    "items_train = items[idx_train]\n",
    "items_val = items[idx_val]\n",
    "print(\"Train samples:\", len(items_train))\n",
    "print(\"Validation samples:\", len(items_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# TO BE COMPLETED\n",
    "#\n",
    "\n",
    "#\n",
    "# Data generator pandas to load the parquet files into a numpy array.\n",
    "#\n",
    "# Original spectrograms.\n",
    "# 50 seconds slice\n",
    "# 4 channels\n",
    "#\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, items, data, batch_size=32, n_classes=6, shuffle=True):\n",
    "        ''' Initialization\n",
    "        items: [eeg_id, eeg_sub_id, idx of offset, target]\n",
    "        '''\n",
    "        self.n_channels = 4\n",
    "        self.n_freqs = 40\n",
    "        self.dim = (25, self.n_freqs)\n",
    "\n",
    "        self.data = data\n",
    "        self.items = items\n",
    "        self.batch_size = batch_size\n",
    "        self.len = items.shape[0]\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.ceil(self.len / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(indexes)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(self.len)\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, indexes):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        true_size = len(indexes)\n",
    "        X = np.empty((true_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((true_size), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, idx in enumerate(indexes):\n",
    "            item = self.items[idx]\n",
    "            # print(item)  # Uncomment for testing.\n",
    "            # Sample is 50 second long, that's 25 rows.\n",
    "            initial = item[2] + 137\n",
    "            final = initial + 25\n",
    "            for c in np.arange(self.n_channels):\n",
    "                cinitial = c * 100\n",
    "                cfinal = cinitial + self.n_freqs\n",
    "                X[i,:,:,c] = self.data[initial:final, cinitial:cfinal]\n",
    "            # Store class\n",
    "            y[i] = item[3]\n",
    "\n",
    "        return X, keras.utils.to_categorical(y, num_classes=self.n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_model(input_shape, num_classes):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "\n",
    "    conv1 = keras.layers.Conv2D(filters=32,\n",
    "                                kernel_size=3,\n",
    "                                strides=1,\n",
    "                                padding=\"same\",\n",
    "                                data_format=\"channels_last\",\n",
    "                                # kernel_regularizer=regularizers.l2(0.001),\n",
    "                                # use_bias=True,\n",
    "                                )(input_layer)\n",
    "    conv1 = keras.layers.BatchNormalization()(conv1)\n",
    "    # conv1 = keras.layers.MaxPooling2D(pool_size=8)(conv1)\n",
    "    conv1 = keras.layers.ReLU()(conv1)\n",
    "    \n",
    "    conv2 = keras.layers.Conv2D(filters=32,\n",
    "                                kernel_size=5,\n",
    "                                padding=\"same\",\n",
    "                                data_format=\"channels_last\",\n",
    "                                )(conv1)\n",
    "    #conv2 = keras.layers.BatchNormalization()(conv2)\n",
    "    # conv2 = keras.layers.MaxPooling2D(pool_size=8)(conv2)\n",
    "    conv2 = keras.layers.ReLU()(conv2)\n",
    "\n",
    "    conv3 = keras.layers.Conv2D(filters=64,\n",
    "                                kernel_size=7,\n",
    "                                padding=\"same\",\n",
    "                                data_format=\"channels_last\",\n",
    "                                )(conv2)\n",
    "    conv3 = keras.layers.ReLU()(conv3)\n",
    "    # conv3 = keras.layers.MaxPooling2D(pool_size=2)(conv3)\n",
    "\n",
    "    conv4 = keras.layers.Conv2D(filters=64,\n",
    "                                kernel_size=3,\n",
    "                                padding=\"same\",\n",
    "                                data_format=\"channels_last\",\n",
    "                                )(conv3)\n",
    "    # conv4 = keras.layers.BatchNormalization()(conv4)\n",
    "    conv4 = keras.layers.ReLU()(conv4)\n",
    "    conv4 = keras.layers.MaxPooling2D(pool_size=2)(conv4)\n",
    "\n",
    "    fltn  = keras.layers.Flatten()(conv4) \n",
    "    dense1 = keras.layers.Dense(256)(fltn)\n",
    "    # dout1 = keras.layers.Dropout(rate=0.4)(dense1)\n",
    "    \n",
    "    # relu1 = keras.layers.Dense(256)(fltn)\n",
    "    # relu1 = keras.layers.ReLU()(relu1)\n",
    "\n",
    "    # relu2 = keras.layers.Dense(64)(relu1)\n",
    "    # relu2 = keras.layers.ReLU(64)(relu2)\n",
    "\n",
    "#     lin = keras.layers.Dense(2)(relu2)\n",
    "\n",
    "    output_layer = keras.layers.Dense(num_classes, activation=\"softmax\")(dense1)\n",
    "\n",
    "    return keras.models.Model(inputs=input_layer, outputs=output_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "params = {\n",
    "    'batch_size': 32,\n",
    "    'n_classes': 6,\n",
    "    'shuffle': True\n",
    "    }\n",
    "\n",
    "training_generator = DataGenerator(items_train, data, **params)\n",
    "validation_generator = DataGenerator(items_val, data, **params)\n",
    "\n",
    "model = make_model(input_shape=(25,40,4), num_classes=6)\n",
    "model.compile(optimizer='sgd',\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=[tf.keras.metrics.CategoricalCrossentropy()])\n",
    "\n",
    "model.fit(training_generator, epochs=7, validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGETS = ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n",
    "\n",
    "#\n",
    "# Test Data generator: for predicting.\n",
    "#\n",
    "\n",
    "class test_DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, ids, path_to_test_data, batch_size=32, n_classes=6):\n",
    "        'Initialization'\n",
    "        self.n_channels = 4\n",
    "        self.dim = (25,40)\n",
    "        self.n_freqs = 40\n",
    "\n",
    "        self.path = path_to_test_data\n",
    "        # self.files = os.listdir(path_to_test_data)\n",
    "        self.ids = ids\n",
    "        self.indexes = np.arange(len(self.ids))\n",
    "        # self.columns = self.data.columns[2:]\n",
    "        self.batch_size = batch_size\n",
    "        self.n_classes = n_classes\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.ceil(len(self.ids) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        # items_temp = self.items.iloc[indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X = self.__data_generation(indexes)\n",
    "\n",
    "        return X\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        # self.indexes = np.arange(self.len)\n",
    "        # if self.shuffle == True:\n",
    "        #     np.random.shuffle(self.indexes)\n",
    "        pass\n",
    "\n",
    "    def __data_generation(self, indexes):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((len(indexes), *self.dim, self.n_channels))\n",
    "\n",
    "        # Generate data\n",
    "        for i, idx in enumerate(indexes):\n",
    "            # item = self.items.iloc[idx]\n",
    "            test_spectrogram = pd.read_parquet(f'{self.path}{self.ids[idx]}.parquet')\n",
    "            test_spectrogram.replace(np.nan, 0, inplace=True)\n",
    "\n",
    "            initial = 137\n",
    "            final = initial + 25\n",
    "            for c in np.arange(self.n_channels):\n",
    "                cinitial = c * 100 + 1\n",
    "                cfinal = cinitial + self.n_freqs\n",
    "                # X[i,:,:,c] = self.data[initial:final, cinitial:cfinal]\n",
    "                X[i,:,:,c] = test_spectrogram.iloc[initial:final,cinitial:cfinal].to_numpy(copy=True)\n",
    "\n",
    "        return X\n",
    "\n",
    "\n",
    "# Parameters\n",
    "params = {\n",
    "    'batch_size': 32,\n",
    "    'n_classes': 6,\n",
    "    }\n",
    "\n",
    "\n",
    "base_dir = \"../toy_data\"\n",
    "\n",
    "path_to_test_data = f'{base_dir}/test_spectrograms/'\n",
    "test = pd.read_csv(f'{base_dir}/test.csv')\n",
    "ids = test['spectrogram_id'].values\n",
    "\n",
    "test_generator = test_DataGenerator(ids, path_to_test_data, **params)\n",
    "\n",
    "y_pred = model.predict(test_generator)\n",
    "\n",
    "sub = pd.DataFrame({'eeg_id':test.eeg_id.values})\n",
    "sub[TARGETS] = np.round(y_pred,6)\n",
    "# sub.to_csv('submission.csv',index=False)\n",
    "sub"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gsdc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
