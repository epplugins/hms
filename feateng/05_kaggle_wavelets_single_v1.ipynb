{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wavelets\n",
    "\n",
    "Generating single numpy with cwts.  \n",
    "\n",
    "- cwt of 50 seconds eeg of each pair variable in banana montage\n",
    "- Average of cwts in each group (5 channels)\n",
    "- mean pooling, reducing by 5\n",
    "- storing 10 seconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added target column. Transformed into percentages.\n",
      "Train: 12186\n",
      "Val: 2148\n",
      "Test: 1248\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "from scipy.signal import sosfiltfilt, butter\n",
    "\n",
    "\n",
    "base_dir = \"/kaggle/input/hms-harmful-brain-activity-classification\"\n",
    "\n",
    "data_dir = '/kaggle/input/hms-indices-train-val-test-v2'\n",
    "\n",
    "output_dir = ''\n",
    "\n",
    "fs = 200  # Sample rate.\n",
    "\n",
    "df_traincsv = pd.read_csv(f'{base_dir}/train.csv')\n",
    "\n",
    "TARGETS = ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n",
    "\n",
    "df_traincsv = pd.read_csv(f'{base_dir}/train.csv')\n",
    "df_traincsv.loc[df_traincsv.expert_consensus == 'Seizure', 'target'] = 0\n",
    "df_traincsv.loc[df_traincsv.expert_consensus == 'LPD', 'target'] = 1\n",
    "df_traincsv.loc[df_traincsv.expert_consensus == 'GPD', 'target'] = 2\n",
    "df_traincsv.loc[df_traincsv.expert_consensus == 'LRDA', 'target'] = 3\n",
    "df_traincsv.loc[df_traincsv.expert_consensus == 'GRDA', 'target'] = 4\n",
    "df_traincsv.loc[df_traincsv.expert_consensus == 'Other', 'target'] = 5\n",
    "\n",
    "# Transform votes into percentages.\n",
    "df_traincsv['sum_votes'] = df_traincsv.seizure_vote + df_traincsv.lpd_vote + df_traincsv.gpd_vote\t+ df_traincsv.lrda_vote + df_traincsv.grda_vote + df_traincsv.other_vote\n",
    "df_traincsv['seizure_vote'] = df_traincsv.seizure_vote/df_traincsv.sum_votes\n",
    "df_traincsv['lpd_vote'] = df_traincsv.lpd_vote/df_traincsv.sum_votes\n",
    "df_traincsv['gpd_vote'] = df_traincsv.gpd_vote/df_traincsv.sum_votes\n",
    "df_traincsv['lrda_vote'] = df_traincsv.lrda_vote/df_traincsv.sum_votes\n",
    "df_traincsv['grda_vote'] = df_traincsv.grda_vote/df_traincsv.sum_votes\n",
    "df_traincsv['other_vote'] = df_traincsv.other_vote/df_traincsv.sum_votes\n",
    "\n",
    "idxs_train = np.load(f'{data_dir}/03_stratified_v2_idxs_train.npy')\n",
    "idxs_val = np.load(f'{data_dir}/03_stratified_v2_idxs_val.npy')\n",
    "idxs_test = np.load(f'{data_dir}/03_stratified_v2_idxs_test.npy')\n",
    "df_train = df_traincsv.loc[idxs_train]\n",
    "df_val = df_traincsv.loc[idxs_val]\n",
    "df_test = df_traincsv.loc[idxs_test]\n",
    "\n",
    "print(\"Added target column. Transformed into percentages.\")\n",
    "print(\"Train:\", len(df_train))\n",
    "print(\"Val:\", len(df_val))\n",
    "print(\"Test:\", len(df_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_'></a>[Definitions](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2024022800\n",
    "def banana(eeg_absolute, filter=False, fs=200.0):\n",
    "    '''Returns pandas dataframe with a banana montage.\n",
    "\n",
    "    filter: False or [low freq, high freq]\n",
    "    '''\n",
    "    if filter:\n",
    "        filtered_data = eeg_absolute.copy()\n",
    "        # Apply band pass.\n",
    "        sos = butter(5, filter, btype='bandpass', fs=fs, output='sos')\n",
    "        for c in filtered_data.columns:\n",
    "            filtered_data[c] = sosfiltfilt(sos, filtered_data[c])\n",
    "    else:\n",
    "        filtered_data = eeg_absolute.copy()\n",
    "\n",
    "    eeg = pd.DataFrame(data={\n",
    "        'Fp1-F7' : filtered_data.Fp1 - filtered_data.F7,\n",
    "        'Fp7-T3' : filtered_data.F7 - filtered_data.T3,\n",
    "        'T3-T5' : filtered_data.T3 - filtered_data.T5,\n",
    "        'T5-O1' : filtered_data.T5 - filtered_data.O1,\n",
    "\n",
    "        'Fp2-F8' : filtered_data.Fp2 - filtered_data.F8,\n",
    "        'F8-T4' : filtered_data.F8 - filtered_data.T4,\n",
    "        'T4-T6' : filtered_data.T4 - filtered_data.T6,\n",
    "        'T6-O2' : filtered_data.T6 - filtered_data.O2,\n",
    "\n",
    "        'Fp1-F3' : filtered_data.Fp1 - filtered_data.F3,\n",
    "        'F3-C3' : filtered_data.F3 - filtered_data.C3,\n",
    "        'C3-P3' : filtered_data.C3 - filtered_data.P3,\n",
    "        'P3-O1' : filtered_data.P3 - filtered_data.O1,\n",
    "\n",
    "        'Fp2-F4' : filtered_data.Fp2 - filtered_data.F4,\n",
    "        'F4-C4' : filtered_data.F4 - filtered_data.C4,\n",
    "        'C4-P4' : filtered_data.C4 - filtered_data.P4,\n",
    "        'P4-O2' : filtered_data.P4 - filtered_data.O2,\n",
    "\n",
    "        'Fz-Cz' : filtered_data.Fz - filtered_data.Cz,\n",
    "        'Cz-Pz' : filtered_data.Cz - filtered_data.Pz,\n",
    "\n",
    "        'EKG' : filtered_data.EKG\n",
    "        })\n",
    "    return eeg\n",
    "\n",
    "#20240304\n",
    "def asStride(arr,sub_shape,stride):\n",
    "    '''Get a strided sub-matrices view of an ndarray.\n",
    "    See also skimage.util.shape.view_as_windows()\n",
    "    '''\n",
    "    s0,s1=arr.strides[:2]\n",
    "    m1,n1=arr.shape[:2]\n",
    "    m2,n2=sub_shape\n",
    "    view_shape=(1+(m1-m2)//stride[0],1+(n1-n2)//stride[1],m2,n2)+arr.shape[2:]\n",
    "    strides=(stride[0]*s0,stride[1]*s1,s0,s1)+arr.strides[2:]\n",
    "    subs=np.lib.stride_tricks.as_strided(arr,view_shape,strides=strides)\n",
    "    return subs\n",
    "\n",
    "#20240304\n",
    "def poolingOverlap(mat,ksize,stride=None,method='max',pad=False):\n",
    "    '''Overlapping pooling on 2D or 3D data.\n",
    "\n",
    "    <mat>: ndarray, input array to pool.\n",
    "    <ksize>: tuple of 2, kernel size in (ky, kx).\n",
    "    <stride>: tuple of 2 or None, stride of pooling window.\n",
    "              If None, same as <ksize> (non-overlapping pooling).\n",
    "    <method>: str, 'max for max-pooling,\n",
    "                   'mean' for mean-pooling.\n",
    "    <pad>: bool, pad <mat> or not. If no pad, output has size\n",
    "           (n-f)//s+1, n being <mat> size, f being kernel size, s stride.\n",
    "           if pad, output has size ceil(n/s).\n",
    "\n",
    "    Return <result>: pooled matrix.\n",
    "    '''\n",
    "\n",
    "    m, n = mat.shape[:2]\n",
    "    ky,kx=ksize\n",
    "    if stride is None:\n",
    "        stride=(ky,kx)\n",
    "    sy,sx=stride\n",
    "\n",
    "    _ceil=lambda x,y: int(np.ceil(x/float(y)))\n",
    "\n",
    "    if pad:\n",
    "        ny=_ceil(m,sy)\n",
    "        nx=_ceil(n,sx)\n",
    "        size=((ny-1)*sy+ky, (nx-1)*sx+kx) + mat.shape[2:]\n",
    "        mat_pad=np.full(size,np.nan)\n",
    "        mat_pad[:m,:n,...]=mat\n",
    "    else:\n",
    "        mat_pad=mat[:(m-ky)//sy*sy+ky, :(n-kx)//sx*sx+kx, ...]\n",
    "\n",
    "    view=asStride(mat_pad,ksize,stride)\n",
    "\n",
    "    if method=='max':\n",
    "        result=np.nanmax(view,axis=(2,3))\n",
    "    else:\n",
    "        result=np.nanmean(view,axis=(2,3))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single numpy of CWTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to 05_single_cwt_v1_train.npy\n",
      "Saving to 05_single_cwt_v1_train_items.npy\n"
     ]
    }
   ],
   "source": [
    "fmin = 1\n",
    "fmax = 50\n",
    "scales = np.arange(1,50)\n",
    "waveletname = 'morl'\n",
    "# train_size = len(df_train)\n",
    "train_size = 100\n",
    "# val_size = len(df_val)\n",
    "val_size = 100\n",
    "# test_size= len(df_test)\n",
    "test_size= 100\n",
    "n_channels = 5\n",
    "dim1 = scales.shape[0]\n",
    "pool_window = 5\n",
    "dim2 = int(2000/pool_window)\n",
    "sampling_period = 1\n",
    "\n",
    "sgrams = np.empty((train_size, dim1, dim2, n_channels))\n",
    "# item: [eeg_id, eeg_sub_id, idx in sgrams (1st index), target,\n",
    "#       seizure_vote, lpd_vote, gpd_vote, lrda_vote,\n",
    "#       grda_vote, other_vote]\n",
    "items = np.array([], dtype=float).reshape(0,10)\n",
    "\n",
    "for i in range(train_size):\n",
    "    if i % 1000 == 0:\n",
    "        print(f'{i} eegs loaded', end='\\r')\n",
    "    item = df_train.iloc[i]\n",
    "    eeg_full = pd.read_parquet(f'{base_dir}/train_eegs/{item.eeg_id}.parquet')\n",
    "    # 50 second eeg sub sample\n",
    "    offset = int(item.eeg_label_offset_seconds)\n",
    "    start = offset * fs\n",
    "    end = (offset + 50) * fs\n",
    "    eeg_absolute = eeg_full[start:end]\n",
    "    eeg_absolute = eeg_absolute.interpolate(limit_direction='both') # <<<<< Interpolation\n",
    "    eeg = banana(eeg_absolute, filter=[fmin,fmax])\n",
    "    start = int(2000/pool_window)\n",
    "    end = int(4000/pool_window)\n",
    "    # X = np.empty((1, dim1, dim2, n_channels))\n",
    "    # Averaging each chain in the banana montage.\n",
    "\n",
    "    # Left temporal chain.\n",
    "    coeff = np.empty((dim1, 10000))\n",
    "    for col in [0,1,2,3]:\n",
    "        coeff_, freq = pywt.cwt(eeg.iloc[:,col], scales, waveletname, sampling_period=sampling_period)\n",
    "        coeff = coeff + coeff_\n",
    "\n",
    "    coeff = coeff/4\n",
    "    coeff = poolingOverlap(coeff,(1,pool_window),stride=None,method='mean',pad=False)\n",
    "    coeff = (coeff - np.mean(coeff)) / np.std(coeff)\n",
    "    x = coeff[:,start:end].copy()\n",
    "    sgrams[i,:,:,0] = x.copy()\n",
    "\n",
    "    # Right temporal chain.\n",
    "    coeff = np.empty((dim1, 10000))\n",
    "    for col in [4,5,6,7]:\n",
    "        coeff_, freq = pywt.cwt(eeg.iloc[:,col], scales, waveletname, sampling_period=sampling_period)\n",
    "        coeff = coeff + coeff_\n",
    "\n",
    "    coeff = coeff/4\n",
    "    coeff = poolingOverlap(coeff,(1,pool_window),stride=None,method='mean',pad=False)\n",
    "    coeff = (coeff - np.mean(coeff)) / np.std(coeff)\n",
    "    x = coeff[:,start:end].copy()\n",
    "    sgrams[i,:,:,1] = x.copy()\n",
    "\n",
    "    # Left parasagittal chain.\n",
    "    coeff = np.empty((dim1, 10000))\n",
    "    for col in [8,9,10,11]:\n",
    "        coeff_, freq = pywt.cwt(eeg.iloc[:,col], scales, waveletname, sampling_period=sampling_period)\n",
    "        coeff = coeff + coeff_\n",
    "\n",
    "    coeff = coeff/4\n",
    "    coeff = poolingOverlap(coeff,(1,pool_window),stride=None,method='mean',pad=False)\n",
    "    coeff = (coeff - np.mean(coeff)) / np.std(coeff)\n",
    "    x = coeff[:,start:end].copy()\n",
    "    sgrams[i,:,:,2] = x.copy()\n",
    "\n",
    "    # Right parasagittal chain.\n",
    "    coeff = np.empty((dim1, 10000))\n",
    "    for col in [12,13,14,15]:\n",
    "        coeff_, freq = pywt.cwt(eeg.iloc[:,col], scales, waveletname, sampling_period=sampling_period)\n",
    "        coeff = coeff + coeff_\n",
    "\n",
    "    coeff = coeff/4\n",
    "    coeff = poolingOverlap(coeff,(1,pool_window),stride=None,method='mean',pad=False)\n",
    "    coeff = (coeff - np.mean(coeff)) / np.std(coeff)\n",
    "    x = coeff[:,start:end].copy()\n",
    "    sgrams[i,:,:,3] = x.copy()\n",
    "\n",
    "    # Central chain.\n",
    "    coeff = np.empty((dim1, 10000))\n",
    "    for col in [16,17]:\n",
    "        coeff_, freq = pywt.cwt(eeg.iloc[:,col], scales, waveletname, sampling_period=sampling_period)\n",
    "        coeff = coeff + coeff_\n",
    "\n",
    "    coeff = coeff/2\n",
    "    coeff = poolingOverlap(coeff,(1,pool_window),stride=None,method='mean',pad=False)\n",
    "    coeff = (coeff - np.mean(coeff)) / np.std(coeff)\n",
    "    x = coeff[:,start:end].copy()\n",
    "    sgrams[i,:,:,4] = x.copy()\n",
    "\n",
    "    xitem = np.array([item.eeg_id, item.eeg_sub_id, i, item.target,\n",
    "                    item.seizure_vote, item.lpd_vote, item.gpd_vote,\n",
    "                    item.lrda_vote, item.grda_vote, item.other_vote],\n",
    "                    dtype=float).reshape(1,10)\n",
    "    items = np.concatenate([items, xitem])\n",
    "\n",
    "filename = '05_single_cwt_v1_train'     \n",
    "print(f'Saving to {filename}.npy')\n",
    "print(f'Saving to {filename}_items.npy')\n",
    "np.save(f'{output_dir}{filename}.npy', sgrams)\n",
    "np.save(f'{output_dir}{filename}_items.npy', items)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgrams = np.empty((train_size, dim1, dim2, n_channels))\n",
    "# item: [eeg_id, eeg_sub_id, idx in sgrams (1st index), target,\n",
    "#       seizure_vote, lpd_vote, gpd_vote, lrda_vote,\n",
    "#       grda_vote, other_vote]\n",
    "items = np.array([], dtype=float).reshape(0,10)\n",
    "\n",
    "for i in range(val_size):\n",
    "    if i % 1000 == 0:\n",
    "        print(f'{i} eegs loaded', end='\\r')\n",
    "    item = df_val.iloc[i]\n",
    "    eeg_full = pd.read_parquet(f'{base_dir}/train_eegs/{item.eeg_id}.parquet')\n",
    "    # 50 second eeg sub sample\n",
    "    offset = int(item.eeg_label_offset_seconds)\n",
    "    start = offset * fs\n",
    "    end = (offset + 50) * fs\n",
    "    eeg_absolute = eeg_full[start:end]\n",
    "    eeg_absolute = eeg_absolute.interpolate(limit_direction='both') # <<<<< Interpolation\n",
    "    eeg = banana(eeg_absolute, filter=[fmin,fmax])\n",
    "    start = int(2000/pool_window)\n",
    "    end = int(4000/pool_window)\n",
    "    # X = np.empty((1, dim1, dim2, n_channels))\n",
    "    # Averaging each chain in the banana montage.\n",
    "\n",
    "    # Left temporal chain.\n",
    "    coeff = np.empty((dim1, 10000))\n",
    "    for col in [0,1,2,3]:\n",
    "        coeff_, freq = pywt.cwt(eeg.iloc[:,col], scales, waveletname, sampling_period=sampling_period)\n",
    "        coeff = coeff + coeff_\n",
    "\n",
    "    coeff = coeff/4\n",
    "    coeff = poolingOverlap(coeff,(1,pool_window),stride=None,method='mean',pad=False)\n",
    "    coeff = (coeff - np.mean(coeff)) / np.std(coeff)\n",
    "    x = coeff[:,start:end].copy()\n",
    "    sgrams[i,:,:,0] = x.copy()\n",
    "\n",
    "    # Right temporal chain.\n",
    "    coeff = np.empty((dim1, 10000))\n",
    "    for col in [4,5,6,7]:\n",
    "        coeff_, freq = pywt.cwt(eeg.iloc[:,col], scales, waveletname, sampling_period=sampling_period)\n",
    "        coeff = coeff + coeff_\n",
    "\n",
    "    coeff = coeff/4\n",
    "    coeff = poolingOverlap(coeff,(1,pool_window),stride=None,method='mean',pad=False)\n",
    "    coeff = (coeff - np.mean(coeff)) / np.std(coeff)\n",
    "    x = coeff[:,start:end].copy()\n",
    "    sgrams[i,:,:,1] = x.copy()\n",
    "\n",
    "    # Left parasagittal chain.\n",
    "    coeff = np.empty((dim1, 10000))\n",
    "    for col in [8,9,10,11]:\n",
    "        coeff_, freq = pywt.cwt(eeg.iloc[:,col], scales, waveletname, sampling_period=sampling_period)\n",
    "        coeff = coeff + coeff_\n",
    "\n",
    "    coeff = coeff/4\n",
    "    coeff = poolingOverlap(coeff,(1,pool_window),stride=None,method='mean',pad=False)\n",
    "    coeff = (coeff - np.mean(coeff)) / np.std(coeff)\n",
    "    x = coeff[:,start:end].copy()\n",
    "    sgrams[i,:,:,2] = x.copy()\n",
    "\n",
    "    # Right parasagittal chain.\n",
    "    coeff = np.empty((dim1, 10000))\n",
    "    for col in [12,13,14,15]:\n",
    "        coeff_, freq = pywt.cwt(eeg.iloc[:,col], scales, waveletname, sampling_period=sampling_period)\n",
    "        coeff = coeff + coeff_\n",
    "\n",
    "    coeff = coeff/4\n",
    "    coeff = poolingOverlap(coeff,(1,pool_window),stride=None,method='mean',pad=False)\n",
    "    coeff = (coeff - np.mean(coeff)) / np.std(coeff)\n",
    "    x = coeff[:,start:end].copy()\n",
    "    sgrams[i,:,:,3] = x.copy()\n",
    "\n",
    "    # Central chain.\n",
    "    coeff = np.empty((dim1, 10000))\n",
    "    for col in [16,17]:\n",
    "        coeff_, freq = pywt.cwt(eeg.iloc[:,col], scales, waveletname, sampling_period=sampling_period)\n",
    "        coeff = coeff + coeff_\n",
    "\n",
    "    coeff = coeff/2\n",
    "    coeff = poolingOverlap(coeff,(1,pool_window),stride=None,method='mean',pad=False)\n",
    "    coeff = (coeff - np.mean(coeff)) / np.std(coeff)\n",
    "    x = coeff[:,start:end].copy()\n",
    "    sgrams[i,:,:,4] = x.copy()\n",
    "\n",
    "    xitem = np.array([item.eeg_id, item.eeg_sub_id, i, item.target,\n",
    "                    item.seizure_vote, item.lpd_vote, item.gpd_vote,\n",
    "                    item.lrda_vote, item.grda_vote, item.other_vote],\n",
    "                    dtype=float).reshape(1,10)\n",
    "    items = np.concatenate([items, xitem])\n",
    "\n",
    "filename = '05_single_cwt_v1_val'     \n",
    "print(f'Saving to {filename}.npy')\n",
    "print(f'Saving to {filename}_items.npy')\n",
    "np.save(f'{output_dir}{filename}.npy', sgrams)\n",
    "np.save(f'{output_dir}{filename}_items.npy', items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgrams = np.empty((train_size, dim1, dim2, n_channels))\n",
    "# item: [eeg_id, eeg_sub_id, idx in sgrams (1st index), target,\n",
    "#       seizure_vote, lpd_vote, gpd_vote, lrda_vote,\n",
    "#       grda_vote, other_vote]\n",
    "items = np.array([], dtype=float).reshape(0,10)\n",
    "\n",
    "for i in range(test_size):\n",
    "    if i % 1000 == 0:\n",
    "        print(f'{i} eegs loaded', end='\\r')\n",
    "    item = df_test.iloc[i]\n",
    "    eeg_full = pd.read_parquet(f'{base_dir}/train_eegs/{item.eeg_id}.parquet')\n",
    "    # 50 second eeg sub sample\n",
    "    offset = int(item.eeg_label_offset_seconds)\n",
    "    start = offset * fs\n",
    "    end = (offset + 50) * fs\n",
    "    eeg_absolute = eeg_full[start:end]\n",
    "    eeg_absolute = eeg_absolute.interpolate(limit_direction='both') # <<<<< Interpolation\n",
    "    eeg = banana(eeg_absolute, filter=[fmin,fmax])\n",
    "    start = int(2000/pool_window)\n",
    "    end = int(4000/pool_window)\n",
    "    # X = np.empty((1, dim1, dim2, n_channels))\n",
    "    # Averaging each chain in the banana montage.\n",
    "\n",
    "    # Left temporal chain.\n",
    "    coeff = np.empty((dim1, 10000))\n",
    "    for col in [0,1,2,3]:\n",
    "        coeff_, freq = pywt.cwt(eeg.iloc[:,col], scales, waveletname, sampling_period=sampling_period)\n",
    "        coeff = coeff + coeff_\n",
    "\n",
    "    coeff = coeff/4\n",
    "    coeff = poolingOverlap(coeff,(1,pool_window),stride=None,method='mean',pad=False)\n",
    "    coeff = (coeff - np.mean(coeff)) / np.std(coeff)\n",
    "    x = coeff[:,start:end].copy()\n",
    "    sgrams[i,:,:,0] = x.copy()\n",
    "\n",
    "    # Right temporal chain.\n",
    "    coeff = np.empty((dim1, 10000))\n",
    "    for col in [4,5,6,7]:\n",
    "        coeff_, freq = pywt.cwt(eeg.iloc[:,col], scales, waveletname, sampling_period=sampling_period)\n",
    "        coeff = coeff + coeff_\n",
    "\n",
    "    coeff = coeff/4\n",
    "    coeff = poolingOverlap(coeff,(1,pool_window),stride=None,method='mean',pad=False)\n",
    "    coeff = (coeff - np.mean(coeff)) / np.std(coeff)\n",
    "    x = coeff[:,start:end].copy()\n",
    "    sgrams[i,:,:,1] = x.copy()\n",
    "\n",
    "    # Left parasagittal chain.\n",
    "    coeff = np.empty((dim1, 10000))\n",
    "    for col in [8,9,10,11]:\n",
    "        coeff_, freq = pywt.cwt(eeg.iloc[:,col], scales, waveletname, sampling_period=sampling_period)\n",
    "        coeff = coeff + coeff_\n",
    "\n",
    "    coeff = coeff/4\n",
    "    coeff = poolingOverlap(coeff,(1,pool_window),stride=None,method='mean',pad=False)\n",
    "    coeff = (coeff - np.mean(coeff)) / np.std(coeff)\n",
    "    x = coeff[:,start:end].copy()\n",
    "    sgrams[i,:,:,2] = x.copy()\n",
    "\n",
    "    # Right parasagittal chain.\n",
    "    coeff = np.empty((dim1, 10000))\n",
    "    for col in [12,13,14,15]:\n",
    "        coeff_, freq = pywt.cwt(eeg.iloc[:,col], scales, waveletname, sampling_period=sampling_period)\n",
    "        coeff = coeff + coeff_\n",
    "\n",
    "    coeff = coeff/4\n",
    "    coeff = poolingOverlap(coeff,(1,pool_window),stride=None,method='mean',pad=False)\n",
    "    coeff = (coeff - np.mean(coeff)) / np.std(coeff)\n",
    "    x = coeff[:,start:end].copy()\n",
    "    sgrams[i,:,:,3] = x.copy()\n",
    "\n",
    "    # Central chain.\n",
    "    coeff = np.empty((dim1, 10000))\n",
    "    for col in [16,17]:\n",
    "        coeff_, freq = pywt.cwt(eeg.iloc[:,col], scales, waveletname, sampling_period=sampling_period)\n",
    "        coeff = coeff + coeff_\n",
    "\n",
    "    coeff = coeff/2\n",
    "    coeff = poolingOverlap(coeff,(1,pool_window),stride=None,method='mean',pad=False)\n",
    "    coeff = (coeff - np.mean(coeff)) / np.std(coeff)\n",
    "    x = coeff[:,start:end].copy()\n",
    "    sgrams[i,:,:,4] = x.copy()\n",
    "\n",
    "    xitem = np.array([item.eeg_id, item.eeg_sub_id, i, item.target,\n",
    "                    item.seizure_vote, item.lpd_vote, item.gpd_vote,\n",
    "                    item.lrda_vote, item.grda_vote, item.other_vote],\n",
    "                    dtype=float).reshape(1,10)\n",
    "    items = np.concatenate([items, xitem])\n",
    "\n",
    "filename = '05_single_cwt_v1_test'     \n",
    "print(f'Saving to {filename}.npy')\n",
    "print(f'Saving to {filename}_items.npy')\n",
    "np.save(f'{output_dir}{filename}.npy', sgrams)\n",
    "np.save(f'{output_dir}{filename}_items.npy', items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gsdc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
